[{"docID": "t5_2r3gv", "qSentId": 65837, "question": "UPDATE: Andrew Ng and Adam Coates will be doing an AMA in /r/MachineLearning on April 14 9AM PST", "aSentId": 65838, "answer": "Sorry, I'm new to reddit, what's an AMA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65839, "question": "Sorry, I'm new to reddit, what's an AMA?", "aSentId": 65840, "answer": "AMA means \"Ask me anything.\"\nYou can ask questions and, in this case, Andrew Ng and Adam Coates will answer them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65841, "question": "AMA means \"Ask me anything.\"\nYou can ask questions and, in this case, Andrew Ng and Adam Coates will answer them.", "aSentId": 65842, "answer": "Andrew Ng and Adam Coates... Exciting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65841, "question": "AMA means \"Ask me anything.\"\nYou can ask questions and, in this case, Andrew Ng and Adam Coates will answer them.", "aSentId": 65844, "answer": "Is there a way to reminder to when the AMA starts?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65845, "question": "Is there a way to reminder to when the AMA starts?", "aSentId": 65846, "answer": "I don't think Reddit has a reminder feature. However setting the AMA time on your Google calendar can help.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65837, "question": "UPDATE: Andrew Ng and Adam Coates will be doing an AMA in /r/MachineLearning on April 14 9AM PST", "aSentId": 65848, "answer": "9 AM..what the fuck is that shit..why not 9 PM ?? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65849, "question": "9 AM..what the fuck is that shit..why not 9 PM ?? ", "aSentId": 65850, "answer": "so that the people at the other side of the globe cud attend it :p\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65837, "question": "UPDATE: Andrew Ng and Adam Coates will be doing an AMA in /r/MachineLearning on April 14 9AM PST", "aSentId": 65852, "answer": "GREAT! thanks", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65860, "question": "\"Social Swarming\" merges human and computer intelligence.", "aSentId": 65861, "answer": "Firstly, this isn't really ML. Secondly, the outputs you get from a query like this depend highly on how you arrange the options. Even with the same people, if you moved around the options to a different configuration the resulting output could be different. And thirdly, this is essentially just a surveying technique, and is vulnerable to sampling bias and all other weaknesses.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65863, "question": "Invariant backpropagation algorithm", "aSentId": 65864, "answer": "I read this paper a few months ago, it's a nice idea but I think they explain it in a needlessly complicated way.\n\nTheir main idea is that you can think of the backwards pass in backpropagation as a forwards pass in a \"backward\" network that shares parameters with the \"forward\" network.  This \"backward\" network (whose structure depends on the input) is a mapping from the loss to the derivatives wrt the input, so if you want to be invariant with respect to perturbations of the input then you should minimize\n\n    L(f(x), y) + alpha*||g_x(y)||^2\n\nwhere f is the forward network and g_x is the backward network.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65865, "question": "I read this paper a few months ago, it's a nice idea but I think they explain it in a needlessly complicated way.\n\nTheir main idea is that you can think of the backwards pass in backpropagation as a forwards pass in a \"backward\" network that shares parameters with the \"forward\" network.  This \"backward\" network (whose structure depends on the input) is a mapping from the loss to the derivatives wrt the input, so if you want to be invariant with respect to perturbations of the input then you should minimize\n\n    L(f(x), y) + alpha*||g_x(y)||^2\n\nwhere f is the forward network and g_x is the backward network.\n", "aSentId": 65866, "answer": "So, essentially the same thing that Goodfellow et al proposed in the [adversarial examples paper](http://arxiv.org/abs/1412.6572) several months earlier.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65867, "question": "So, essentially the same thing that Goodfellow et al proposed in the [adversarial examples paper](http://arxiv.org/abs/1412.6572) several months earlier.", "aSentId": 65868, "answer": "Our adversarial training procedure is different from invariant backprop.\n\nAdversarial training regularizes the *decision function* to be locally *approximately constant*, while invariant backprop regularizes the *cost function* to be *approximately flat*.\n\nThe Goodfellow '14 paper is basically a followup on the Szegedy '13 paper, where we speed up adversarial example generation in order to make adversarial training practical.\n\nThe Demyanov '15 paper is more of a follow-up on contractive autoencoders. It's essentially just the application of the contractive autoencoder penalty to the cost function rather than the hidden representation.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65863, "question": "Invariant backpropagation algorithm", "aSentId": 65870, "answer": "My first association was actually flat minimum search.\n\nFlat minimum search is a rather ancient regulariser, put forward by Hochreiter &amp; Schmidhuber (the LSTM team!). The idea is that minima that are \"flat\", i.e. in a region of low curvature (not derivatives, as in this case) have better generalization capabilities as they are more robust towards perturbations.\n\nWhat strikes me in IBP is that at the minima of the training loss, dL/dw where w are the first layer weights will be zero. Thus, dL/dX will be zero as well (acc. to the chain rule.) Therefore, this method has a regularisation effect that vanishes at the optima. This makes it potentially interesting for RNNs, as argued in our ICLR2014 paper on fast dropout for RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65872, "question": "Q about NNs and embeddings", "aSentId": 65873, "answer": "This is basically the idea of zero shot learning, no?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65874, "question": "This is basically the idea of zero shot learning, no?", "aSentId": 65875, "answer": "You could be right! :) Idk. But there is a major difference. New classes are added in fully supervised mode in my model. No need to mess up with word embeddings etc. Plus we are essentially fixing errors and uncertainties about classification on the go. We could add new classes on the fly. Or fix classification errors as we noticing them. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65872, "question": "Q about NNs and embeddings", "aSentId": 65877, "answer": "I think this is basically the idea of a parzen window classifier on top of a trained convnet. Yann LeCun mentions it in his NVidia webinar, have been meaning to implement myself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65872, "question": "Q about NNs and embeddings", "aSentId": 65879, "answer": "Thinking about this, such model got another advantage, it could learn as you go, newerly classified hashes could be used to adjust subspace of a given class.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65882, "question": "Need Helping using NN to Generalize to Solve the Checkerboard Problem", "aSentId": 65883, "answer": "That paper applies to decision trees, which is why random forests are industry standard. Have you tried the RF hammer on the checkerboard problem for comparison?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65884, "question": "That paper applies to decision trees, which is why random forests are industry standard. Have you tried the RF hammer on the checkerboard problem for comparison?", "aSentId": 65885, "answer": "Thanks for the reply. At least in the toy 10x10 checkerboard I outlined in the OP, RF suffers the same problem as DT (i.e. it gets (5, 5) wrong if that's omitted from the board and the out-of-board error is 50%).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65882, "question": "Need Helping using NN to Generalize to Solve the Checkerboard Problem", "aSentId": 65887, "answer": "Shameless plug -- this looks related to my research.  See \"Automatic generation of behavioral hard disk drive access time models\" in MSST '14 or \"Fourier-assisted machine learning of hard disk drive access time models\" in PDSW '13.  Basically, feeding the right input to the neural net helps a lot.  If you know that the problem is periodic, feeding in sines and cosines lets the neural net generalize to regions of the input space it hasn't seen.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65889, "question": "How to learn neuromorphic engineering?", "aSentId": 65890, "answer": "open skull, remove brain.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65893, "question": "A Statistical View of Deep Learning (III): Memory and Kernels", "aSentId": 65894, "answer": "I have continually expected the field of learning the kernel to take off since the enormous resurgence of deep learning.  Kernel learning  essentially operates on the same principles of learning a good \"representation\" (it would just be implicitly stored), but so far all the methods I've seen have been fairly simple (no models with anywhere near the # of parameters of a simple NN).  Wonder why there's not as much interest in this area...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65895, "question": "I have continually expected the field of learning the kernel to take off since the enormous resurgence of deep learning.  Kernel learning  essentially operates on the same principles of learning a good \"representation\" (it would just be implicitly stored), but so far all the methods I've seen have been fairly simple (no models with anywhere near the # of parameters of a simple NN).  Wonder why there's not as much interest in this area...", "aSentId": 65896, "answer": "\"Kernel learning essentially operates on the same principles of learning a good \"representation\"\"\n\nCan you clarify what you mean?  I can think of a lot of kernel based methods that don't learn an intermediate representation.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65897, "question": "\"Kernel learning essentially operates on the same principles of learning a good \"representation\"\"\n\nCan you clarify what you mean?  I can think of a lot of kernel based methods that don't learn an intermediate representation.  ", "aSentId": 65898, "answer": "A kernel maps the observed data-points into some new feature space (which is never explicitly computed) and computes similarity in this space.  Kernel-learning means rather than pre-specifying the kernel, you try and learn this process.  One easy way to do this would be to explicitly parameterize the mapping into the new feature-space and then just compute a simple say Euclidean similarity in terms of the learned-features in which case you are directly learning a representation (and you can make the mapping into feature-space a few layers deep if you are so inclined).  However, this of course goes against the dogma of kernels whose strength comes from the \"trick\" that you don't need to ever compute the mapping into feature-space.  \nThus the question would be: What kinds of parameterization can we introduce over the  set of similarity-functions (kernels) to be learned such that the corresponding implicit feature mapping is a good representation.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65897, "question": "\"Kernel learning essentially operates on the same principles of learning a good \"representation\"\"\n\nCan you clarify what you mean?  I can think of a lot of kernel based methods that don't learn an intermediate representation.  ", "aSentId": 65900, "answer": "Its kernel learning, not just kernel methods. I think that is the distinction.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65902, "question": "Tips/Tricks/Intuition to obtain Convolutional Neural Network Layer 1 filter convergence (smooth and orthogonal looking filters)?", "aSentId": 65903, "answer": "Definitely normalize the data, that is always a good idea.\n\nIt sounds like you have ~5000 samples overall, that's not a lot. I would guess that the convnet doesn't have to produce crisp first layer filters because the task isn't challenging enough. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65904, "question": "Definitely normalize the data, that is always a good idea.\n\nIt sounds like you have ~5000 samples overall, that's not a lot. I would guess that the convnet doesn't have to produce crisp first layer filters because the task isn't challenging enough. ", "aSentId": 65905, "answer": "I really appreciate the feedback!  :)  I will try normalizing the data next, see what happens.\n\nAlso, I am collecting more samples, but it's a slow process.  I might try data augmentation after trying normalization.  I am not currently adding crops / shifts / flips of my data set, so this may help a lot.\n\nPS, \"Definitely\" gets me all the time too, haha", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65906, "question": "I really appreciate the feedback!  :)  I will try normalizing the data next, see what happens.\n\nAlso, I am collecting more samples, but it's a slow process.  I might try data augmentation after trying normalization.  I am not currently adding crops / shifts / flips of my data set, so this may help a lot.\n\nPS, \"Definitely\" gets me all the time too, haha", "aSentId": 65907, "answer": "Yea data augmentation might be helpful.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65904, "question": "Definitely normalize the data, that is always a good idea.\n\nIt sounds like you have ~5000 samples overall, that's not a lot. I would guess that the convnet doesn't have to produce crisp first layer filters because the task isn't challenging enough. ", "aSentId": 65909, "answer": "It's spelled definitely, you titanic wanker.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65910, "question": "It's spelled definitely, you titanic wanker.", "aSentId": 65911, "answer": "Fair enough.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65912, "question": "Fair enough.", "aSentId": 65913, "answer": "Leave me alone you malodorous shitbassoon", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65914, "question": "Leave me alone you malodorous shitbassoon", "aSentId": 65915, "answer": "This is a really mean bot :(", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65916, "question": "This is a really mean bot :(", "aSentId": 65917, "answer": "Leave me alone you titanic guttersnipe", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65918, "question": "Leave me alone you titanic guttersnipe", "aSentId": 65919, "answer": "Is there a reply limit here?\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65902, "question": "Tips/Tricks/Intuition to obtain Convolutional Neural Network Layer 1 filter convergence (smooth and orthogonal looking filters)?", "aSentId": 65921, "answer": "Like sibibombs said, this happens when the task is too easy. We want the network to learn subtleties of shape and texture, but if the classes are easily separable by something like mean value, the network will just train the final layer to recognize this. \n\nNormalization may help, you can also try making the task harder by adding transformations like gamma adjustment, scale changes, geometric warping, or random cropping. Nice thing is this gives you more training data at the same time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65902, "question": "Tips/Tricks/Intuition to obtain Convolutional Neural Network Layer 1 filter convergence (smooth and orthogonal looking filters)?", "aSentId": 65923, "answer": "Try using a small amount of L2 weight decay. Cross validate to pick the best value.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65924, "question": "Try using a small amount of L2 weight decay. Cross validate to pick the best value.", "aSentId": 65925, "answer": "oh nice, this is a good idea, I forgot about this parameter!  Now that you mention it I remember Dr. Ng talking about the importance of this in the lectures and also using it in the auto-encoder to get nice features.\n\nI'm currently using Caffe, I noticed that I have a global weight decay set to something small, like 0.0005.\n\nThe interesting thing is I read that the way you set the weight_decay for weights and biases for a caffe layer is to add these two lines\n\n  weight_decay: 1      # weight decay multiplier for the filters\n\n  weight_decay: 0      # weight decay multiplier for the biases\n\n\nI kind of wonder what the default multiplier is for biases...if I remember we don't want to weight_decay the biases, but none of my layers have it set to zero.  I looked through the caffe code, but couldn't find an obvious default for the bias weight_decay.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65926, "question": "oh nice, this is a good idea, I forgot about this parameter!  Now that you mention it I remember Dr. Ng talking about the importance of this in the lectures and also using it in the auto-encoder to get nice features.\n\nI'm currently using Caffe, I noticed that I have a global weight decay set to something small, like 0.0005.\n\nThe interesting thing is I read that the way you set the weight_decay for weights and biases for a caffe layer is to add these two lines\n\n  weight_decay: 1      # weight decay multiplier for the filters\n\n  weight_decay: 0      # weight decay multiplier for the biases\n\n\nI kind of wonder what the default multiplier is for biases...if I remember we don't want to weight_decay the biases, but none of my layers have it set to zero.  I looked through the caffe code, but couldn't find an obvious default for the bias weight_decay.", "aSentId": 65927, "answer": "Weight decay on the filters is the important part; you can leave the bias decay term at 0.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65929, "question": "Introducing Amazon Machine Learning \u2013 Make Data-Driven Decisions at Scale", "aSentId": 65930, "answer": "I'm concerned by anything which considers \"false positive rate\" to be an \"advanced metric\" :-/", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65931, "question": "I'm concerned by anything which considers \"false positive rate\" to be an \"advanced metric\" :-/", "aSentId": 65932, "answer": "I suppose it's advanced in the sense that it's not really in the everyday vernacular, in the way that words like \"precise\" and \"accurate\" are.  Still, its meaning is self explanatory.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65933, "question": "I suppose it's advanced in the sense that it's not really in the everyday vernacular, in the way that words like \"precise\" and \"accurate\" are.  Still, its meaning is self explanatory.  ", "aSentId": 65934, "answer": "Call me old fashioned or elitist, but if you consider \"false positive rate\" to be \"advanced\", then you have no business running any form of regression or machine learning.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65935, "question": "Call me old fashioned or elitist, but if you consider \"false positive rate\" to be \"advanced\", then you have no business running any form of regression or machine learning.", "aSentId": 65936, "answer": "elitist!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65935, "question": "Call me old fashioned or elitist, but if you consider \"false positive rate\" to be \"advanced\", then you have no business running any form of regression or machine learning.", "aSentId": 65938, "answer": "This product doesn't seem to be intended for people who actually know machine learning and statistical modeling.  You may think it's a travesty (and I don't necessarily disagree) but there's a market for it.  Not everybody can afford an actual data scientist.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65939, "question": "This product doesn't seem to be intended for people who actually know machine learning and statistical modeling.  You may think it's a travesty (and I don't necessarily disagree) but there's a market for it.  Not everybody can afford an actual data scientist.", "aSentId": 65940, "answer": "That's what bothers me: this idea that we're dumbing down quite complicated statistics and computer science to something so simple we'd consider a basic metric of model quality to be too advanced for the user.\n\nI was in a meeting at my company a few months ago where another (quite large) company was pitching their point-and-click statistical modeling software to us for (drum roll) $250k/yr.  That's more than the cost of a (non-netflix) data scientist in the bay area, and doesn't include the cost of the personnel to actually use the software.  Further, if you actually pay the cost for a \"legit\" data scientist, they'd know that the model you're trying to build could be done with 2 lines of R code (and, in reality, the hardest work in either case is the data wrangling that happens for weeks prior to building the model).  The unfortunate part of these \"ML-as-a-service\" products is that the user has no concept for how to assess when they're right or wrong.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65929, "question": "Introducing Amazon Machine Learning \u2013 Make Data-Driven Decisions at Scale", "aSentId": 65942, "answer": "Azure machine learning is free.\n\nAmazon is not.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65943, "question": "Azure machine learning is free.\n\nAmazon is not.\n", "aSentId": 65944, "answer": "Kind of. Azure ML's free tier is only single node and doesn't have a production API.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65929, "question": "Introducing Amazon Machine Learning \u2013 Make Data-Driven Decisions at Scale", "aSentId": 65946, "answer": "OP, thank you so much for this. I was looking for some pre-built solutions against which I could evaluate my programming skills. This is extremely helpful even if I pay for $2 of use to verify from time to time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65947, "question": "OP, thank you so much for this. I was looking for some pre-built solutions against which I could evaluate my programming skills. This is extremely helpful even if I pay for $2 of use to verify from time to time.", "aSentId": 65948, "answer": "This doesn't sound like what you're looking for...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65947, "question": "OP, thank you so much for this. I was looking for some pre-built solutions against which I could evaluate my programming skills. This is extremely helpful even if I pay for $2 of use to verify from time to time.", "aSentId": 65950, "answer": "How do you mean, in terms of implementing the algorithm correctly or optimizing/parallelizing it for efficiency?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65952, "question": "What is IBM looking for in Numenta?", "aSentId": 65953, "answer": "I always see Numenta getting shit around here, but for once I'm curious to see an earnest discussion on what might have caught IBM's attention here and what technologies are at play.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65954, "question": "I always see Numenta getting shit around here, but for once I'm curious to see an earnest discussion on what might have caught IBM's attention here and what technologies are at play.", "aSentId": 65955, "answer": "If you're looking for any kind of *informed* discussion then an MIT Tech Review article is the wrong place to start.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65952, "question": "What is IBM looking for in Numenta?", "aSentId": 65957, "answer": "IBM is looking for more PR. And Numenta oreol of advanced AI startup only adds to IBM aura. \n\nAnd IBM spends a lot on PR, their entrance into Jeopardy! was pure PR move.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65958, "question": "IBM is looking for more PR. And Numenta oreol of advanced AI startup only adds to IBM aura. \n\nAnd IBM spends a lot on PR, their entrance into Jeopardy! was pure PR move.", "aSentId": 65959, "answer": "This might be pretty close to the truth. I know of several areas in which IBM sells software to companies/governments around the world through their business contacts in which their technology is quite far from impressive or state-of-the-art. The whole hype and buzz cycle they create is used to sell this technology (and used by the employees of the companies/governments to sell the ideas to their peers). It is, of course, a legitimate way of doing business, but Hawkins pointing to IBM's endorsement as proof that the ideas have merit does not do anything for me.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65960, "question": "This might be pretty close to the truth. I know of several areas in which IBM sells software to companies/governments around the world through their business contacts in which their technology is quite far from impressive or state-of-the-art. The whole hype and buzz cycle they create is used to sell this technology (and used by the employees of the companies/governments to sell the ideas to their peers). It is, of course, a legitimate way of doing business, but Hawkins pointing to IBM's endorsement as proof that the ideas have merit does not do anything for me.", "aSentId": 65961, "answer": "You're mostly right about this.. I think, however, that it's an attempt to counteract the widespread public dismissal of HTM by many on the Deep Learning side. And it's correct that IBM's endorsement is no proof of merit, any more than Google's, Baidu's or Facebook's is proof of the merit of DL. It's \"proof\" only in the PR conflict between the two. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65962, "question": "You're mostly right about this.. I think, however, that it's an attempt to counteract the widespread public dismissal of HTM by many on the Deep Learning side. And it's correct that IBM's endorsement is no proof of merit, any more than Google's, Baidu's or Facebook's is proof of the merit of DL. It's \"proof\" only in the PR conflict between the two. ", "aSentId": 65963, "answer": "The dismissal of HTM has nothing to do with the fact that big companies don't use it, nor is the excitement around DL centered on the fact that big companies do use it. The causal relationship is very much that DL got exciting (by showing very impressive results in benchmarks/competitions), therefore FaceGooBai started to use it.\n\nHTM is neither impressive from a machine learning, nor a neuroscientific perspective. Honestly no one understands Hawkins' incoherent ramblings anyway.\n\nIBM needed a differentiator - they can't compete with open source packages or things like GraphLab or H2O for ML as a service (which is what they want Watson to be), so they're betting on this fringe rubbish that they're hoping will ultimately be redeemed (like DL was in the last decade or so).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65964, "question": "The dismissal of HTM has nothing to do with the fact that big companies don't use it, nor is the excitement around DL centered on the fact that big companies do use it. The causal relationship is very much that DL got exciting (by showing very impressive results in benchmarks/competitions), therefore FaceGooBai started to use it.\n\nHTM is neither impressive from a machine learning, nor a neuroscientific perspective. Honestly no one understands Hawkins' incoherent ramblings anyway.\n\nIBM needed a differentiator - they can't compete with open source packages or things like GraphLab or H2O for ML as a service (which is what they want Watson to be), so they're betting on this fringe rubbish that they're hoping will ultimately be redeemed (like DL was in the last decade or so).", "aSentId": 65965, "answer": "You don't even know what HTM is, how are you so sure that it is \"fringe rubbish\"? Also, if you cannot implement HTM yourself after following the whitepaper, then it's not the \"incoherent ramblings\" but rather your lack of understanding. (For reference, I wrote an HTM implementation by just following the whitepaper. I found it relatively easy. And no, I haven't worked for Numenta).\n\nHTM can do one-shot learning (no catastrophic interference). I think it deserves some credit for that alone.\n\nYou act like HTM is irredeemably useless voodoo snakeoil. It is definitely not.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65966, "question": "You don't even know what HTM is, how are you so sure that it is \"fringe rubbish\"? Also, if you cannot implement HTM yourself after following the whitepaper, then it's not the \"incoherent ramblings\" but rather your lack of understanding. (For reference, I wrote an HTM implementation by just following the whitepaper. I found it relatively easy. And no, I haven't worked for Numenta).\n\nHTM can do one-shot learning (no catastrophic interference). I think it deserves some credit for that alone.\n\nYou act like HTM is irredeemably useless voodoo snakeoil. It is definitely not.", "aSentId": 65967, "answer": "How do HTMs compare to Li, Fergus and Perona (2006) in terms of one-shot learning? You're certainly right about me not wanting to invest my time into learning the details of/implementing HTMs, and that is because I just have no evidence that it performs close to the state-of-the-art on any task. And Hawkins has been going on and on about his achievements (which have never worked well in any practical applications), that he now needs to show people these comparisons, or it makes sense to stick with the voodoo snake oil prior.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65966, "question": "You don't even know what HTM is, how are you so sure that it is \"fringe rubbish\"? Also, if you cannot implement HTM yourself after following the whitepaper, then it's not the \"incoherent ramblings\" but rather your lack of understanding. (For reference, I wrote an HTM implementation by just following the whitepaper. I found it relatively easy. And no, I haven't worked for Numenta).\n\nHTM can do one-shot learning (no catastrophic interference). I think it deserves some credit for that alone.\n\nYou act like HTM is irredeemably useless voodoo snakeoil. It is definitely not.", "aSentId": 65969, "answer": "show us the benchmark, eric.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65970, "question": "show us the benchmark, eric.", "aSentId": 65971, "answer": "You realize that I am trying to do that, right? That's what I make all the posts on. I also made a library, called pyhtfe, which has a benchmark in it for music prediction.\n\nYou bring absolutely nothing to the discussion. What have you created that is of any value? All you do is destroy other people's work.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65952, "question": "What is IBM looking for in Numenta?", "aSentId": 65973, "answer": "Please keep in mind that use of the word \"like\" in all these references which try to compare DL to HTMs are \"like\" extending a branch to someone sinking in quicksand. It is an attempt to bridge an understanding only. To put things in terms to which DL people can relate.\nHTM theory is just different. It is an examination of the biological cause of cognition - a realization of the limitation that a \"whole\" is more than the sum of its parts. Just because you get something that looks like a steering wheel, engine, chassis, seats etc. doesn't mean you now have a car - and because it rolls a little bit, doesn't even verify the soundness of its parts.\nHTM theory works like the brain does. A lot of effort is put into this examination. We already have a system that does cognition, why try to arrive at the whole by postulating \"look-alike\" parts?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65974, "question": "Please keep in mind that use of the word \"like\" in all these references which try to compare DL to HTMs are \"like\" extending a branch to someone sinking in quicksand. It is an attempt to bridge an understanding only. To put things in terms to which DL people can relate.\nHTM theory is just different. It is an examination of the biological cause of cognition - a realization of the limitation that a \"whole\" is more than the sum of its parts. Just because you get something that looks like a steering wheel, engine, chassis, seats etc. doesn't mean you now have a car - and because it rolls a little bit, doesn't even verify the soundness of its parts.\nHTM theory works like the brain does. A lot of effort is put into this examination. We already have a system that does cognition, why try to arrive at the whole by postulating \"look-alike\" parts?", "aSentId": 65975, "answer": "because your shit doesn't do shit? neuroscientists think you suck also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65979, "question": "New video series: Intro to machine learning with scikit-learn (Kaggle)", "aSentId": 65980, "answer": "Awesome, just what I am looking for.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65982, "question": "[Question] Signal Variance Issues in networks with rectifier units and a softmax layer.", "aSentId": 65983, "answer": "\"This may be problematic if the the final layer is a softmax/sigmoid, which might become saturated\"\n\nWhy is this bad?  Cross entropy loss is: \n\nlog(y)       if y* == 1\n\n\nlog(1 - y)  if y* == 0\n\nBasically, if your model's prediction is wrong, then the loss goes to infinity as the confidence goes to 100%.  So you can still have large loss, even if the sigmoid saturates.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65984, "question": "\"This may be problematic if the the final layer is a softmax/sigmoid, which might become saturated\"\n\nWhy is this bad?  Cross entropy loss is: \n\nlog(y)       if y* == 1\n\n\nlog(1 - y)  if y* == 0\n\nBasically, if your model's prediction is wrong, then the loss goes to infinity as the confidence goes to 100%.  So you can still have large loss, even if the sigmoid saturates.  ", "aSentId": 65985, "answer": "hmm i see as the sigmoid type unit is just present in one, the output layer, it can be fixed by a function like the cross-entropy whose gradient does not involve the unit activation...? (do i understand this correctly?)\nso the normal vanishing gradient problem we consider will not be an issue.\n\nYour answer made me go through Michael Nielsen's chapter on [this](http://neuralnetworksanddeeplearning.com/chap5.html) (section \" The exploding gradient problem\") It does seem the exploding gradient problem may still occur?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65982, "question": "[Question] Signal Variance Issues in networks with rectifier units and a softmax layer.", "aSentId": 65987, "answer": "You could implement batch normalization to deal with this. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65990, "question": "Error in Text Understanding from Scratch Paper - Zhang, LeCun", "aSentId": 65991, "answer": "To me, this error is way more benign than the fact that the paper's overall evaluation methodology is extremely poor. \n\nTheir baselines are unreasonably weak. They're seriously just using unigram on the top 5000 words in the vocabulary? Yes, they're doing NLP from scratch, but it would have been reasonable to show that they can beat using features that you would be expected to implement in an undergrad intro NLP course, such as bigrams, etc. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65990, "question": "Error in Text Understanding from Scratch Paper - Zhang, LeCun", "aSentId": 65993, "answer": "I published erroneous results twice already, both only submitted to arxiv though. The moment you realise this is pretty terrible.\n\nThe good news is that arxiv lets you withdraw papers and fix errors with new versions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65990, "question": "Error in Text Understanding from Scratch Paper - Zhang, LeCun", "aSentId": 65995, "answer": "This isn't the first time errors in creating testing and training sets has led to paper retractions.\n\nOn such large user-generated datasets, making sure every element in the dataset is entirely independent of every other in every way seems almost impossible.\n\nIn this case, it's simple duplication, but one might imagine other cases where, for example, reviews quote one another or images which are of the exact same scene from different angles or crops of the same photo.\n\nHow can the community protect against that?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65996, "question": "This isn't the first time errors in creating testing and training sets has led to paper retractions.\n\nOn such large user-generated datasets, making sure every element in the dataset is entirely independent of every other in every way seems almost impossible.\n\nIn this case, it's simple duplication, but one might imagine other cases where, for example, reviews quote one another or images which are of the exact same scene from different angles or crops of the same photo.\n\nHow can the community protect against that?", "aSentId": 65997, "answer": "Include knn, k=1, in your benchmarks. If there is duplicate data it will do really well. \n\nAlso looking at the distribution of errors should help. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 65996, "question": "This isn't the first time errors in creating testing and training sets has led to paper retractions.\n\nOn such large user-generated datasets, making sure every element in the dataset is entirely independent of every other in every way seems almost impossible.\n\nIn this case, it's simple duplication, but one might imagine other cases where, for example, reviews quote one another or images which are of the exact same scene from different angles or crops of the same photo.\n\nHow can the community protect against that?", "aSentId": 65999, "answer": "It doesn't seem like it affects the efficacy of the code. I've been experimenting with it on my own datasets to great results so far.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66001, "question": "Anyone have a good near-duplicates checking method? Maybe I'll use `difflib.get_close_matches()`, but that seems quite slow.\n\nNow that I think about it, I suspect that my product reviews datasets may have many duplicates too. In reviews that mention multiple products, people often post that same review to all the mentioned products, with only a sentence or two changed.", "aSentId": 66002, "answer": "Maybe something like FLANN would perform well enough to do a big nearest neighbor search, outliers should be pretty visible there.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66004, "question": "I posed a question about Machine Learning and Artificial Intelligence, but my friends and I couldn't find an answer.", "aSentId": 66005, "answer": "You may want to look into automated theorem proving.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66006, "question": "You may want to look into automated theorem proving.", "aSentId": 66007, "answer": "Additionally, check out Godel's Incompleteness Theorem. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66008, "question": "Additionally, check out Godel's Incompleteness Theorem. ", "aSentId": 66009, "answer": "I don't know very much about machine learning or AI, but I am very interested in the subject (I want to explore it as I continue my degree in CS), so when I was reading about G\u00f6del's Incompleteness Theorem, the first thing that came to mind was this: would we be able to create a machine that has a set of existing axioms that it can use in higher level math to solve problems on its own? Would something like that be feasible? Or after a certain point, do things like this become impractical or impossible?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66004, "question": "I posed a question about Machine Learning and Artificial Intelligence, but my friends and I couldn't find an answer.", "aSentId": 66011, "answer": "An often used toy-example for Recurrent Neural Nets is to demonstrate learning of a binary addition algorithm. Not sure about what other math-y things RNNs can do these days...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66004, "question": "I posed a question about Machine Learning and Artificial Intelligence, but my friends and I couldn't find an answer.", "aSentId": 66013, "answer": "Machine learning is about creating models for highly noisy and random systems.\n\nMaths is about simple logic.\n\nThe two do not work well together.\n\nBut there is already AI for math. But it is not machine learning but proper languages to describe mathematical logic.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66014, "question": "Machine learning is about creating models for highly noisy and random systems.\n\nMaths is about simple logic.\n\nThe two do not work well together.\n\nBut there is already AI for math. But it is not machine learning but proper languages to describe mathematical logic.", "aSentId": 66015, "answer": "I agree, however some people take steps in this direction:\n\nhttp://arxiv.org/abs/1410.5401\n\nPreliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66017, "question": "Do you mean something like this, just more complex?\nhttps://photomath.net/en/", "aSentId": 66018, "answer": "This is along the lines of what I was thinking, yes. Other comments have shed light on my question as well. I knew that AI was complicated, I just didn't realize that AI with math would be so much more complicated since math seems to be straightforward (i.e it has rules and laws that govern how things work within systems.).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66021, "question": "Markov Chain Audio Generation", "aSentId": 66022, "answer": "I did a project like this for an AI class. You'll quickly realize that the melodies generated can sound \"meandering\" with a simple Markov chain. So I took a slightly more sophisticated approach. First, I trained a Markov chain to generate a chord progression. Then, I built a probability distribution of notes for each chord. I also built a Markov chain for each voice (soprano, alto, etc.). Then I built a \"harmony\" distribution (I.e. the probability of an E playing with a B, for example) for each pair of notes and applied it to each pair of voices. To create a song, I would generate four notes, one for each voice, a beat at a time, by sampling from the product of each previously mentioned probability distribution. I trained on some Bach chorales since they have a very rigid and consistent structure. I did a user study to see if people could tell the difference between a generated piece or a real Bach piece. People with some musical training could sometimes tell the difference. There was some more details but that was the basic idea.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66023, "question": "I did a project like this for an AI class. You'll quickly realize that the melodies generated can sound \"meandering\" with a simple Markov chain. So I took a slightly more sophisticated approach. First, I trained a Markov chain to generate a chord progression. Then, I built a probability distribution of notes for each chord. I also built a Markov chain for each voice (soprano, alto, etc.). Then I built a \"harmony\" distribution (I.e. the probability of an E playing with a B, for example) for each pair of notes and applied it to each pair of voices. To create a song, I would generate four notes, one for each voice, a beat at a time, by sampling from the product of each previously mentioned probability distribution. I trained on some Bach chorales since they have a very rigid and consistent structure. I did a user study to see if people could tell the difference between a generated piece or a real Bach piece. People with some musical training could sometimes tell the difference. There was some more details but that was the basic idea.", "aSentId": 66024, "answer": "That is awesome. Is your code or a paper about your work available someplace?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66025, "question": "That is awesome. Is your code or a paper about your work available someplace?", "aSentId": 66026, "answer": "They're on backup storage somewhere but I can try to find them", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66023, "question": "I did a project like this for an AI class. You'll quickly realize that the melodies generated can sound \"meandering\" with a simple Markov chain. So I took a slightly more sophisticated approach. First, I trained a Markov chain to generate a chord progression. Then, I built a probability distribution of notes for each chord. I also built a Markov chain for each voice (soprano, alto, etc.). Then I built a \"harmony\" distribution (I.e. the probability of an E playing with a B, for example) for each pair of notes and applied it to each pair of voices. To create a song, I would generate four notes, one for each voice, a beat at a time, by sampling from the product of each previously mentioned probability distribution. I trained on some Bach chorales since they have a very rigid and consistent structure. I did a user study to see if people could tell the difference between a generated piece or a real Bach piece. People with some musical training could sometimes tell the difference. There was some more details but that was the basic idea.", "aSentId": 66028, "answer": "How did you read in the music files? Similar to what I wrote in my post?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66029, "question": "How did you read in the music files? Similar to what I wrote in my post?", "aSentId": 66030, "answer": "I'm working on a similar project, and it seems that there isn't any good library for MIDI usage and conversion to markov chians (via n-grams or some other approach), at least not in java or python.\n\nThe way MIDI stores data is space efficient, you get a signal when a note turns \"on\" and another when the note goes \"off\", this forces you to convert to a format where you can query whether or not a given note is on or off at time *t* to construct a markov-chain based model. (and no library I've found does this, so we built one, but its currently hacky and ugly).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66029, "question": "How did you read in the music files? Similar to what I wrote in my post?", "aSentId": 66032, "answer": "To train I read in kern files because they were easy to parse. The program would output kern which you can convert to midi.  There's a suite of tools available for kern files that can compute the key of a song, or estimate the chord progression, which I used for training the chord progression Markov chain.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66023, "question": "I did a project like this for an AI class. You'll quickly realize that the melodies generated can sound \"meandering\" with a simple Markov chain. So I took a slightly more sophisticated approach. First, I trained a Markov chain to generate a chord progression. Then, I built a probability distribution of notes for each chord. I also built a Markov chain for each voice (soprano, alto, etc.). Then I built a \"harmony\" distribution (I.e. the probability of an E playing with a B, for example) for each pair of notes and applied it to each pair of voices. To create a song, I would generate four notes, one for each voice, a beat at a time, by sampling from the product of each previously mentioned probability distribution. I trained on some Bach chorales since they have a very rigid and consistent structure. I did a user study to see if people could tell the difference between a generated piece or a real Bach piece. People with some musical training could sometimes tell the difference. There was some more details but that was the basic idea.", "aSentId": 66034, "answer": "Do you remember roughly how long it took to learn the transition probabilities?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66035, "question": "Do you remember roughly how long it took to learn the transition probabilities?", "aSentId": 66036, "answer": "Not that long, they were pretty simple to compute. Sampling from the product was time consuming, however, because I used a rejection sampler. Markov chain monte Carlo might have been better.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66021, "question": "Markov Chain Audio Generation", "aSentId": 66038, "answer": "If you are interested in this, check out the RNN-RBM on the Theano deep learning tutorials - this is exactly what it was used for (on midi files). Note that training Gaussian RBMs or DBNs really sucks in my experience, but Bernoulli seems to work great. Long live MIDI?\n\nhttp://deeplearning.net/tutorial/rnnrbm.html#rnnrbm\n\nI have done a version which computes MFCCs or LPC/LSF coefficients from the raw wav files, discretizes using vector quantization (K-means) then trains an RNN-RBM on that binarized (one-hot) representation. You then reconstruct the audio from the output by inverting the preprocessing chain (look up value of K-means code, then invert LPC/LSF/MFCC). A similar approach might work for you if you want to get into RNN-RBMs. The current best method for this to my knowledge is LSTM-DBN, by Kratarth Goel http://arxiv.org/abs/1412.7927", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66021, "question": "Markov Chain Audio Generation", "aSentId": 66040, "answer": "I'm thinking about doing this with some ambient music from my favourite composers. So if you build something, I'd be very interested in seeing the results!\n\nI recently came into possession of a shit-ton of ML-audio-related papers all in pdf format (that I haven't read through yet), but I'm pretty sure at least one of them discussed Markov chains for audio generation. I can PM a link to them if you're interested.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66041, "question": "I'm thinking about doing this with some ambient music from my favourite composers. So if you build something, I'd be very interested in seeing the results!\n\nI recently came into possession of a shit-ton of ML-audio-related papers all in pdf format (that I haven't read through yet), but I'm pretty sure at least one of them discussed Markov chains for audio generation. I can PM a link to them if you're interested.", "aSentId": 66042, "answer": "Would love to see anything you've got that could help.\n\nData-related ML and Computer Vision are my two main areas of focus, but I have a background in music (play guitar, bass, drums, piano, and voice) and thought something like this would make for an interesting/fun side-project.\n\nWill probably start taking a crack at it over the weekend and if I can get something working, I'll post the Github link here.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66045, "question": "Funny, I was actually just recently thinking about this as a fun side project! However, I decided to put it off and focus on other things at the moment.\n\nAnyway, I would definitely do this with midi if you can. The internet is abundant with free classical midi files. There is a [nice library](https://github.com/vishnubob/python-midi) for reading and writing midi files with python, too.\n\nI was planning to do this with fugues from Bach's Well-Tempered Clavier since these have a natural sequential nature to them and number of notes that are on at a given point is usually quite limited. My plan was to translate all the fugues to a common key, say C, and use this as training data to learn transition probabilities of a 2nd or maybe 3rd order Markov Chain. My only issue (hypothetically) is in handling different note lengths since Markov Chains are discrete.\n\nHas anyone tried something other than a Markov Chain?", "aSentId": 66046, "answer": "&gt; Has anyone tried something other than a Markov Chain?\n\nAt this point, it's just an idea I had and wanted to get some feedback from others.  I'm open to whatever other variations people might think of.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 66045, "question": "Funny, I was actually just recently thinking about this as a fun side project! However, I decided to put it off and focus on other things at the moment.\n\nAnyway, I would definitely do this with midi if you can. The internet is abundant with free classical midi files. There is a [nice library](https://github.com/vishnubob/python-midi) for reading and writing midi files with python, too.\n\nI was planning to do this with fugues from Bach's Well-Tempered Clavier since these have a natural sequential nature to them and number of notes that are on at a given point is usually quite limited. My plan was to translate all the fugues to a common key, say C, and use this as training data to learn transition probabilities of a 2nd or maybe 3rd order Markov Chain. My only issue (hypothetically) is in handling different note lengths since Markov Chains are discrete.\n\nHas anyone tried something other than a Markov Chain?", "aSentId": 66048, "answer": "Is it easy to convert the MIDI files into music? \n\nAn ML algo needs vectors as input, and generates vectors as output. Is it easy to go from MIDI -&gt; a vector representation, and vice versa?", "corpus": "reddit"}]