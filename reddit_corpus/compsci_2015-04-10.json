[{"docID": "t5_2qhmr", "qSentId": 65527, "question": "Graph Theory for Third Graders", "aSentId": 65528, "answer": "Great stuff. Graphs really should have a place in early education curriculum because it's such a visual concept. They also have amazing scalability, you can ask a third grader a question about a graph that he can likely answer, and you can ask a PhD student a question about the very same graph that he might have a hard time answering!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65529, "question": "Great stuff. Graphs really should have a place in early education curriculum because it's such a visual concept. They also have amazing scalability, you can ask a third grader a question about a graph that he can likely answer, and you can ask a PhD student a question about the very same graph that he might have a hard time answering!", "aSentId": 65530, "answer": "They don't teach graph theory in middle school/high school where you live?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65531, "question": "They don't teach graph theory in middle school/high school where you live?", "aSentId": 65532, "answer": "Well I don't hang around middle school very much even though my post history might suggest that, so I'm not sure. All I know is that when I grew up in the 90s in Norway the only graphs I knew were the y = 2x kind. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65531, "question": "They don't teach graph theory in middle school/high school where you live?", "aSentId": 65534, "answer": "Where are you that they do?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65535, "question": "Where are you that they do?", "aSentId": 65536, "answer": "UK maths A-levels seem to include a segment where they make them do graph algorithms by hand (think Kruskal's algorithm for finding a minimum spanning tree), of course without bothering with correctness arguments. Students seem to either like these modules because they're easy, or dislike them because they are boring. (I have a maths undergrad friend who refuses to do any graph theory because he got sick of it in school.)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65535, "question": "Where are you that they do?", "aSentId": 65538, "answer": "Hungary.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65531, "question": "They don't teach graph theory in middle school/high school where you live?", "aSentId": 65540, "answer": "The Louisiana public school system didn't back in the early 2000's. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65527, "question": "Graph Theory for Third Graders", "aSentId": 65542, "answer": "That's dangerous. Graphs are gateway maths to Operational Research.\n\nSeriously, common people try to put the world into small square boxes, but the truth is, the world is a graph. Much more connected that you'd think, too.\n\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65543, "question": "That's dangerous. Graphs are gateway maths to Operational Research.\n\nSeriously, common people try to put the world into small square boxes, but the truth is, the world is a graph. Much more connected that you'd think, too.\n\n", "aSentId": 65544, "answer": "The world is a complete graph, if you're sufficiently general.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65543, "question": "That's dangerous. Graphs are gateway maths to Operational Research.\n\nSeriously, common people try to put the world into small square boxes, but the truth is, the world is a graph. Much more connected that you'd think, too.\n\n", "aSentId": 65546, "answer": "Funny, since historically topology was considered to be one of the most abstract and impractical branches of mathematics.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65527, "question": "Graph Theory for Third Graders", "aSentId": 65548, "answer": "That's awesome! I recently just learnt about this in a graph theory class in Junior year of college, so it's pretty cool seeing how you made it simple enough for third graders to follow!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65551, "question": "This was truly awesome. I wish I had be thought graphs at this level when I first learned them. ", "aSentId": 65552, "answer": "The sad part is. Since I finished school, I've had so many great math-lessons, that were interesting and where I could really learn something. Just never in school. The one institution, that's supposed to teach young children how to do maths, is the one that does a better job at making it seem boring and dull... \n\nThere are so many great resources out there. But schools still think they are in the 1800s... ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65555, "question": "That is awesome made available for kids. But am I the only one who is surprised/terrified that math teachers at the school didn't know this stuff?", "aSentId": 65556, "answer": "Terrified? \n\nAt my school, we have one undergraduate graph theory class. And every MathEd student doesn't take every math class. That would impossible. So some get through without taking graph theory. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65555, "question": "That is awesome made available for kids. But am I the only one who is surprised/terrified that math teachers at the school didn't know this stuff?", "aSentId": 65558, "answer": "I'm not. Most K-12 public schools in America put an emphasis on Arithmetic, Algebra, Geometry, Trigonometry, and Calculus (a little bit of rudimentary Statistics too). Not being up to date on Graph Theory doesn't mean they wouldn't be perfectly qualified to teach in one of these other fields.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65555, "question": "That is awesome made available for kids. But am I the only one who is surprised/terrified that math teachers at the school didn't know this stuff?", "aSentId": 65560, "answer": "I don't know if it's different where you live but here in the UK before secondary (high school) most state school teachers aren't required to be proficient in a certain subject and all of them tend to teach everything. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65561, "question": "I don't know if it's different where you live but here in the UK before secondary (high school) most state school teachers aren't required to be proficient in a certain subject and all of them tend to teach everything. ", "aSentId": 65562, "answer": "That might be the difference. Where I am from teachers doesn't teach everything, but only the 2-3 subjects they specialize in.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65565, "question": "\"surprised\".. haven't you been in school?\n\nHardly any teacher I had ever knew more than what they had to teach. Hardly anyone could answer followup questions. The few who could were considered great teachers. \n\nYou know how they say: \"Those who can, do. Those who can't, teach\"... \n\nEven though, in reality, it's usually a case of the good teachers opting out of teaching, because it just doesn't pay. They can earn a lot more in a regular job. ", "aSentId": 65566, "answer": "Well guess we see things very differently. I've had good and bad teachers, so i refuse to generalize all teachers like you just did. And even though i know it is true that there are a lot of bad teachers, I don't think it helps anyone that we become content with them being bad just because \"Those who can, do. Those who can't, teach\" as you said.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65567, "question": "Well guess we see things very differently. I've had good and bad teachers, so i refuse to generalize all teachers like you just did. And even though i know it is true that there are a lot of bad teachers, I don't think it helps anyone that we become content with them being bad just because \"Those who can, do. Those who can't, teach\" as you said.", "aSentId": 65568, "answer": "Like I tried to clarify, not all teachers are bad. But considering that teachers get a bad pay, many good teachers I had chose to leave teaching and start working in the private sector. Especially one very good math-teacher I had, who quit because he got paid little, didn't get the resources he wanted for teaching and got offered a job at a statistics-company paying him 3 times what he would have gotten teaching. Despite wanting to teach, he chose that he'd rather not teach under those circumstances.\n\nSadly, our Schoolsystem encourages bad teachers (as long as they don't fall out of line too often) to stay in their job, while good teachers are encouraged to look for better jobs. \n\nThe problem isn't the teachers. It's the system that accumulates bad teachers while it gets rid of good ones. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65569, "question": "Like I tried to clarify, not all teachers are bad. But considering that teachers get a bad pay, many good teachers I had chose to leave teaching and start working in the private sector. Especially one very good math-teacher I had, who quit because he got paid little, didn't get the resources he wanted for teaching and got offered a job at a statistics-company paying him 3 times what he would have gotten teaching. Despite wanting to teach, he chose that he'd rather not teach under those circumstances.\n\nSadly, our Schoolsystem encourages bad teachers (as long as they don't fall out of line too often) to stay in their job, while good teachers are encouraged to look for better jobs. \n\nThe problem isn't the teachers. It's the system that accumulates bad teachers while it gets rid of good ones. ", "aSentId": 65570, "answer": "For context, which school system is this that you're talking about?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65571, "question": "For context, which school system is this that you're talking about?", "aSentId": 65572, "answer": "Middle of europe, but applies to every country where education is underfunded. \n\nSome northern european countries have a better situation, but I guess it's nowhere perfect. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65575, "question": "1. Who is the most influential living computer scientist? 2. who is the most influential computer scientist of the 20th century?", "aSentId": 65576, "answer": "1. Knuth, 2. Von Neumann\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65575, "question": "1. Who is the most influential living computer scientist? 2. who is the most influential computer scientist of the 20th century?", "aSentId": 65578, "answer": "1. Here's the easy answer: Don Knuth\n2. Another gimme: Alan Turing.  ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65579, "question": "1. Here's the easy answer: Don Knuth\n2. Another gimme: Alan Turing.  ", "aSentId": 65580, "answer": "The guy who played Barney Fife on the Andy Griffith show?!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65575, "question": "1. Who is the most influential living computer scientist? 2. who is the most influential computer scientist of the 20th century?", "aSentId": 65582, "answer": "Von Neumann is the greatest of the 20th century no doubt...although Turing is close\n\n\nwhy do you guys consider Knuth to be the greatest living computer scientist though? his output a combination of factors etc.?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65583, "question": "Von Neumann is the greatest of the 20th century no doubt...although Turing is close\n\n\nwhy do you guys consider Knuth to be the greatest living computer scientist though? his output a combination of factors etc.?", "aSentId": 65584, "answer": "Have you studied algorithms? Like 50%+ of algorithms in daily use he invented or had a hand in.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65585, "question": "Have you studied algorithms? Like 50%+ of algorithms in daily use he invented or had a hand in.", "aSentId": 65586, "answer": "so is Knuth like the leading mind behind algorithms", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65592, "question": "Without a doubt, Richard Stallman.  Of course, less because of his direct contributions to the CS field and more to do with the social aspect of FSF and GNU.\n\nThere are plenty others, though.  Guy Steele, Hal Abelson, Gerald Sussman, etc.", "aSentId": 65593, "answer": "To be honest, this post actually upset me. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65597, "question": "The Stellar Consensus Protocol: A Federated Model for Internet-level Consensus", "aSentId": 65598, "answer": "Can't log in and read it...", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65597, "question": "The Stellar Consensus Protocol: A Federated Model for Internet-level Consensus", "aSentId": 65600, "answer": "Edited away to nothingness.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65602, "question": "how to deal with ResearchGate spam", "aSentId": 65603, "answer": "Did you really need to bring bill gates into this?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65604, "question": "Did you really need to bring bill gates into this?", "aSentId": 65605, "answer": "Talk about a non sequitur", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65604, "question": "Did you really need to bring bill gates into this?", "aSentId": 65607, "answer": "Yeah.  Investors rarely, if ever, have influence over tactics.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65604, "question": "Did you really need to bring bill gates into this?", "aSentId": 65609, "answer": "Successful people, right? Holding disdain for them makes me feel better about myself!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65602, "question": "how to deal with ResearchGate spam", "aSentId": 65611, "answer": "What's researchGate?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65612, "question": "What's researchGate?", "aSentId": 65613, "answer": "Something like an academic LinkedIn, except I don't know if anyone actually uses it (as opposed to just creating an account and forgetting about it).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65614, "question": "Something like an academic LinkedIn, except I don't know if anyone actually uses it (as opposed to just creating an account and forgetting about it).", "aSentId": 65615, "answer": "It's hard to forget when they keep sending you shit...", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65602, "question": "how to deal with ResearchGate spam", "aSentId": 65617, "answer": "After all the mails I've been getting, I was actually planning on asking Reddit if ResearchGate was something I should use or not.\n\nIt never struck me as impersonation, though. I felt it was clear that the mail came from the system, and not from a co-author. Doesn't LinkedIn and what not do the same?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65618, "question": "After all the mails I've been getting, I was actually planning on asking Reddit if ResearchGate was something I should use or not.\n\nIt never struck me as impersonation, though. I felt it was clear that the mail came from the system, and not from a co-author. Doesn't LinkedIn and what not do the same?", "aSentId": 65619, "answer": "The co-author's name is on the From line. Only if you open the message or carefully examine the wording of the subject line do you discover that your co-author is not the true author of the email, and in all likelihood, did not approve of its being sent in their name.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65620, "question": "The co-author's name is on the From line. Only if you open the message or carefully examine the wording of the subject line do you discover that your co-author is not the true author of the email, and in all likelihood, did not approve of its being sent in their name.", "aSentId": 65621, "answer": "&gt; The co-author's name is on the From line.\n\nRight. I put more weight on the address (maybe because that's what might be difficult to spoof), and that said \"no-reply@researchgate.net\".", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65624, "question": "Got to say I'm relieved that this is about a shitty website and not some new scandal. ", "aSentId": 65625, "answer": "Oh good, I'm not the only one!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65629, "question": "What makes a good bug report?", "aSentId": 65630, "answer": "A good bug report should state three key items:\n\n * What was attempted (with detailed steps for replication)\n * What was expected\n * What was observed\n\nThe reporter should also be willing to justify their expectation (in case it's not clear to the developer why they would expect that), provide a test case (especially if it involved data specific to the reporter), and to test any attempted fixes to ensure it resolves the issue.\n\nThis makes it \"good\" because it's actionable. As a developer, the first thing I will do is attempt to reproduce it, and assuming that I can, I will then attempt to rework it to do what the reporter expected. Once I've resolved it on the test case, I will send it back to the reporter to verify that it works properly for them, which both confirms for me that I fixed the actual issue and confirms for the reporter that their issue has been resolved. Given all this, the reporter should agree that their issue has been resolved. \n\nThe justification is important because, if there is a discrepancy between my expectations and the reporter's, then the problem can be far more endemic. Perhaps I am unaware of some context, such as the problem that the reporter is trying to solve through application of the software. Perhaps the reporter has a mental model based on some other domain-specific context that I lack. Perhaps the reporter's model doesn't match the system model (or at least the designer's model) because of a failure for the software to clearly communicate that model. Whatever the case, it may indicate a far larger problem than the specific instance that was reported which might require design and architecture changes, or may identify a completely new use case that requires additional features.\n\nA feature request is quite different. Users will often ask you to implement their own solution to a problem, rather than asking you to find a solution to their problem, but the user is typically the last person who knows what would be the best solution to implement in software. Ask a user what would make a good calendar program and they would say, \"One that works just like the calendar on my wall.\" That's what they are used to, and it's what worked on the wall, but what is ideal for one situation can be terrible for another: you end up getting the worst of both worlds. A developer typically has to ask many questions to get to the root of the problem so that they can begin to find solutions that are appropriate for the system.\n\nThat said, the developer rarely has a complete understanding of the user's problem. The user's goals, constraints, and expectations may be completely unlike those of the developer. Without asking questions about these, the developer is doomed to solve the wrong problem: their solution will work great for themselves, but poorly for the user.\n\nAt some point, a feature requests turns into a requirement specification, but it consists of more than just that. It should cover all of the following:\n\n * What problem is the feature supposed to solve for the user?\n * What is the user's end goal? (This is intimately related to the above)\n * What task is the user performing while using this feature?\n * What expectations does the user have?\n * What constraints do they have upon them while performing the task?\n * What is their desired outcome from using the feature?\n * What is the value of solving this problem to the developer?\n\nThere are many more questions worth asking and there have been some great books written on the subject. This is probably one of the most essential and difficult areas of software development. The overall idea is that you want to solve the problem in a way that benefits both the user and the developer, which means solving the actual problem (not a user's or developer's perceived problem) and doing so in a way that is profitable.\n\nFor both bug reports and feature requests, the overall goal is to ensure that the developer understands enough about the problem that they can come up with a reasonable solution. That means having enough of the right information without getting distracted by irrelevant or misleading information. What seems relevant to the reporter is often not what the developer needs to know. Depending on the circumstances, you may be able to coach the reporter into providing better reports, but in many cases a developer must persist in asking appropriate questions.\n\nThe most important thing to remember is that bug reports and feature requests shouldn't be fire-and-forget processes. It should be the beginning of a dialog. There will be questions and clarifications throughout the process. No report will ever be perfect. Developers must be willing to ask questions and should set the expectation with their customers that it will be a cooperative process, not dictated from either side.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65631, "question": "A good bug report should state three key items:\n\n * What was attempted (with detailed steps for replication)\n * What was expected\n * What was observed\n\nThe reporter should also be willing to justify their expectation (in case it's not clear to the developer why they would expect that), provide a test case (especially if it involved data specific to the reporter), and to test any attempted fixes to ensure it resolves the issue.\n\nThis makes it \"good\" because it's actionable. As a developer, the first thing I will do is attempt to reproduce it, and assuming that I can, I will then attempt to rework it to do what the reporter expected. Once I've resolved it on the test case, I will send it back to the reporter to verify that it works properly for them, which both confirms for me that I fixed the actual issue and confirms for the reporter that their issue has been resolved. Given all this, the reporter should agree that their issue has been resolved. \n\nThe justification is important because, if there is a discrepancy between my expectations and the reporter's, then the problem can be far more endemic. Perhaps I am unaware of some context, such as the problem that the reporter is trying to solve through application of the software. Perhaps the reporter has a mental model based on some other domain-specific context that I lack. Perhaps the reporter's model doesn't match the system model (or at least the designer's model) because of a failure for the software to clearly communicate that model. Whatever the case, it may indicate a far larger problem than the specific instance that was reported which might require design and architecture changes, or may identify a completely new use case that requires additional features.\n\nA feature request is quite different. Users will often ask you to implement their own solution to a problem, rather than asking you to find a solution to their problem, but the user is typically the last person who knows what would be the best solution to implement in software. Ask a user what would make a good calendar program and they would say, \"One that works just like the calendar on my wall.\" That's what they are used to, and it's what worked on the wall, but what is ideal for one situation can be terrible for another: you end up getting the worst of both worlds. A developer typically has to ask many questions to get to the root of the problem so that they can begin to find solutions that are appropriate for the system.\n\nThat said, the developer rarely has a complete understanding of the user's problem. The user's goals, constraints, and expectations may be completely unlike those of the developer. Without asking questions about these, the developer is doomed to solve the wrong problem: their solution will work great for themselves, but poorly for the user.\n\nAt some point, a feature requests turns into a requirement specification, but it consists of more than just that. It should cover all of the following:\n\n * What problem is the feature supposed to solve for the user?\n * What is the user's end goal? (This is intimately related to the above)\n * What task is the user performing while using this feature?\n * What expectations does the user have?\n * What constraints do they have upon them while performing the task?\n * What is their desired outcome from using the feature?\n * What is the value of solving this problem to the developer?\n\nThere are many more questions worth asking and there have been some great books written on the subject. This is probably one of the most essential and difficult areas of software development. The overall idea is that you want to solve the problem in a way that benefits both the user and the developer, which means solving the actual problem (not a user's or developer's perceived problem) and doing so in a way that is profitable.\n\nFor both bug reports and feature requests, the overall goal is to ensure that the developer understands enough about the problem that they can come up with a reasonable solution. That means having enough of the right information without getting distracted by irrelevant or misleading information. What seems relevant to the reporter is often not what the developer needs to know. Depending on the circumstances, you may be able to coach the reporter into providing better reports, but in many cases a developer must persist in asking appropriate questions.\n\nThe most important thing to remember is that bug reports and feature requests shouldn't be fire-and-forget processes. It should be the beginning of a dialog. There will be questions and clarifications throughout the process. No report will ever be perfect. Developers must be willing to ask questions and should set the expectation with their customers that it will be a cooperative process, not dictated from either side.", "aSentId": 65632, "answer": "What a response! Thank you very much, that's exactly what I was looking for!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65629, "question": "What makes a good bug report?", "aSentId": 65634, "answer": "For bug reports, I have two criteria that I like to have. First, a picture or log output, whatever best shows the failing behavior best. Second, a very clear and repeatable set of steps to reproduce the broken behavior. If I have those two things, it should be very straightforward to confirm the broken behavior and identify the root cause of the bug.\n\nIn the case of feature requests, I usually like to get a problem statement in the form of \"I'm trying to do X so that I can get Y result, but the existing features simply don't enable me to do this.\" IMO this is the best way to request a feature, because it gives me flexibility to make the best solution for your needs, and let's me suggest a solution for you if one already exists.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65635, "question": "For bug reports, I have two criteria that I like to have. First, a picture or log output, whatever best shows the failing behavior best. Second, a very clear and repeatable set of steps to reproduce the broken behavior. If I have those two things, it should be very straightforward to confirm the broken behavior and identify the root cause of the bug.\n\nIn the case of feature requests, I usually like to get a problem statement in the form of \"I'm trying to do X so that I can get Y result, but the existing features simply don't enable me to do this.\" IMO this is the best way to request a feature, because it gives me flexibility to make the best solution for your needs, and let's me suggest a solution for you if one already exists.", "aSentId": 65636, "answer": "I'd add a good title and maybe categorization. The title must describe the problem succinctly, so you don't have to read every detail to manage a bunch. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65629, "question": "What makes a good bug report?", "aSentId": 65638, "answer": "Eli5 version:\n\nWhat I did: \n\nWhat I expected would happen:\n\nWhat actually happened.\n\nAttachments: (Log, detailed error msg, savegame, OS-Info, Version-Info, whatever you need, usually collected by the bug-report-tool or as upload-option for web-interface)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65642, "question": "Message deduplication, buffering, and forwarding practices?", "aSentId": 65643, "answer": "Have you considered using a database?  All databases that I know of (there may be a weird one or two) have the concept of a primary key which is guaranteed to be unique.  By using an ID from the message, or perhaps generate a key based on the message like a checksum/cryptographic hash, it will basically handle all of the deduplication for you.  You can also store a timestamp along with the record in many of them so that you know how old the message.\n\nSome options, in no particular order: PosgreSQL, MySQL, VoltDB, Redis, BerkeleyDB.\n\nAlso, you may want to look at queues like ActiveMQ or RabbitMQ.  I believe that some have the ability to deduplicate as well.\n\nSo, no, you don't need a fancy AI or anything like that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65644, "question": "Have you considered using a database?  All databases that I know of (there may be a weird one or two) have the concept of a primary key which is guaranteed to be unique.  By using an ID from the message, or perhaps generate a key based on the message like a checksum/cryptographic hash, it will basically handle all of the deduplication for you.  You can also store a timestamp along with the record in many of them so that you know how old the message.\n\nSome options, in no particular order: PosgreSQL, MySQL, VoltDB, Redis, BerkeleyDB.\n\nAlso, you may want to look at queues like ActiveMQ or RabbitMQ.  I believe that some have the ability to deduplicate as well.\n\nSo, no, you don't need a fancy AI or anything like that.", "aSentId": 65645, "answer": "I guess I should have mentioned in my post that the ultimate destination service currently getting inundated with messages is running on a database and that's likely part of the problem. This buffer process will likely be running on the same machine so using a DB would result in the same number of IOPS plus a few more as the existing setup. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65646, "question": "I guess I should have mentioned in my post that the ultimate destination service currently getting inundated with messages is running on a database and that's likely part of the problem. This buffer process will likely be running on the same machine so using a DB would result in the same number of IOPS plus a few more as the existing setup. ", "aSentId": 65647, "answer": "I hate to say it, but I think you've fallen victem to poor design.  As /u/metaphorm stated, that amount of data is very low for modern computers.  If you can, please provide more information so that we can better help you.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65648, "question": "I hate to say it, but I think you've fallen victem to poor design.  As /u/metaphorm stated, that amount of data is very low for modern computers.  If you can, please provide more information so that we can better help you.", "aSentId": 65649, "answer": "It's a JIRA instance being sent crashes from remote software via the built in REST interface. \n\nI've decided on a buffering method though, I'll update the OP momentarily. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65642, "question": "Message deduplication, buffering, and forwarding practices?", "aSentId": 65651, "answer": "I'm wondering if you can identify the actual problem a little bit more precisely. You've suggested that you're concerned about load on your server, but the rate of incoming messages (500-800/hour) is really incredibly small by modern computing standards. \n\nI'm having trouble imagining that will cause load issues for any machine with more computing power than a potato. do the duplicate messages actually cause problems with your program? what is the semantics of the messaging in your system? ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65653, "question": "cppOpt - a C++ library for n-parametric numerical optimisation which I wrote. Hope you guys like it", "aSentId": 65654, "answer": "Looks good :) A couple of thoughts, if I may. \n\nI'd use templates rather than a #define for the  opt type.\n\nFor the simulated annealing are you using a cooling schedule for termination? Also have you tested how robust it is on noisy irregular distributions?\n\nFinally, I feel the design is tightly coupled to the task at hand. Have you looked at how the std library implements functions like std::sort? Where they provide a template driven function that can be further customised by passing lambda's. What if your library followed this model and just provided nicely abstracted and optimised implementations of the functions you care about. I.e.\n\n    template&lt;typename T_result, typename T_domain&gt;\n    T_result opt::simulated_annealing(T_domain dom, std::function&lt;T_result(T_domain)&gt; fitnessFunc);\n\n\nOr something of the like. This way applying an optimisation algorithm within the users code does not require them to specifically structure their classes to use your framework.\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65655, "question": "Looks good :) A couple of thoughts, if I may. \n\nI'd use templates rather than a #define for the  opt type.\n\nFor the simulated annealing are you using a cooling schedule for termination? Also have you tested how robust it is on noisy irregular distributions?\n\nFinally, I feel the design is tightly coupled to the task at hand. Have you looked at how the std library implements functions like std::sort? Where they provide a template driven function that can be further customised by passing lambda's. What if your library followed this model and just provided nicely abstracted and optimised implementations of the functions you care about. I.e.\n\n    template&lt;typename T_result, typename T_domain&gt;\n    T_result opt::simulated_annealing(T_domain dom, std::function&lt;T_result(T_domain)&gt; fitnessFunc);\n\n\nOr something of the like. This way applying an optimisation algorithm within the users code does not require them to specifically structure their classes to use your framework.\n", "aSentId": 65656, "answer": "it's templated now", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65653, "question": "cppOpt - a C++ library for n-parametric numerical optimisation which I wrote. Hope you guys like it", "aSentId": 65658, "answer": "You should use more modern/efficient optimisation algorithms...", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65659, "question": "You should use more modern/efficient optimisation algorithms...", "aSentId": 65660, "answer": "which ones?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65659, "question": "You should use more modern/efficient optimisation algorithms...", "aSentId": 65662, "answer": "i.e. Particle Swarm Optimization is really simple but far better than those you used...", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65653, "question": "cppOpt - a C++ library for n-parametric numerical optimisation which I wrote. Hope you guys like it", "aSentId": 65664, "answer": "It looks nice.\nI use multidimensional optimisation almost daily, and currently I am using the BFGS algorithm, however i've been long searching for a implementation of L-BFGS-B that is much faster and uses less memory, The fortran implementation was corrected not so long ago (I think this year) but it hasn't arrived in C++ form yet, you could easily add it to your library using f2c. This algorithm is very very fast when you have the gradient but the hessian matrix is almost singular and cant be computed directly. It would be a nice addition to the package. Maybe i'll contribute it in a few weeks if i have the time. But you can look into it if it serves your purposes.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65665, "question": "It looks nice.\nI use multidimensional optimisation almost daily, and currently I am using the BFGS algorithm, however i've been long searching for a implementation of L-BFGS-B that is much faster and uses less memory, The fortran implementation was corrected not so long ago (I think this year) but it hasn't arrived in C++ form yet, you could easily add it to your library using f2c. This algorithm is very very fast when you have the gradient but the hessian matrix is almost singular and cant be computed directly. It would be a nice addition to the package. Maybe i'll contribute it in a few weeks if i have the time. But you can look into it if it serves your purposes.", "aSentId": 65666, "answer": "can BFGS work with problems where the actual function is unknown?  \ncurrently I want to limit it to algorithms which don't need any knowledge", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65668, "question": "Kolmogorov Complexity", "aSentId": 65669, "answer": "I'm not sure what you mean by \"analytic approximation\". But any approximation of Kolmogorov complexity is going to be wildly inaccurate for some strings, mostly due to this theorem:\n\nThere exists a constant L (which only depends on the particular axiomatic system and the choice of description language) such that there does not exist a string s for which the statement \"K(s) \u2265 L (as formalized in S)\" can be proven within the axiomatic system S.\n\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65670, "question": "I'm not sure what you mean by \"analytic approximation\". But any approximation of Kolmogorov complexity is going to be wildly inaccurate for some strings, mostly due to this theorem:\n\nThere exists a constant L (which only depends on the particular axiomatic system and the choice of description language) such that there does not exist a string s for which the statement \"K(s) \u2265 L (as formalized in S)\" can be proven within the axiomatic system S.\n\n", "aSentId": 65671, "answer": "What is the intuition for this theorem? Is there a simple example of L for a certain axiom system?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65672, "question": "What is the intuition for this theorem? Is there a simple example of L for a certain axiom system?", "aSentId": 65673, "answer": "[What follows isn't very rigorous, if you need a formal proof look elsewhere]\n\nI like to think of the above theorem as following from the halting problem. If you want to prove a string S has complexity greater than L, you can run all programs with length less than L, and show that none of them output S. But it's impossible to know which of those programs we need to run, as we don't know which will halt. Any small program P that you can't prove anything about could ouput S, so you don't know S has high complexity. Just choose L &gt; |P|, and then any large string just might have complexity less than L.\n\nWhich brings us to your desired approximation algorithm. Long random strings will have high complexity, so the algorithm will give a large estimate. But since its complexity could be less than L, we can't prove anything about the accuracy of the approximation.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65674, "question": "[What follows isn't very rigorous, if you need a formal proof look elsewhere]\n\nI like to think of the above theorem as following from the halting problem. If you want to prove a string S has complexity greater than L, you can run all programs with length less than L, and show that none of them output S. But it's impossible to know which of those programs we need to run, as we don't know which will halt. Any small program P that you can't prove anything about could ouput S, so you don't know S has high complexity. Just choose L &gt; |P|, and then any large string just might have complexity less than L.\n\nWhich brings us to your desired approximation algorithm. Long random strings will have high complexity, so the algorithm will give a large estimate. But since its complexity could be less than L, we can't prove anything about the accuracy of the approximation.", "aSentId": 65675, "answer": "I'm not entirely sure this question makes sense because I have a very weak background in theoretical CS: Wouldn't for practical purposes only programs be of interest which run in finite time, thus the bounded halting problem would apply which is computable in NP-C?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65676, "question": "I'm not entirely sure this question makes sense because I have a very weak background in theoretical CS: Wouldn't for practical purposes only programs be of interest which run in finite time, thus the bounded halting problem would apply which is computable in NP-C?", "aSentId": 65677, "answer": "Halting's a slight aside, you can work out a paradox anyway. Any approximation to the Kolmogorov complexity must be arbitrarily crap.\n\nConsider the program ```P``` that finds a program of complexity ```&gt;|P|``` as follows (supposing we have some approximation function ```C```).\n\n    fun P C U n = if C(n) &gt; U then n else P C U (n+1)\n\nwhere ```U``` is an upper bound on the length of ```P```. This is a total function (if ```C``` is a decent approximation) by the existence of a string of K-complexity ```&gt;n``` for any ```n```).\n\nAnyway it prints something of Kolmogorov complexity greater than it should be able to. By picking a worse estimate of |P| you can make it arbitrarily crap. There are slight problems due to the informal definition I've given, but it can be worked out.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65668, "question": "Kolmogorov Complexity", "aSentId": 65679, "answer": "It's uncomputable in general, and any reasonable guarantee will be uncomputable as well. Without knowing what problem you're trying to solve, I'd suggest just using standard compression routines...", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65668, "question": "Kolmogorov Complexity", "aSentId": 65681, "answer": "i don't have an answer, but i just wanted to say, folks, they're asking for an **approximation**.  they know it's not feasible in general, and, from that, that any **approximation** will not always work.  that's already implicit in the question.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65683, "question": "Yes, the size of a compressed version of your string as a file, say with bzip2 or your favorite compressing software.", "aSentId": 65684, "answer": "But that is not analytic.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65686, "question": "What is the current status in artificial intelligence?", "aSentId": 65687, "answer": "We're working on it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65686, "question": "What is the current status in artificial intelligence?", "aSentId": 65689, "answer": "it isn't ready yet", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65686, "question": "What is the current status in artificial intelligence?", "aSentId": 65691, "answer": "By using slightly fancy statistics and huge amounts of data and processing power, you can get some pretty fun toys.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65695, "question": "Unsure on what approach to use for knn", "aSentId": 65696, "answer": "What are the data types? Are you using 3D vectors of ints, floats, or doubles?\n\nAlso what CPU?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65697, "question": "What are the data types? Are you using 3D vectors of ints, floats, or doubles?\n\nAlso what CPU?", "aSentId": 65698, "answer": "All of the data types are 3D vectors of floats. As of right now I'm using an i7 4790K. I was considering using AVX, but using AVX on a KD tree doesn't seem all too useful unless I did breadth first which might create issues in the long run ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65699, "question": "All of the data types are 3D vectors of floats. As of right now I'm using an i7 4790K. I was considering using AVX, but using AVX on a KD tree doesn't seem all too useful unless I did breadth first which might create issues in the long run ", "aSentId": 65700, "answer": "So you have 2500 * 12 / 1024 ~ 30KB for your labelled set which will easily fit in L3 and even L2 cache.\n\nStore your query set in one continuous block of memory. Then spawn `nproc` threads to iterate over equally sized chuck of the query set. \n\nYou can you use K-d tree to find the nearest point but he tree probably won't fit into l2 cache because of the extra book keeping data required. The kD tree may also confuse the branch prediction because there's a 50/50 chance at each level of the tree to go left or right. So even though lookup in the kD tree will only take ~12 operations the constant factor could be large because of cache and branching effects. \n\nThis means brute force + AVX may yield better results since you can compute  16  inner products per core every few clock cycles. This means brute force will require ~128 operations per element but the constant factor will be less because of caching, memory access patterns, and better branch prediction since the `current_inner_product &gt; max_inner_product` will only trip a few times. \n\nEither way test both and see what gives the best results on a subset of the query set of ~ 1 million points. Don't discount brute force though. I've used it for the binary nearest neighbour problems and it gives better results then using a kD-tree. Since your dimensions are small and fit in AVX registers you may find that you get better results for brute force. If you have a GPU and can use CUDA brute force will definitely be better. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65701, "question": "So you have 2500 * 12 / 1024 ~ 30KB for your labelled set which will easily fit in L3 and even L2 cache.\n\nStore your query set in one continuous block of memory. Then spawn `nproc` threads to iterate over equally sized chuck of the query set. \n\nYou can you use K-d tree to find the nearest point but he tree probably won't fit into l2 cache because of the extra book keeping data required. The kD tree may also confuse the branch prediction because there's a 50/50 chance at each level of the tree to go left or right. So even though lookup in the kD tree will only take ~12 operations the constant factor could be large because of cache and branching effects. \n\nThis means brute force + AVX may yield better results since you can compute  16  inner products per core every few clock cycles. This means brute force will require ~128 operations per element but the constant factor will be less because of caching, memory access patterns, and better branch prediction since the `current_inner_product &gt; max_inner_product` will only trip a few times. \n\nEither way test both and see what gives the best results on a subset of the query set of ~ 1 million points. Don't discount brute force though. I've used it for the binary nearest neighbour problems and it gives better results then using a kD-tree. Since your dimensions are small and fit in AVX registers you may find that you get better results for brute force. If you have a GPU and can use CUDA brute force will definitely be better. ", "aSentId": 65702, "answer": "Awesome. I'll try and report back here if I have any questions after implementing it ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65701, "question": "So you have 2500 * 12 / 1024 ~ 30KB for your labelled set which will easily fit in L3 and even L2 cache.\n\nStore your query set in one continuous block of memory. Then spawn `nproc` threads to iterate over equally sized chuck of the query set. \n\nYou can you use K-d tree to find the nearest point but he tree probably won't fit into l2 cache because of the extra book keeping data required. The kD tree may also confuse the branch prediction because there's a 50/50 chance at each level of the tree to go left or right. So even though lookup in the kD tree will only take ~12 operations the constant factor could be large because of cache and branching effects. \n\nThis means brute force + AVX may yield better results since you can compute  16  inner products per core every few clock cycles. This means brute force will require ~128 operations per element but the constant factor will be less because of caching, memory access patterns, and better branch prediction since the `current_inner_product &gt; max_inner_product` will only trip a few times. \n\nEither way test both and see what gives the best results on a subset of the query set of ~ 1 million points. Don't discount brute force though. I've used it for the binary nearest neighbour problems and it gives better results then using a kD-tree. Since your dimensions are small and fit in AVX registers you may find that you get better results for brute force. If you have a GPU and can use CUDA brute force will definitely be better. ", "aSentId": 65704, "answer": "Honestly the only way I can describe my results is that I'm baffled how much faster CUDA was at this. It speed up KNN nearly 20X when compared to ANN-C++\n\n:D", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65708, "question": "What is a \"no-regret learning algorithm\"? The definitions I find are so fuzzy.", "aSentId": 65709, "answer": "Perhaps you could share the fuzzy definitions you have found, otherwise risking someone posting something that you have already found to be unhelpful.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65710, "question": "Perhaps you could share the fuzzy definitions you have found, otherwise risking someone posting something that you have already found to be unhelpful.", "aSentId": 65711, "answer": "Absolutely. Here is what I have heard or read:\n\n* \n\n &gt; Small regret in hindsight\n\n -\n\n &gt; You'd like to compete with the best single strategy in hindsight.\n\n Hindsight seems to be the central thing here, but I have no idea what is meant by it. :-)\n\n* \n\n &gt; No matter what process is generating the time series, your algorithm will look good compared to the best thing in some comparator class.\n\n I suppose that \"looking good\" is something else than actually being good, because if they were the same, this description of no-regret learning seems to be that you should simply be better than everyone else, which of course what we always want and which doesn't seem to warrant the special term _no-regret_.\n\n* \n\n &gt; A learning algorithm is said\nto exhibit no-regret iff average payoffs that are\nachieved by the algorithm exceed the payoffs\nthat could be achieved by any fixed strategy in\nthe limit.\n\n This sounds more like a proper definition, but it is unclear what a \"fixed\" strategy is.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65712, "question": "Absolutely. Here is what I have heard or read:\n\n* \n\n &gt; Small regret in hindsight\n\n -\n\n &gt; You'd like to compete with the best single strategy in hindsight.\n\n Hindsight seems to be the central thing here, but I have no idea what is meant by it. :-)\n\n* \n\n &gt; No matter what process is generating the time series, your algorithm will look good compared to the best thing in some comparator class.\n\n I suppose that \"looking good\" is something else than actually being good, because if they were the same, this description of no-regret learning seems to be that you should simply be better than everyone else, which of course what we always want and which doesn't seem to warrant the special term _no-regret_.\n\n* \n\n &gt; A learning algorithm is said\nto exhibit no-regret iff average payoffs that are\nachieved by the algorithm exceed the payoffs\nthat could be achieved by any fixed strategy in\nthe limit.\n\n This sounds more like a proper definition, but it is unclear what a \"fixed\" strategy is.", "aSentId": 65713, "answer": "So this appears to be some reinforcement learning thing, I'm not sure how familiar you are with this stuff so I will also quickly cover the basics by way of example.\n\nBasically suppose you are playing a gameshow where there are 4 (this number was chosen arbitrarily, it could be any number or infinite) doors and many rounds. At each round you get to pick one door and receive a prize. During each round the various prizes are swapped in some way. In this setting we could imagine an \"oracle\" that knows exactly whats behind every door in every round, but can only select one door and has to stick to it for all the rounds. You on the other hand don't know whats behind the doors but can adapt your strategy and change doors. A typical reinforcement learning bound says that amount of money the oracle makes compared to you increases as a square root compared to the number of rounds, this is \"regret.\"\n\n But if we suppose that your strategy happens to be really good compared to how they are mixing up the prizes then you can actually do better than the oracle and thus have zero or negative regret (you make more money than the oracle). For example if the order of the best prize for each round is 1,2,3,4,1,2,3,4,1,2,..., then maybe you happened to choose a strategy which nails that pattern and gets the best prize each time, where the oracle is stuck getting the best prize only every fourth round.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65714, "question": "So this appears to be some reinforcement learning thing, I'm not sure how familiar you are with this stuff so I will also quickly cover the basics by way of example.\n\nBasically suppose you are playing a gameshow where there are 4 (this number was chosen arbitrarily, it could be any number or infinite) doors and many rounds. At each round you get to pick one door and receive a prize. During each round the various prizes are swapped in some way. In this setting we could imagine an \"oracle\" that knows exactly whats behind every door in every round, but can only select one door and has to stick to it for all the rounds. You on the other hand don't know whats behind the doors but can adapt your strategy and change doors. A typical reinforcement learning bound says that amount of money the oracle makes compared to you increases as a square root compared to the number of rounds, this is \"regret.\"\n\n But if we suppose that your strategy happens to be really good compared to how they are mixing up the prizes then you can actually do better than the oracle and thus have zero or negative regret (you make more money than the oracle). For example if the order of the best prize for each round is 1,2,3,4,1,2,3,4,1,2,..., then maybe you happened to choose a strategy which nails that pattern and gets the best prize each time, where the oracle is stuck getting the best prize only every fourth round.", "aSentId": 65715, "answer": "In your example, the oracle must choose the same door every time. Is that what they mean by _fixed_, you think? Another possibility that I considered was that \"fixed\" meant _given_, _i.e._ that they were given already in the statement of the problem.\n\nIs the term _regret_ applicable only when you compare yourself to a strategy that is \"fixed\" in some sense, or can you use it whenever there is a competing strategy?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65716, "question": "In your example, the oracle must choose the same door every time. Is that what they mean by _fixed_, you think? Another possibility that I considered was that \"fixed\" meant _given_, _i.e._ that they were given already in the statement of the problem.\n\nIs the term _regret_ applicable only when you compare yourself to a strategy that is \"fixed\" in some sense, or can you use it whenever there is a competing strategy?", "aSentId": 65717, "answer": "&gt;In your example, the oracle must choose the same door every time. Is that what they mean by fixed, you think? \n\nThat is exactly what is meant by fixed, unless you are looking at some sort of new theoretical setting I haven't heard of. The \"fixed\" setting is the classic and commonly studied setting for an oracle. There are others, but I'm fairly sure this is the setting you are looking at.\n\n&gt;Is the term regret applicable only when you compare yourself to a strategy that is \"fixed\" in some sense, or can you use it whenever there is a competing strategy?\n\nYou have to put some restrictions on the behavior of the oracle to get any sort of interesting theoretical bounds.\n\nIf we let the oracle do whatever it wanted you can't really get any sort of (interesting) theoretical result; the door pattern could be totally crazy and random and we couldn't reasonably hope to do as well as the oracle. Alternatively, suppose that the pattern is really crazy, but we have a fixed oracle, then the oracle would also do bad because it is restricted to only having the same choice each round. If the best prize is behind door 1 every time, then we would eventually latch onto that pattern and, although we might not have gotten the correct door the first few rounds, we are now doing as well as the oracle for the rest of the game. Fixing the oracle basically induces your strategy to one like \"if we see the best prize behind door 1 for twenty turns in a row, we should probably choose door 1.\" \n\nThere are other, less common, oracle settings that are also studied. Maybe you only let the oracle change every 20 turns, then you would be comparing to a setting where \"the door pattern changes, but only occasionally\". Also you could only let the oracle change the door value by one each round, which would correspond with \"the pattern changes constantly, but only by a little bit.\"", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65708, "question": "What is a \"no-regret learning algorithm\"? The definitions I find are so fuzzy.", "aSentId": 65719, "answer": "Sure, I can explain it formally.\n\nEvery day for T days, you will make a decision \"h\" (usually called a \"hypothesis\"). It can be a different decision each day. Then, nature will choose something \"x\" to happen that day (often called the data point). You then suffer some loss as a function of h and x.\n\nNow, at the end of the T days, you have some total loss that you suffered, calculated by adding up over all T days the loss you experienced on that day.\n\nHere's where regret comes in. There's some set of possible decisions you could have taken. You might ask yourself, what if I had just done the same thing every day? What would my loss be then? Well, for any fixed hypothesis h, you can calculate that by summing up the loss of h and x for every x over all the days.\n\nIf this value is smaller than the loss you actually experienced, then you have *regret* defined as the difference between these two total losses. Because you could have just chosen h every single day and done better than you actually did.\n\nGenerally, we speak of the regret as being the maximum of the above value over all possible hypotheses you could have chosen in hindsight.\n\nNow, here's where \"no regret\" comes in. Suppose that every possible loss is between 0 and 1. So your total loss is between 0 and T. For some class of hypotheses and loss function, if your algorithm guarantees that for *every possible data sequence*, your regret is o(T), that is considered pretty good: As T goes to infinity, your *average* regret per day is going to zero (because your regret is o(T) and there are T days).\n\nA final point is that it's not really formally defined until you define the set of allowable hypotheses, the set of allowable data points, and the loss function. Let me know if I can clarify any of this further.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65720, "question": "Sure, I can explain it formally.\n\nEvery day for T days, you will make a decision \"h\" (usually called a \"hypothesis\"). It can be a different decision each day. Then, nature will choose something \"x\" to happen that day (often called the data point). You then suffer some loss as a function of h and x.\n\nNow, at the end of the T days, you have some total loss that you suffered, calculated by adding up over all T days the loss you experienced on that day.\n\nHere's where regret comes in. There's some set of possible decisions you could have taken. You might ask yourself, what if I had just done the same thing every day? What would my loss be then? Well, for any fixed hypothesis h, you can calculate that by summing up the loss of h and x for every x over all the days.\n\nIf this value is smaller than the loss you actually experienced, then you have *regret* defined as the difference between these two total losses. Because you could have just chosen h every single day and done better than you actually did.\n\nGenerally, we speak of the regret as being the maximum of the above value over all possible hypotheses you could have chosen in hindsight.\n\nNow, here's where \"no regret\" comes in. Suppose that every possible loss is between 0 and 1. So your total loss is between 0 and T. For some class of hypotheses and loss function, if your algorithm guarantees that for *every possible data sequence*, your regret is o(T), that is considered pretty good: As T goes to infinity, your *average* regret per day is going to zero (because your regret is o(T) and there are T days).\n\nA final point is that it's not really formally defined until you define the set of allowable hypotheses, the set of allowable data points, and the loss function. Let me know if I can clarify any of this further.", "aSentId": 65721, "answer": "Thank you. So, is the term _regret_ used specifically when you compare your own strategy to one that is constant (_i.e._ makes the same decision every day)? If so, what makes these constant strategies special that they motivate a special term (instead of something plain like _performance difference_)?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65722, "question": "Thank you. So, is the term _regret_ used specifically when you compare your own strategy to one that is constant (_i.e._ makes the same decision every day)? If so, what makes these constant strategies special that they motivate a special term (instead of something plain like _performance difference_)?", "aSentId": 65723, "answer": "Yes, usually you define regret either with respect to either a particular fixed decision, or the best fixed decision.\n\nOne point is that if you ask for the best possible strategy in hindsight that can change, then this is kind of impossibly hard to match: You just can look back at each day and that day's data x, and suppose you had known in advance x was coming and picked the best decision for that x. That seems way too much to expect.\n\nI like the driving routes example that someone else mentioned. It makes sense to look back and say, oh, if I had just driven route B every day all year I would have had a smaller average commute time. So I regret not just sticking with B. But it doesn't make as much sense to look back and say, oh, every day I should have been able to anticipate all the traffic details for that particular day and picked the best route for that particular day.\n\nAs for why the term regret, I think the point is that it's a comparison \"in hindsight\". So you have different term than regret if you see all the past days' data and want to make a prediction for a new day.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65708, "question": "What is a \"no-regret learning algorithm\"? The definitions I find are so fuzzy.", "aSentId": 65725, "answer": "Let's say every day for T days you choose one of N routes to travel to work.  Your choice on day t is a probability distribution p^t over the N routes.\n\nAfter you've completed your travel on day t, you observe a length N loss vector l^(t).  The ith component of l^t is the time it would have taken to get to work given you chose route i.  Let's assume each element is bounded between 0 and 1.\n\nThe total time it took you to travel to work is sum_t sum_i p^(t)(i) l^(t)(i), the expected loss of your policy.\n\nThe total time it would have taken you if you chose route i^* at each time step is sum_t l^(t)(i^(*)).\n\nYour expected regret for having not taken i^* is the extra loss you incurred by following your own policy:  sum_t (sum_i p^(t)(i)l^(t)(i)) - p^(t)(i^(*))\n\nThe overall expected regret is your expected regret against the best route in hindsight:\n\nR^T = max_{i^(*)} sum_t (sum_i p^(t)(i)l^(t)(i)) - p^(t)(i^(*))\n\nIf for all sequences l^t we can bound R^T by a function sublinear in T we say our decision making algorithm is \"no-regret\".  This means that on average our online algorithm is guaranteed to do almost as well as if we knew the cumulative losses ahead-of-time.\n\nedit: superscripts", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65726, "question": "Let's say every day for T days you choose one of N routes to travel to work.  Your choice on day t is a probability distribution p^t over the N routes.\n\nAfter you've completed your travel on day t, you observe a length N loss vector l^(t).  The ith component of l^t is the time it would have taken to get to work given you chose route i.  Let's assume each element is bounded between 0 and 1.\n\nThe total time it took you to travel to work is sum_t sum_i p^(t)(i) l^(t)(i), the expected loss of your policy.\n\nThe total time it would have taken you if you chose route i^* at each time step is sum_t l^(t)(i^(*)).\n\nYour expected regret for having not taken i^* is the extra loss you incurred by following your own policy:  sum_t (sum_i p^(t)(i)l^(t)(i)) - p^(t)(i^(*))\n\nThe overall expected regret is your expected regret against the best route in hindsight:\n\nR^T = max_{i^(*)} sum_t (sum_i p^(t)(i)l^(t)(i)) - p^(t)(i^(*))\n\nIf for all sequences l^t we can bound R^T by a function sublinear in T we say our decision making algorithm is \"no-regret\".  This means that on average our online algorithm is guaranteed to do almost as well as if we knew the cumulative losses ahead-of-time.\n\nedit: superscripts", "aSentId": 65727, "answer": "There are quite a few runaway superscripts in here, and I'm afraid it makes the exposition difficult to follow.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65729, "question": "\"No regret\" just means that if you make a guess, and it's wrong, you don't refine your fitness function or network. With neural nets, you usually strengthen a connection when it leads to a correct guess, and weaken it when you make an incorrect guess.\n\nIn problems where there's a very small probability of random success, you don't want to demote something that's made some good guesses just because it mostly makes bad guesses, since everything is making bad guesses. An alternative is to weight the demotion based on how common bad guesses are globally, but this is often less efficient than using a no-regret algorithm until you've improved the quality of your guessing to the point where regret isn't hiding successful refinements.\n\nTo use the example of neural networks, they work very well when the activation threshold is near the center of the sigmoid function, but if you're way off on the negative end, you'll never get activated, so you won't promote helpful connections. Similarly, if you're way off on the positive end, you may want to use an only-regret algorithm to get you closer to the center before you switch to a more conventional algorithm that both promotes success and demotes failure.\n\nSome algorithms are naturally no-regret, and others can be made to be no-regret simply by turning off negative feedback. That may be the source of some of the confusion in the definitions you've been reading.", "aSentId": 65730, "answer": "&gt; \"No regret\" just means that if you make a guess, and it's wrong, you don't refine your fitness function or network. \n\nActually, that seems to be an interpretation that is entirely different interpretation from what I'm getting from the rest of this thread. Others talk about comparing to one or more competing predictor algorithms.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65731, "question": "&gt; \"No regret\" just means that if you make a guess, and it's wrong, you don't refine your fitness function or network. \n\nActually, that seems to be an interpretation that is entirely different interpretation from what I'm getting from the rest of this thread. Others talk about comparing to one or more competing predictor algorithms.", "aSentId": 65732, "answer": "That's how it's usually used. Competing predictor algorithms are functionally equivalent to certain kinds of networks though. It's pretty common after training and pruning a learning network to end up with several clusters that are strongly connected locally, but weakly connected to each other. They compete to generate the strongest prediction for the entire network.\n\nI think the reason that \"no regret\" learning isn't used much in neural networks is that it's usually only done as a precursor to the main event. Once you have a somewhat well-tuned neural network, you want to keep applying the usual back-propagation for both success and failure to refine it further. Avoiding demotion entirely in the early stages doesn't really get you anything in terms of optimal results that you can't get with more iterations of your normal training. It's just a shortcut to saving computation time when you're identifying which connections you want to use in the network you start training normally, if you're dealing with what will ultimately be a sparse network. If you expect the end result to be a dense network, there's no point in this pre-training step, because it may actually start you further from optimal if it fails to promote important inputs that you then prune.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65734, "question": "Web Based Finite State Machine Designer", "aSentId": 65735, "answer": "I found out about this site last semester, but never thought about posting it here until I saw a question about DFAs. I've found it to be pretty useful - especially the LaTeX export, since my Automata professor wouldn't accept any hand written work.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65736, "question": "I found out about this site last semester, but never thought about posting it here until I saw a question about DFAs. I've found it to be pretty useful - especially the LaTeX export, since my Automata professor wouldn't accept any hand written work.", "aSentId": 65737, "answer": "I have yet to have a math/CS theory professor that doesn't accept handwritten work. How common is this?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65738, "question": "I have yet to have a math/CS theory professor that doesn't accept handwritten work. How common is this?", "aSentId": 65739, "answer": "My Automata professor makes us upload our homework. Whether or not that is just a scanned copy of handwritten work doesn't matter, but if I'm going to go through the annoyance of scanning it, I'll just type it up in the first place.\n\nNot to mention that LaTeX just looks gorgeous. One of my math professors said that regardless of the correctness of the answers, homework written in LaTeX just *looks* correct.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65738, "question": "I have yet to have a math/CS theory professor that doesn't accept handwritten work. How common is this?", "aSentId": 65741, "answer": "So far I think only my automata theory teacher explicitly said she wouldn't accept hand written work, but my AI teacher requires that work be submitted as a PDF. While it's possible to scan or take a picture of hand written work and convert to PDF, I think she prefers it done on computer.\n\nI can understand not wanting to try to decipher DFAs, graphs, trees, propositional logic, etc written in pencil.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65742, "question": "So far I think only my automata theory teacher explicitly said she wouldn't accept hand written work, but my AI teacher requires that work be submitted as a PDF. While it's possible to scan or take a picture of hand written work and convert to PDF, I think she prefers it done on computer.\n\nI can understand not wanting to try to decipher DFAs, graphs, trees, propositional logic, etc written in pencil.", "aSentId": 65743, "answer": "I actually used that tool in my theoretical foundations of computation class. If I made a mistake, it was much more forgiving than the pencil and eraser.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65738, "question": "I have yet to have a math/CS theory professor that doesn't accept handwritten work. How common is this?", "aSentId": 65745, "answer": "Since compsci theory courses in first year at UofT for me, all assignments have been pdf format only. Math still takes handwritten.  ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65747, "question": "My first big job interview!", "aSentId": 65748, "answer": "I have some advice for you, but its not really about technical or computing, just some stuff I've learned during my working years about good things to do during an interview (and especially a phone interview, since you won't have visual cues to help). \n\n* DO make sure you understand the question before you begin to answer. Its a good idea to ask the interviewer to clarify things if there is something you thought was ambiguous or confusing. \n* DO ask the interviewer if you have answered the question. This is really common in all kinds of business communication and its a good habit to get into. After you finish giving your response, you can ask something like \"does that answer your question?\". You don't have to ask this after literally every question (especially not the simple or trivial ones), but it is a good idea to ask after you finish answering a more complicated question.\n* DO have questions of your own for the interviewer. Almost always you'll be given an opportunity to ask these questions at some point during the interview (often right at the beginning, and again at the end). Its a good idea to ask questions about what kind of work you'll be doing in the role, and maybe some other polite questions about the business and company culture.\n* DON'T worry about being nervous. Its normal and natural and the interviewer will (hopefully) be sympathetic to that. If you feel stuck or confused, just talk it out and let the interviewer know what your thought process is like. Even if you can't answer the question you'll still help the interviewer get to know what your problem solving technique is like. Don't just freeze and say nothing.\n* DON'T ask about salary stuff yet. There will be a time and place for that if everything goes well, but the technical phone interview is not the place for that. Hold your horses on the money stuff until you know the company wants to hire you and is ready to start negotiating. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65747, "question": "My first big job interview!", "aSentId": 65750, "answer": "COBOL lol.\n\nI don't know how many jobs you applied to, but you should apply for more. Coding interviews are random as hell, you might get a question in an area you're bad at, or just a bad interviewer, you might just have an off day. If you mess up or don't get the questions, don't blame yourself, I think very few people do well on their first interviews. Especially if they do Google-style \"whiteboard\" interviews, for something like that you really just need to practice on a whiteboard, even real coding experience won't help you in those types of interviews.\n\nAnyways don't worry too much, they're probably desperate for people, and if they actually read your resume then they already know you're a fresh grad and decided to interview you anyways. If they ask you for salary don't tell them anything, just let them offer what they intended to offer, no reason to low-ball them just because you don't know any better.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65747, "question": "My first big job interview!", "aSentId": 65752, "answer": "I'd bone up on your algorithms.  In  my last job interviews they asked for me to write a simple console based poker game, where cards are dealt off the top of a randomized deck etc.  I would be prepared for those sort of questions.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65754, "question": "Trying to understand fork() and Copy-on-Write (COW)", "aSentId": 65755, "answer": "fork() creates a a child process that is a duplicate of the calling process (the parent).  They are distinguish by PID.  In a traditional fork this means copying the memory in use by the parent when creating the child.  This can be quite expensive, especially for large processes.\n\nCopy-On-Write avoids this expense by being lazy.  Rather than copy all the memory at once it pretends it was copied and only actually copies when the parent and child need to hold different values at the same address.  The child is presented with a view of memory by having the virtual memory segments backed by the same physical memory as the parent.  If either process writes to memory the parent retains the physical page and the child is given a new one with the correct value stored.\n\n&gt; In COW, when a fork call is made, it creates a child process that has pointers to the parent's frames in memory so as to not create redundant data. In this case, it reduces copying. Is this correct?\n\nCOW happens below the abstraction of pointers in the virtual memory system.  Since fork() is a system call the work is done by the OS kernel, outside the programmer's hands.  Processes are given virtual memory space by the kernel, numbered 0 through 2^64 (these days).  Each process can't write to memory address 0 to start their space or they would all write to the same addresses and overwrite each other.  So the kernel creates virtual memory pages and maps them to physical addresses.  When a process asks for address 0 that is translated to a physical address and retrieved.  That translation happens outside the process memory space, so as far as your program is concerned it isn't taking place.  All the pointers in your program still only point to memory inside your process address space.  COW is done by the kernel in the background by using the same physical page for both parent and child.  If either writes to the memory a 2nd page is allocated so both versions can be stored.\n\nCOW is the clever way to reduce copying memory on fork() by using the abstraction of virtual memory.  It's worth noting there are now filesystems and databases that use the same abstraction to handle graceful rollbacks and data guarantees.  Before COW was a common OS ability the classic unix way to avoid the expense of fork() was to only fork() tiny processes.  If you look at daemons that fork to handle incoming connections the actual amount of code is pretty minimal.\n\n&gt;I have come to the understanding that when a fork() command is called, the child process executes an exec() call and abandons the copied memory\n\nfork-exec is for executing new programs but it isn't required.  It involves calling fork and then the child calling exec to start a new (different) program.  It's how shells actually run commands.  If you just call fork you end up with 2 processes running the same program (which is actually more useful than it sounds.  Lots of daemons fork on connection, the child handles the connection and then dies).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65756, "question": "fork() creates a a child process that is a duplicate of the calling process (the parent).  They are distinguish by PID.  In a traditional fork this means copying the memory in use by the parent when creating the child.  This can be quite expensive, especially for large processes.\n\nCopy-On-Write avoids this expense by being lazy.  Rather than copy all the memory at once it pretends it was copied and only actually copies when the parent and child need to hold different values at the same address.  The child is presented with a view of memory by having the virtual memory segments backed by the same physical memory as the parent.  If either process writes to memory the parent retains the physical page and the child is given a new one with the correct value stored.\n\n&gt; In COW, when a fork call is made, it creates a child process that has pointers to the parent's frames in memory so as to not create redundant data. In this case, it reduces copying. Is this correct?\n\nCOW happens below the abstraction of pointers in the virtual memory system.  Since fork() is a system call the work is done by the OS kernel, outside the programmer's hands.  Processes are given virtual memory space by the kernel, numbered 0 through 2^64 (these days).  Each process can't write to memory address 0 to start their space or they would all write to the same addresses and overwrite each other.  So the kernel creates virtual memory pages and maps them to physical addresses.  When a process asks for address 0 that is translated to a physical address and retrieved.  That translation happens outside the process memory space, so as far as your program is concerned it isn't taking place.  All the pointers in your program still only point to memory inside your process address space.  COW is done by the kernel in the background by using the same physical page for both parent and child.  If either writes to the memory a 2nd page is allocated so both versions can be stored.\n\nCOW is the clever way to reduce copying memory on fork() by using the abstraction of virtual memory.  It's worth noting there are now filesystems and databases that use the same abstraction to handle graceful rollbacks and data guarantees.  Before COW was a common OS ability the classic unix way to avoid the expense of fork() was to only fork() tiny processes.  If you look at daemons that fork to handle incoming connections the actual amount of code is pretty minimal.\n\n&gt;I have come to the understanding that when a fork() command is called, the child process executes an exec() call and abandons the copied memory\n\nfork-exec is for executing new programs but it isn't required.  It involves calling fork and then the child calling exec to start a new (different) program.  It's how shells actually run commands.  If you just call fork you end up with 2 processes running the same program (which is actually more useful than it sounds.  Lots of daemons fork on connection, the child handles the connection and then dies).", "aSentId": 65757, "answer": "COW may also (depending on workload) increase performance not by eliminating copying but simply by spreading it out over time, decreasing the maximum bandwidth of whatever type required.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65754, "question": "Trying to understand fork() and Copy-on-Write (COW)", "aSentId": 65759, "answer": "your assumption is correct. In general, only memory that is written to after the `fork()` needs to be copied. There is also `vfork()` which does not have COW semantics, instead both parent and child operate on the same address space. Be careful with `vfork()`.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65761, "question": "Proving that there is no DFA for a given language?", "aSentId": 65762, "answer": "This is one of those really interesting cases where seemingly similar problems actually fall in completely different classes. The reason the second example has a DFA is that the number of 01's and the number of 10's cannot differ by more than one (think about it - in order to get more of the one, you have to insert the other too). So you can work away the difference of 1 and then decide on equal numbers of 01 and 10, which is easy. The first example on the other hand is obviously not regular, you can use the pumping lemma or just remember that DFAs cannot count arbitrarily high.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65761, "question": "Proving that there is no DFA for a given language?", "aSentId": 65764, "answer": "Here's an intuitive argument as to why the first can't have a DFA: suppose it did, and that DFA had `n` states.  Now by the pidgeonhole principle, there must be numbers `i` and `j` with `i != j` and so that `a^i` and `a^j` bring the automaton in the same state.  Note that the automaton will accept `a^i^b^i` and `a^jb^j` (by how the language is defined).  But since after consuming `a^i` it is in the same state as consuming `a^j`, it will also accept `a^jb^i`, which is not in the language, which contradicts our assumption.\n\n(I suspect that this is a special case of the solution /u/Triple_Elation gives.)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65761, "question": "Proving that there is no DFA for a given language?", "aSentId": 65766, "answer": "You demonstrate there is no automaton by demonstrating there is no automaton. There is no special trick to doing it. However, the pumping lemma is often useful in this endeavor, and you *can* employ it here as well.\n\nThe latter language is regular because it is equal to the regular expression  \n&gt; {\u03b5} U **(**{0} \u00b7 {0,1}* \u00b7 {0}**)** U **(**{1} \u00b7 {0,1}* \u00b7 {1}**)** .", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65769, "question": "I'm hoping this isn't a homework question and you're genuinely curious. \n\nIf you align your states vertically and start at q\\_0 (which also happens to be the final state), you can let q\\_1, q\\_2 be the states with 1 and 2 more 1's than 0's respectively. Similarly q\\_-1 and q\\_-2 will be the states where you have 1 and 2 more 0's than 1's respectively.\n\nNow to accept the string 1^2 0^2, you'll need up to state q\\_2. To accept 1^3 0^3 you'll need up to q\\_3. You can say without loss of generality to accept 1^n 0^n you'll need a q\\_n state. This DFA won't be able to accept 1^n+1 0^n+1.\n\nSo by the logic of mathematical induction you can say that for any finite DFA you can find a bigger string that the DFA won't accept. So a finite DFA just won't cut it. Although a better proof would be to use the pumping lemma, since the existence of a DFA for a language and the fact that a language is regular are equivalent statements.", "aSentId": 65770, "answer": "What you should have said is that you need *at least* n states in an automaton that recognises the string 1^(n)0^(n), therefore any automaton does not recognise the string 1^(q+1)0^(q+1) where q is its number of states, and hence does not recognise the language  \n{1^(n)0^(n) | n in N} .\n\nBut of course you did not prove this because inductive reasoning is fallacious (and not to be confused with mathematical induction).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65771, "question": "What you should have said is that you need *at least* n states in an automaton that recognises the string 1^(n)0^(n), therefore any automaton does not recognise the string 1^(q+1)0^(q+1) where q is its number of states, and hence does not recognise the language  \n{1^(n)0^(n) | n in N} .\n\nBut of course you did not prove this because inductive reasoning is fallacious (and not to be confused with mathematical induction).", "aSentId": 65772, "answer": "I'm not sure I follow your argument. A DFA that accepts 1^n 0^n from this language will have 2n+1 states because you will need to accept 0^n 1^n as well. Assuming you mean q=|Q| isn't q+1 too large a number? I mean it works but it doesn't help prove the point clearly.\n\nEdit: When I said inductive reasoning I meant following the logic of mathematical induction. Maybe I should change the phrasing in my first post.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65773, "question": "I'm not sure I follow your argument. A DFA that accepts 1^n 0^n from this language will have 2n+1 states because you will need to accept 0^n 1^n as well. Assuming you mean q=|Q| isn't q+1 too large a number? I mean it works but it doesn't help prove the point clearly.\n\nEdit: When I said inductive reasoning I meant following the logic of mathematical induction. Maybe I should change the phrasing in my first post.", "aSentId": 65774, "answer": "You reasoned (fallaciously) that an automaton that accepts 1^(n)0^(n) requires (n+1) states. (I wrote n above by mistake.) This is false because to any automaton you can add a state and still have it accept the same language, so you should have written that you need *at least* (n+1). That was my first point.\n\nThe second point, I was just clarifying your conclusion. Namely that any automaton won't accept a string of a certain size, viz. any string 1^(n)0^(n) where n is at least the number of the states of the automaton.\n\nOf course this is all moot since you did not establish the premise, namely that any automaton which recognises 1^(n)0^(n) must have at least (n+1) states.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65775, "question": "You reasoned (fallaciously) that an automaton that accepts 1^(n)0^(n) requires (n+1) states. (I wrote n above by mistake.) This is false because to any automaton you can add a state and still have it accept the same language, so you should have written that you need *at least* (n+1). That was my first point.\n\nThe second point, I was just clarifying your conclusion. Namely that any automaton won't accept a string of a certain size, viz. any string 1^(n)0^(n) where n is at least the number of the states of the automaton.\n\nOf course this is all moot since you did not establish the premise, namely that any automaton which recognises 1^(n)0^(n) must have at least (n+1) states.", "aSentId": 65776, "answer": "&gt; You reasoned (fallaciously) that an automaton that accepts 1n0n requires (n+1) states\n\nNope, I said that you need 2n+1 states. I'm not sure where you're getting n+1 from though I'd like to hear your reasoning behind it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65777, "question": "&gt; You reasoned (fallaciously) that an automaton that accepts 1n0n requires (n+1) states\n\nNope, I said that you need 2n+1 states. I'm not sure where you're getting n+1 from though I'd like to hear your reasoning behind it.", "aSentId": 65778, "answer": "You never said 2n+1 because really you never said any number of states only that you need \"a q_n state\" for 1^(n)0^(n) which is what you mentioned and what I mentioned, not 0^(n)1^(n). Numbered 0 through n that is n+1 states. Not sure why you keep bringing this up anyway, it is irrelevant.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65779, "question": "You never said 2n+1 because really you never said any number of states only that you need \"a q_n state\" for 1^(n)0^(n) which is what you mentioned and what I mentioned, not 0^(n)1^(n). Numbered 0 through n that is n+1 states. Not sure why you keep bringing this up anyway, it is irrelevant.", "aSentId": 65780, "answer": "No it's relevant to the correctness. You seemed pretty confident when calling out the inconsistencies so I was curious to know why. I see where you're coming from though so here's what you missed from the proof:\n\nMy naming convention is unconventional because it also goes to state q\\_-n, so n+1 states is entirely too small. It's always great to be on your toes for off-by-one errors though :)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65781, "question": "No it's relevant to the correctness. You seemed pretty confident when calling out the inconsistencies so I was curious to know why. I see where you're coming from though so here's what you missed from the proof:\n\nMy naming convention is unconventional because it also goes to state q\\_-n, so n+1 states is entirely too small. It's always great to be on your toes for off-by-one errors though :)", "aSentId": 65782, "answer": "The language that has the same number of 0s and 1s is not equal to the language {1^(n)0^(n) | n} U {0^(n)1^(n) | n}. I was indulging you by talking about 1^(n)0^(n) which is the string you bought up in the first place; you never mentioned 0^(n)1^(n). I left my psychic powers back home.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65783, "question": "The language that has the same number of 0s and 1s is not equal to the language {1^(n)0^(n) | n} U {0^(n)1^(n) | n}. I was indulging you by talking about 1^(n)0^(n) which is the string you bought up in the first place; you never mentioned 0^(n)1^(n). I left my psychic powers back home.", "aSentId": 65784, "answer": "Maybe if you actually read my comments you would have found it? Ctrl+F will do the trick. When you call someone out you can't just say \"that's wrong\", you have to prove it. I still think you have no idea what's going on.\n\nEdit: typo", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65785, "question": "Maybe if you actually read my comments you would have found it? Ctrl+F will do the trick. When you call someone out you can't just say \"that's wrong\", you have to prove it. I still think you have no idea what's going on.\n\nEdit: typo", "aSentId": 65786, "answer": "You're really not getting it at all are you. You reasoned using 1^(n)0^(n) which is why I used that to reply. If you assert that an automaton which recognises the *string* 1^(n)0^(n) has at least (n+1) states then you are wrong and that can easily be observed by the fact that a one state automaton recognises all strings. I was doing nothing but entertaining your idea to make a point. That is why it is 0^(n)1^(n) is irrelevant.\n\nThe only way you can reconcile that is by considering a language and not a string recognised (in which case 1^(n)0^(n) is more or less irrelevant as well) but your reasoning is still wrong because you induced from 2 and 3.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65787, "question": "You're really not getting it at all are you. You reasoned using 1^(n)0^(n) which is why I used that to reply. If you assert that an automaton which recognises the *string* 1^(n)0^(n) has at least (n+1) states then you are wrong and that can easily be observed by the fact that a one state automaton recognises all strings. I was doing nothing but entertaining your idea to make a point. That is why it is 0^(n)1^(n) is irrelevant.\n\nThe only way you can reconcile that is by considering a language and not a string recognised (in which case 1^(n)0^(n) is more or less irrelevant as well) but your reasoning is still wrong because you induced from 2 and 3.", "aSentId": 65788, "answer": "No it's you that doesn't get it. I know exactly what you're saying. _Sure_ it needs n+1 states. But it  is true for the same reason that it needs at least 1 state.\n\nEdit: What you have is not the greatest lower bound, just an arbitrary lower bound which doesn't do much to anything.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65789, "question": "No it's you that doesn't get it. I know exactly what you're saying. _Sure_ it needs n+1 states. But it  is true for the same reason that it needs at least 1 state.\n\nEdit: What you have is not the greatest lower bound, just an arbitrary lower bound which doesn't do much to anything.", "aSentId": 65790, "answer": "It needs at least (n+1) states means that (n+1) \u2264 (number of states). Since we are reasoning for arbitrary n it would mean that if we picked n := 3 then we would have that the automaton with one state which recognises any string and therefore the string 1^(3)0^(3) has at least four states, i.e. 4 \u2264 1.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65791, "question": "It needs at least (n+1) states means that (n+1) \u2264 (number of states). Since we are reasoning for arbitrary n it would mean that if we picked n := 3 then we would have that the automaton with one state which recognises any string and therefore the string 1^(3)0^(3) has at least four states, i.e. 4 \u2264 1.", "aSentId": 65792, "answer": "&gt; 4 \u2264 1\n\nWhat are you saying", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65773, "question": "I'm not sure I follow your argument. A DFA that accepts 1^n 0^n from this language will have 2n+1 states because you will need to accept 0^n 1^n as well. Assuming you mean q=|Q| isn't q+1 too large a number? I mean it works but it doesn't help prove the point clearly.\n\nEdit: When I said inductive reasoning I meant following the logic of mathematical induction. Maybe I should change the phrasing in my first post.", "aSentId": 65794, "answer": "Changing the phrasing does not matter. You can write \"by mathematical induction\" but you still used inductive reasoning.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65795, "question": "Changing the phrasing does not matter. You can write \"by mathematical induction\" but you still used inductive reasoning.", "aSentId": 65796, "answer": "Care to explain the difference then? I'm not going to let you make a statement without proving it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65797, "question": "Care to explain the difference then? I'm not going to let you make a statement without proving it.", "aSentId": 65798, "answer": "What is there to \"prove\"? You patently did not use mathematical induction. If you think you did then you need to reassess what you think that is. It is using (or is) the fact that  \n&gt; (An:: p(n)) &lt;=  p(0) \\^ (An:: p(n) =&gt; p(n+1)) .\n\nIt is *not* saying  it is true for 2, it is true for 3, therefore abracadabra and without loss of generality it is true for any natural number\".", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65799, "question": "What is there to \"prove\"? You patently did not use mathematical induction. If you think you did then you need to reassess what you think that is. It is using (or is) the fact that  \n&gt; (An:: p(n)) &lt;=  p(0) \\^ (An:: p(n) =&gt; p(n+1)) .\n\nIt is *not* saying  it is true for 2, it is true for 3, therefore abracadabra and without loss of generality it is true for any natural number\".", "aSentId": 65800, "answer": "I gave the idea of a proof. You seem to have an awfully high standard for meticulousness from other posters while you make bold claims without support on your own. That's not a healthy attitude to have.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65801, "question": "I gave the idea of a proof. You seem to have an awfully high standard for meticulousness from other posters while you make bold claims without support on your own. That's not a healthy attitude to have.", "aSentId": 65802, "answer": "There is nothing meticulous about it. Your reasoning was wrong. I'd like to see you try to prove your premise without the use of the pumping lemma.\n\nPS Not sure what \"bold claims\" I have made.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65805, "question": "[Huffman coding] Differentiating between messages when using a variable-length code?", "aSentId": 65806, "answer": "The codes are \"prefix free\".  That is, no word is a prefix of any other word.  So, if you have 010 and 011 as two of your symbols, they would preclude you from having 01 as a symbol, because after seeing the first two bits there, you would not be able to distinguish whether that was the end of the first symbol or just the first two bits of one of the other symbols.  Starting from the beginning of the entire coded string, you go until you can decode a single symbol, and right then, that is the first symbol.  The next bit is the first bit of the next symbol.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65807, "question": "The codes are \"prefix free\".  That is, no word is a prefix of any other word.  So, if you have 010 and 011 as two of your symbols, they would preclude you from having 01 as a symbol, because after seeing the first two bits there, you would not be able to distinguish whether that was the end of the first symbol or just the first two bits of one of the other symbols.  Starting from the beginning of the entire coded string, you go until you can decode a single symbol, and right then, that is the first symbol.  The next bit is the first bit of the next symbol.", "aSentId": 65808, "answer": "Ah, okay. So basically that property that I thought had to be true for a uniquely decodable code has to be true. Thanks!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65805, "question": "[Huffman coding] Differentiating between messages when using a variable-length code?", "aSentId": 65810, "answer": "Because you can arrange the codewords belonging to those symbols such that they form paths down a tree, always starting from the root and ending in a leaf. That's what the whole \"Huffman tree\" thing is about. So a possible decoding strategy is to read bits and going down the tree, when you hit a leaf you know the symbol ended.\n\nHowever, I feel obliged to mentioned that in practice, that's not how you really decode Huffman codes. It's just a proof to show that it can be done, but it has the unfortunate side effect that many people think that that's how you actually do it, leading to the belief that Huffman codes are extremely slow. The simplest (both to explain why it works and to code) alternative, is to make a table of length 2 to the power of the length of the longest codeword (which in practice, and *for this reason*, will typically be limited to something for which this table won't be too big - say 15), you will always read that many bits (without necessarily advancing the read pointer by that much) and treat it as an index in that table. The entries of the table are tuples of the length of first codeword (so you can advance the read pointer by the right amount) in it and the corresponding symbol (which you output). Most advanced decoding techniques are descendants of this method.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65805, "question": "[Huffman coding] Differentiating between messages when using a variable-length code?", "aSentId": 65812, "answer": "The symbols have to be chosen so that there's no ambiguity, that there's no way that any series of bits can be interpreted in more than one way.  In your example, if 010 is a valid 3-bit symbol, then that means that 01 is not a valid 2-bit symbol, because if you are given 010 you can't tell whether that's a single 3 bit symbol or a 2 bit symbol plus the first bit of the next symbol.  Likewise, it means 0 is not a valid 1-bit symbol.\n\nThis is what you naturally get if you visualize the set of all symbols as a binary tree where any path from the root to a leaf node represents a valid symbol.  Using the same example as above, if 0-1-0 was the path to a leaf node, then that by definition means that 0 and 0-1 could not have been paths to leaf nodes.  If either of those were, it would have been impossible for 0-1-0 to exist, because once you reach a leaf node you cannot descend any further, so 0 and 0-1 must be paths to internal nodes.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65814, "question": "Question on RAM Disks and How It Uses Physical Memory as Storage", "aSentId": 65815, "answer": "Nope. Give it a try using any of the many tutorials available via Google and you'll see you can create almost any size you want. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65816, "question": "Nope. Give it a try using any of the many tutorials available via Google and you'll see you can create almost any size you want. ", "aSentId": 65817, "answer": "It was unclear in the many tutorials on Google, therefore I came to have the question answered here. To be clear, you can format any part of a RAM stick (given the size being a power of 2) to be a RAM disk, and that therefore it would be excluded from when the OS attempts to allocate memory for other programs?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65818, "question": "It was unclear in the many tutorials on Google, therefore I came to have the question answered here. To be clear, you can format any part of a RAM stick (given the size being a power of 2) to be a RAM disk, and that therefore it would be excluded from when the OS attempts to allocate memory for other programs?", "aSentId": 65819, "answer": "Yep. Effectively it is allocating the memory right now. And the program is the RAM disk driver. Thus, it is no longer available to other programs. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65820, "question": "Yep. Effectively it is allocating the memory right now. And the program is the RAM disk driver. Thus, it is no longer available to other programs. ", "aSentId": 65821, "answer": "So when this occurs, and memory has been completely used, the OS will use storage as memory? If so, what stops the OS to use this RAM disk as newly allocated memory?\n\nEDIT: this is based on the assumption that no program is being used to create the RAM disk, and for theoretical purposes.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65822, "question": "So when this occurs, and memory has been completely used, the OS will use storage as memory? If so, what stops the OS to use this RAM disk as newly allocated memory?\n\nEDIT: this is based on the assumption that no program is being used to create the RAM disk, and for theoretical purposes.", "aSentId": 65823, "answer": "The RAM disk will be it's own partition/device. On windows the swap file (where disk is used as virtual memory) will always be on c:, thus not on your RAM disk. On Linux, the swap space is actually in it's own partition that is only used for that purpose and uses a special file system (swapfs). So, once again, your RAM disk will not be used to back the swap file. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65824, "question": "The RAM disk will be it's own partition/device. On windows the swap file (where disk is used as virtual memory) will always be on c:, thus not on your RAM disk. On Linux, the swap space is actually in it's own partition that is only used for that purpose and uses a special file system (swapfs). So, once again, your RAM disk will not be used to back the swap file. ", "aSentId": 65825, "answer": "What is the hierarchy of drives that would be used for memory when RAM is full? Is it that, once RAM is full, the drive that the OS is installed on is used for memory? Like I said before, I want to assume that the user decided, without an external program, to partition the RAM as a RAM disk, and that this RAM disk would not be used for virtual memory.\n\nJust trying to be crystal clear so to not have any assumptions, so thank you for bearing with me :P\n\nEDIT: For clarification, lets assume that the partitioned RAM disk is empty. The resource has been set aside for read/write, but nothing has yet to be stored in the RAM disk. Could it be used by the OS when all RAM memory is used up?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65826, "question": "What is the hierarchy of drives that would be used for memory when RAM is full? Is it that, once RAM is full, the drive that the OS is installed on is used for memory? Like I said before, I want to assume that the user decided, without an external program, to partition the RAM as a RAM disk, and that this RAM disk would not be used for virtual memory.\n\nJust trying to be crystal clear so to not have any assumptions, so thank you for bearing with me :P\n\nEDIT: For clarification, lets assume that the partitioned RAM disk is empty. The resource has been set aside for read/write, but nothing has yet to be stored in the RAM disk. Could it be used by the OS when all RAM memory is used up?", "aSentId": 65827, "answer": "Windows or Linux?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65828, "question": "Windows or Linux?", "aSentId": 65829, "answer": "Mainly in theory.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65830, "question": "Mainly in theory.", "aSentId": 65831, "answer": "A RAM disk is nothing more than a program or a driver allocating a chunk of memory, just like any other program would, and then providing an interface that makes the OS see it as yet another storage device that is attached to the machine, just like if there was a physical disk there. To the OS there's nothing special about that storage device. OSes generally don't try to use random storage devices attached to the machine as swap space when they run out of memory so no, the OS won't touch it if it runs out of memory. I suppose you could write a RAM disk driver that dynamically resizes based on some criteria though.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65832, "question": "A RAM disk is nothing more than a program or a driver allocating a chunk of memory, just like any other program would, and then providing an interface that makes the OS see it as yet another storage device that is attached to the machine, just like if there was a physical disk there. To the OS there's nothing special about that storage device. OSes generally don't try to use random storage devices attached to the machine as swap space when they run out of memory so no, the OS won't touch it if it runs out of memory. I suppose you could write a RAM disk driver that dynamically resizes based on some criteria though.", "aSentId": 65833, "answer": "I don't think that would work, seeing as every time any of the space is allocated for the drive it needs to format the desired space. If the RAM disk was dynamically resizing, it would need to be constantly wiping itself and reformatting the newly sized partition, thus eliminating any of the use it might give for storage.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 65834, "question": "I don't think that would work, seeing as every time any of the space is allocated for the drive it needs to format the desired space. If the RAM disk was dynamically resizing, it would need to be constantly wiping itself and reformatting the newly sized partition, thus eliminating any of the use it might give for storage.", "aSentId": 65835, "answer": "I don't see it being outside the realm of possibility, especially if the driver has comprehension of the filesystem used on the disk and thus can manipulate its structures. There are filesystems that support online growing and shrinking, reiserfs comes to mind. Using one of those would potentially reduce the amount of headache involved. Not saying it'd be easy or fun to write or very practical in any manner.\n\nHowever the whole thing was more of an aside from the actual reply, and how to make it work is just an implementation detail ;)", "corpus": "reddit"}]
