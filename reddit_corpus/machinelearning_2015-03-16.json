[{"docID": "t5_2r3gv", "qSentId": 205, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 206, "answer": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 207, "question": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "aSentId": 208, "answer": "Thanks - I should! I\u2019ve been thinking about this for years. But it\ntakes time, and there are so many other things in the pipeline \u2026", "corpus": "reddit"}{"docID": "t5_2r3gv", "qSentId": 205, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 210, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 211, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 212, "answer": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 213, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 214, "answer": "This is very good to hear.  Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 213, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 216, "answer": "Wow! Thanks for Sacred.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 217, "question": "Wow! Thanks for Sacred.", "aSentId": 218, "answer": "You are welcome.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 211, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 220, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 221, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 222, "answer": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 223, "question": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "aSentId": 224, "answer": "RNNLIB is provided as source, which you have to compile yourself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 225, "question": "RNNLIB is provided as source, which you have to compile yourself.", "aSentId": 226, "answer": "RNNLIB is the exception rather than the rule as far as I can tell.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 221, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 228, "answer": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 229, "question": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "aSentId": 230, "answer": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 231, "question": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "aSentId": 232, "answer": "Fair enough. But it also means that there effectively is no (fast) up-to-date library. At least not with LSTM support out of the box.", "corpus": "reddit"}{"docID": "t5_2r3gv", "qSentId": 205, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 234, "answer": "What do you think about learning selective attention with recurrent neural networks?  What do you think are the promising methods in this area?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 238, "question": "Do you have a favorite Theory Of Consciousness (TOC)? \n\nWhat do you think of Guilio Tononi's Integrated Information Theory? \n\nWhat implications - if any - do you think \"TOC\" has for AGI?", "aSentId": 239, "answer": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 240, "question": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "aSentId": 241, "answer": "Holy fuck\n\nEDIT: \nI mean, as a ML student researcher, Holy fuck.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 247, "question": "How do you recognize a promising machine learning phd student?", "aSentId": 248, "answer": "I am privileged because I have been able to attract and\nwork with several truly outstanding students. But how to quickly\nrecognize a promising student when you first meet her? There is no recipe,\nbecause they are all different! In fact, sometimes it takes a while to\nrecognize someone\u2019s brilliance. In hindsight, however, they all have\nsomething in common: successful students are not only smart but also\ntenacious. While trying to solve a challenging problem, they run into\na dead end, and backtrack. Another dead end, another backtrack. But\nthey don\u2019t give up. And suddenly there is this little insight into the\nproblem which changes everything. And suddenly they are world experts\nin a particular aspect of the field, and then find it easy to churn\nout one paper after another, and create a great PhD thesis.\n\nAfter these abstract musings, some more concrete advice.  In\ninterviews with applicants, members of my lab tend to pose a few\nlittle problems, to see how the candidate approaches them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 252, "question": "The LSTM unit is delicately crafted to solve a specific problem in training RNNs. Do you see the need for other similarly \"high-complexity\" units in RNNs or CNNs, like for example Hinton's \"capsules\"? On the topic of CNNs and capsules, do you agree with Hinton's assessment that the efficacy of pooling is actually a disaster? (I do, for what it's worth)", "aSentId": 253, "answer": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 254, "question": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "aSentId": 255, "answer": "Thank you!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 262, "question": "Hi Dr. Schmidhuber, Thanks for the AMA!\nHow close are you to building the optimal scientist? ", "aSentId": 263, "answer": "You are welcome! \n\nAbout a stone's throw away :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 265, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 266, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 267, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 268, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 269, "question": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "aSentId": 270, "answer": "As you see, they may have better personal relationships ... that's it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 272, "question": "In what field do you think machine learning will make the biggest impact in the next ~5 years?", "aSentId": 273, "answer": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 274, "question": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "aSentId": 275, "answer": "Well, I guess I meant commerical, although not in terms of money, but in terms of it being actually used my masses of people.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 280, "question": "If marcus hutter was doing an AMA 20 years from now, what scientific question would you ask? Are there any machine learning specific questions you would ask?", "aSentId": 281, "answer": "(Edited on 3/10/2015:) 20 years from now I'll be 72 and enter my midlife crisis. People will forgive me for asking silly questions. I cannot  predict the most important machine learning-specific question of 2035. If I could, I\u2019d probably ask it right now. However, since Marcus is not only a great computer scientist but also a physicist, I\u2019ll ask him: \u201cGiven the new scientific insights of the past 20 years, how long will it take AIs from our solar system to spread across the galaxy?\u201d Of course, a trivial lower bound is 100,000 years or so, which is nothing compared to the age of the galaxy. But that will work out only if someone else has already installed receivers such that (construction plans of) AIs can travel there by radio. Otherwise one must physically send seeds of self-replicating robot factories to the stars, to build the required infrastructure. How? Current proposals involve light sails pushed by lasers, but how to greatly slow down a seed near its target star? One idea: through even faster reflective sails traveling ahead of the seed. But there must be a better way. Let\u2019s hear what Marcus will have to tell us 20 years from now. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 284, "question": "You have postulated that quantum computers will fail because deterministic universe is a simpler hypothesis than a non-deterministic universe. What do you think about the current state of quantum computation?", "aSentId": 285, "answer": "If you didn't see it, the professor commented on Quantum computing in another question.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 290, "question": "What is the future of PyBrain? Is your team still working with/on PyBrain? If not, what is your framework of choice? What do you think of Theano? Are you using something better?", "aSentId": 291, "answer": "My PhD students Klaus and Rupesh are working on a successor of PyBrain with many new features, which hopefully will be released later this year.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 293, "question": "What's something exciting you're working on right now, if it's okay to be specific? ", "aSentId": 294, "answer": "Among other things, we are working on the \u201cRNNAIssance\u201d - \nthe birth of a Recurrent Neural Network-based Artificial Intelligence (RNNAI).\nThis is about a reinforcement learning, RNN-based, increasingly general problem solver.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 296, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 297, "answer": "I think I recall Hinton giving an answer to this in his MOOC: we like activations, from which derivatives can be computed easily in terms of the function value itself. For sigmoid the derivative is s(x) * (1 - s(x)) for example.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 296, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 299, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 296, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 301, "answer": "I suspect activation functions that grow more quickly are harder to control, and likely lead to exploding or vanishing gradients. Although we've managed to handle piecewise linear activations, I'm not sure if quadratic/exponential would work well. In fact, I'd bet that you could improve on ReLu by making the response become logarithmic after a certain point. RBF activations are common though (and have excellent theoretical properties), they just don't seem to learn as well as ReLu. I once trained a neural net with sin/cosine activations (it went OK, nothing special), but in general you can try out any activation function you want. Throw it into Theano and see what happens.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 303, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 304, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 305, "question": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "aSentId": 306, "answer": "An exponential activation would have as its derivative... an exponential. Gradient descent would be pretty messy with such a wild dynamic range.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 308, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 309, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 310, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 311, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 314, "question": "Just wanted to say I never get tired of your talks... never.. not once.", "aSentId": 315, "answer": "Thanks so much - I greatly appreciate it. \n\nYou are in good company. A colleague of mine has Alzheimer, and he said the same thing :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 317, "question": "If ASI is a real threat, what can we do now to prevent a catastrophe later?", "aSentId": 318, "answer": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 319, "question": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "aSentId": 320, "answer": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 321, "question": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "aSentId": 322, "answer": "In my experience ASI almost always means artificial superintelligence, which is a term that's often used when discussing safe/friendly AI. The idea is that while AGI might be human level, ASI would be vastly more intelligent. This is usually supposed to be achieved by an exponential process of recursive self-improvement by an AGI that results in an intelligence explosion.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 326, "question": "Does Alex Graves have the weight of the future on his shoulders?", "aSentId": 327, "answer": "And vice versa!\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 331, "question": "What music do you like to listen to? any particular bands or composers that you ride for?", "aSentId": 332, "answer": "I feel that in each music genre, there are a few excellent works, and many others. My taste is pretty standard. For example, my favourite rock &amp; pop music act is also the best-selling one (the Beatles). I love certain songs of the Stones, Led Zeppelin, Elvis, S Wonder,  M Jackson, Prince, U2, Supertramp, Pink Floyd, Gr\u00f6nemeyer, Sting, Kraftwerk, M Bianco, P Williams (and many other artists who had a single great song in their entire carreer). IMO the best songs of Queen are as good as anybody\u2019s, with a rare timeless quality. Some of the works indicated above seem written by true geniuses. Some by my favourite composer (Bach) seem dictated by God himself :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 337, "question": "As a researcher do you care if results of your work find practical application? Or research by itself is more than a rewarding exercise. Immagine computational power was not growing at the same a speed as it did then most of results on RNN would stay on the paper.", "aSentId": 338, "answer": "Kurt Lewin said: \"There is nothing so practical as a good theory.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 342, "question": "Hello Prof. Schmidhuber, thanks for doing an AMA! I have some questions regarding the G\u00f6del machine. My understanding is that the machine searches for an optimal behavioural strategy in arbitrary environments. It does so by finding a proof that an alternative strategy is better than the current one and by rewriting the actual strategy (which may include the strategy searching mechanism). The G\u00f6del machine finds the optimal strategy for a given utility function. \n\n * Is it guaranteed that the strategy searching mechanism actually finds a proof?\n * It is a current trend to find 'optimal' behaviours or organisation in nature. For example minimal jerk trajectories for reaching and pointing movements,  sparse features in vision or optimal resolution in grid cells. Nature found these strategies by trial-and-error. How can we take a utility function as a starting point and decide that it is a 'good' utility function?\n * Could the G\u00f6del machine and AIXI guide neuroscience and ML research as a theoretical framework? \n * Are there plans to find implementations of self-optimizing agents?", "aSentId": 343, "answer": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 344, "question": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "aSentId": 345, "answer": "&gt; G\u00f6del machines are limited by the basic limits of math and computation identified by the founder of modern theoretical computer science himself, Kurt G\u00f6del (1931): some theorems are true but cannot be proven by any computational theorem proving procedure (unless the axiomatic system itself is flawed). That is, in some situations the GM may never find a proof of the benefits of some change to its own code.\n\nApart  from undecidable proofs, is there a constructive way to find the proofs? According to the Curry-Howard theorem proofs can be represented as programs and programs as proofs. So what is gained by searching in proof space in contrast to searching in program space? .. Or maybe I'm missing something. I tried to understand G\u00f6del machines for some time now but I'm still not sure how this should work.\n\n&gt; I think so, because they are optimal in theoretical senses that are not practical, and clarify what remains to be done, e.g.: Given a limited constant number of computational instructions per second (a trillion or so), what is the best way of using them to get as close as possible to a model such as AIXI that is optimal in absence of resource constraints?\n\nI think I saw Konrad K\u00f6rding mentioning AIXI in a talk, but unfortunately I could not find the online presentation any more. Just a wild guess that you knew something about this.. \n\n&gt; Yes.\n\nAny chance you could elaborate on this? :) Is something in this direction published?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 350, "question": "I am starting a CS Bachelor this September at ETH. Primarily because I want to get into AI/ML/NN research and creation. It simply is the most important thing there is:D What should i do to be able to join your group in Lugano, what are you looking for in your research assistants? Thanks and cheers", "aSentId": 351, "answer": "Thanks a lot for your interest! We\u2019d like to see: mathematical\nskills, programming skills, willingness to work with others,\ncreativity, dedication, enthusiasm (you seem to have enough of that :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 358, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 359, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 360, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 361, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 362, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 363, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 365, "question": "What do you think a small research institute (in Germany) can do to improve changes for funding of their projects?", "aSentId": 366, "answer": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 367, "question": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "aSentId": 368, "answer": "Thanks for the answer. Up until now, I always was under the impression that institutes would have to produce papers that are recognized as groundbreaking from the first second on. Guess the importance can increase over time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 370, "question": "What is your take on the threat posed by artificial super intelligence to mankind?\n", "aSentId": 371, "answer": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 372, "question": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "aSentId": 373, "answer": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 374, "question": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "aSentId": 375, "answer": "I do understand your concerns. Note, however, that humankind is already used to huge, indifferent powers. A decent earthquake is a thousand times more powerful than all nuclear weapons combined. The sun is slowly heating up, and will make traditional life impossible within a few hundred million years. Humans evolved just in time to think about this, near the end of the 5-billion-year time window for life on earth.\nYour popular but simplistic nanobot scenario actually sounds like a threat to many AIs in the expected future \"ecology\" of AIs. So they'll be at least motivated to prevent that. Currently I am much more worried about certain humans who are relatively powerful but indifferent to the suffering of others. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 381, "question": "Why does a mirror reverse right amd left, but not up and down?\n\n(I dont want the answer a human gives, but how AI explains it!)\n\n/L", "aSentId": 382, "answer": "An AI would answer that your perception is reversed. The reason left and right appear to be reversed is because your brain models the mirror-you as part of the same world as the real you, and if you went around behind the mirror and faced yourself, you'd need to reverse your left and right to match the perception of the mirror-you. The reason you don't see the up-down reversal is because you're used to travelling horizontally. If you went over the mirror and faced yourself, you'd then have to reverse up and down instead. So it's all in your non-AI head!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 392, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 393, "answer": "The models in both US and EU are shaped by Humboldt\u2019s old model\nof the research university. But they come in various flavours.\nFor example, there is huge variance in \"the European models\u201d. \nI see certain advantages of the successful US PhD school model \nwhich I got to know better at the University of Colorado at Boulder in the \nearly 1990s. But I feel that less school-like models also have something \ngoing for them. \n\nUS-inspired PhD schools like those at my present Swiss \nuniversity require students to get credits for certain courses. At TU\nMunich (where I come from), however, the attitude was: a PhD student\nis a grown-up who doesn\u2019t go to school any more; it\u2019s his own job to\nacquire the additional education he needs. This is great for strongly\nself-driven persons but may be suboptimal for others. At TUM, my wonderful\nadvisor, Wilfried Brauer, gave me total freedom in my research. I loved\nit, but it seems kind of out of fashion now in some places. \n\nThe extreme \nvariant is what I like to call the \u201cEinstein model.\u201d Einstein never went to \ngrad school. He worked at the patent office, and at some point he submitted a\nthesis to Univ. Zurich. That was it. Ah, maybe I shouldn\u2019t admit\nthat this is my favorite model. And now I am also realizing that I have not really \nanswered your question in any meaningful way - sorry for that!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 392, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 395, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 396, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 397, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 392, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 399, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 400, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 401, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 402, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 403, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 400, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 405, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 406, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 407, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 409, "question": "What do you think about using ontologies / semantic information (DBPedia, Wikidata) as a substrate / mould for ANNs to generate more versatile networks?", "aSentId": 410, "answer": "Sounds like a great idea! Perhaps relevant:  Ilya Sutskever &amp; Oriol Vinyals &amp; Quoc V. Le use LSTM recurrent neural networks to access semantic information for English-to-French translation, with great success: http://arxiv.org/abs/1409.3215. And Oriol Vinyals &amp; Lukasz Kaiser &amp; Terry Koo &amp; Slav Petrov &amp; Ilya Sutskever &amp; Geoffrey Hinton use LSTM to\nread a sentence, and decode it into a flattened tree. They achieve excellent constituency parsing results: http://arxiv.org/abs/1412.7449", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 412, "question": "(in relation to the Atari paper and partly on your statement about it)\n\nWhat do you personally think about using a diverse selection of video games as a learning problem / \"dataset\"?\n\nOne thing I found interesting about the DeepMind Nature paper is that they could not solve Montezuma's Revenge at all (the game, not the travel problem), which is an action-adventure game requiring some kind of real-world knowledge / thinking - and temporal planning, of course. As any Atari game, conceptually it is still rather simple.\n\nI wonder what would happen if we found an AI succeeding over a wide range of complex game concepts like e.g. Alpha Centauri / Civilization, SimCity, Monkey Island II (for humorous puns, such as \"monkey wrench\"), put it into a robot and unleash it on the real world.", "aSentId": 413, "answer": "&gt; in relation to the Atari paper and partly on your statement about it\n\nCan you point me to his statement about it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 419, "question": "Two questions, if I may:\n\n1. With Moore's law gradually coming to an end, it would seem that we won't be achieving anything even close to General AI on today's hardware, at least not economically. As a researcher at the forefront of the field, are you aware of any hardware \"game changers\" that may simplify training and execution of extremely large neural networks that may be capable of intelligence?\n\n2. What are some of the most exciting papers that you have read (or written) in the past year?", "aSentId": 420, "answer": "&gt; With Moore's law gradually coming to an end\n\nSource? GPUs have just picked up the Moore torch and is now carrying the field. Ive seen no reason why this won't continue for 1 or 2 more cycles before something new  like graphene will be in production.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 423, "question": "What advice do you have for a BTech computer science student passionate about strong AI hoping to join your team at IDSIA someday?", "aSentId": 424, "answer": "Read our papers, re-implement one of our systems, perhaps improve it a bit, or better a lot, or do something else that I was not able to think of because it\u2019s too original!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 430, "question": "Where did you get the joke about the three prisoners? ", "aSentId": 431, "answer": "You mean the one that starts: \"Three prisoners walk into a bar ...\"? :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 437, "question": "What is the algorithm of love?\n", "aSentId": 438, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 437, "question": "What is the algorithm of love?\n", "aSentId": 440, "answer": "Great question!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 437, "question": "What is the algorithm of love?\n", "aSentId": 442, "answer": "In response to the foolish comment: I am not a chinaman, but you are a racist village idiot.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 444, "question": "A long time ago, someone once misattributed '64k ought to be enough for anyone'.\n\nWhat general statement or suggestion about strong generalized a.i. could be looked at in a similar way a decade or two from now?\n\nThanks, I look forward to reading your ama.", "aSentId": 445, "answer": "\"64 yottabytes ought to be enough for anyone.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 457, "question": "Do you think having a PhD is important if one wants to work in a good research team?", "aSentId": 458, "answer": "Not at all - my PhD students are doing excellent work, but don't have a PhD :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 460, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 461, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 463, "question": "i understand that neural networks and deep learning are computationally intensive for non-trivial problems. In addition, many experiments are necessary to see what works and what does not. What sort of equipment do you recommend for doing research in this area without breaking the bank? ", "aSentId": 464, "answer": "As long as your applications are not too ambitious, a desktop machine with one or more GPUs should do!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 474, "question": "What do you think of Bitcoin. ", "aSentId": 475, "answer": "I thought more of it when I had more of it.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 477, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 478, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 482, "question": "Using an Amazon GPU Spot Instance for Deep Learning", "aSentId": 483, "answer": "I'm newbie myself, but I think EBS is pretty much required if you want any kind of persistent data, both for spot and normal instances. And it won't be \"super slow\", it's an SSD drive and probably IS located locally.\n\nAnd in any case, data reading speed is unlikely to be your biggest bottleneck when doing deep learning.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 482, "question": "Using an Amazon GPU Spot Instance for Deep Learning", "aSentId": 485, "answer": "Reading the source data isn't the limiting factor.\n\nI use amazon spot GPU instances.   I issue a read call for each next minibatch while the previous one is being processed, and as far as I know, it isn't a bottleneck.    If it was, I would just issue more read requests for batches in parallel.  The SSD throughput is going to be much faster than the forward/back propagation time for a minibatch on my hardware.\n\n\nMore importantly, you should save the network weights regularly incase your instance gets terminated.   I find my instances often run for days without termination though, often even though my bid is below the spot price - they aren't super speedy with termination.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 482, "question": "Using an Amazon GPU Spot Instance for Deep Learning", "aSentId": 487, "answer": "Save it as an AMI? Perhaps save regularly in case the spot instance terminates.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 488, "question": "Save it as an AMI? Perhaps save regularly in case the spot instance terminates.", "aSentId": 489, "answer": "that would take care of the machine settings, making standing back up quicker, but would not help with data storage. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 493, "question": "Simple Deep learning, Python, No Nvidia GPU: Options?", "aSentId": 494, "answer": "&gt;I also can't install Git on the lab computers\n\nWhy ? \n\nAlso have you considered using Amazon EC2 for your GPU needs ? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 495, "question": "&gt;I also can't install Git on the lab computers\n\nWhy ? \n\nAlso have you considered using Amazon EC2 for your GPU needs ? ", "aSentId": 496, "answer": "University software installation limit headaches. \n(Sidenote: I haven't used Git for anything beyond looking at other people's code). ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 497, "question": "University software installation limit headaches. \n(Sidenote: I haven't used Git for anything beyond looking at other people's code). ", "aSentId": 498, "answer": "If you have Anaconda I *think* you can avoid git by downloading the zip from GitHub then pip installing. Sounds really annoying though! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 497, "question": "University software installation limit headaches. \n(Sidenote: I haven't used Git for anything beyond looking at other people's code). ", "aSentId": 500, "answer": "Have you checked to make sure it's not already installed? Any lab setup used for writing software really should have it.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 501, "question": "Have you checked to make sure it's not already installed? Any lab setup used for writing software really should have it.\n\n", "aSentId": 502, "answer": "It's not. Just getting Numpy, Pandas and sklearn involved a LOT of beurucracy. (That, and none of the PCs there have GPUs).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 503, "question": "It's not. Just getting Numpy, Pandas and sklearn involved a LOT of beurucracy. (That, and none of the PCs there have GPUs).", "aSentId": 504, "answer": "I had troubles with those limits on my lab's cluster, but then i learned how to install stuff from source (hint: ./configure --prefix=your/home; make; make install). \n\nIt doesn't always go smoothly but it's well worth the effort to make your own python installation with everything you need.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 493, "question": "Simple Deep learning, Python, No Nvidia GPU: Options?", "aSentId": 506, "answer": "Besides pylearn and caffe, these two are nice:\n\n\nhttps://github.com/lmjohns3/theanets\n\nhttps://github.com/benanne/Lasagne\n\n\nbut you're not going to get a simple fit() for NNs. Most of these deep learning libs can work without a GPU but they are going to be very slow.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 507, "question": "Besides pylearn and caffe, these two are nice:\n\n\nhttps://github.com/lmjohns3/theanets\n\nhttps://github.com/benanne/Lasagne\n\n\nbut you're not going to get a simple fit() for NNs. Most of these deep learning libs can work without a GPU but they are going to be very slow.\n", "aSentId": 508, "answer": "Blocks also looks interesting. https://github.com/bartvm/blocks\n\nI've only gotten pylearn and theanets to do anything useful. Pylearn is pretty mature once you get past the lack of any means of linearly traversing the documentation or understanding the api.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 493, "question": "Simple Deep learning, Python, No Nvidia GPU: Options?", "aSentId": 510, "answer": "If you are going to do anything serious with it, you are going to need speed. Have you considered using Amazon EC2 instances? They're cheap ($0.06 an hour or thereabouts?) and you'll get root access to install whatever you want. They have specialized GPU instances designed with CUDA/OpenCL in mind. I'm planning on using one for an upcoming Kaggle competition.\n\nEDIT: as others mention, several of the libraries (Caffe, PyLearn etc) have CPU/GPU switches. Which means you can develop/test locally on your CPU, and then rent AWS time to do full-scale training runs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 514, "question": "1. I need it to be free and runnable locally. (Amazon EC2 isn't relevant for me).\n2. Aren't there any \"out of the box\" packages (i.e. not trying to expand the latest bleeding edge RC of Theano) that work with a non-Nvidia GPU? \nThanks.", "aSentId": 515, "answer": "1. why? can't you spare $20 / month?\n\n2. no, there aren't a) anything really out of the box or b) decent that doesn't use nVidia.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 516, "question": "1. why? can't you spare $20 / month?\n\n2. no, there aren't a) anything really out of the box or b) decent that doesn't use nVidia.\n", "aSentId": 517, "answer": "1. MSC student. NO budget. Doing this for fun/learning. \n2. What's out there that isn't decent but still supports gPU acceleration that isn't CUDA? (Without Being in C or the like)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 518, "question": "1. MSC student. NO budget. Doing this for fun/learning. \n2. What's out there that isn't decent but still supports gPU acceleration that isn't CUDA? (Without Being in C or the like)", "aSentId": 519, "answer": "you could try [this](https://github.com/cvjena/cn24). I have no personal experience but it looks fairly professional.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 527, "question": "Tools for Unsupervised Feature Learning.", "aSentId": 528, "answer": "Theano is always a popular choice, although I'm not sure how many people are doing unsupervised pretraining right now.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 529, "question": "Theano is always a popular choice, although I'm not sure how many people are doing unsupervised pretraining right now.", "aSentId": 530, "answer": "Well, that's a good fallback option. But Theano would require some involved implementation, unlike Torch/Caffe/Pylearn2. Not essentially the best thing if all you want to do toy around with it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 531, "question": "Well, that's a good fallback option. But Theano would require some involved implementation, unlike Torch/Caffe/Pylearn2. Not essentially the best thing if all you want to do toy around with it.", "aSentId": 532, "answer": "If you are gonna get into pylearn2 then it is a big benefit to lean some theano first. Also, there is a bunch of Theano code available in the [tutorials](http://deeplearning.net/tutorial/SdA.html).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 533, "question": "If you are gonna get into pylearn2 then it is a big benefit to lean some theano first. Also, there is a bunch of Theano code available in the [tutorials](http://deeplearning.net/tutorial/SdA.html).", "aSentId": 534, "answer": "I am familiar with Theano and have used it previously. I just don't want to use it now unless absolutely required.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 527, "question": "Tools for Unsupervised Feature Learning.", "aSentId": 536, "answer": "I use torch, but I agree that the documentation is pretty bad.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 537, "question": "I use torch, but I agree that the documentation is pretty bad.", "aSentId": 538, "answer": "There's perhaps something I'm missing then. Could you please link to the documentation you use for the unsup package, and a more recent example than the one in the official documentation, if you're aware of one? I've been struggling all afternoon to get the example running on the GPU.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 539, "question": "There's perhaps something I'm missing then. Could you please link to the documentation you use for the unsup package, and a more recent example than the one in the official documentation, if you're aware of one? I've been struggling all afternoon to get the example running on the GPU.", "aSentId": 540, "answer": "I don't know of any unsupervised learning package.  I build up the model I want using nn and then write down an unsupervised objective and optimize it with optim.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 541, "question": "I don't know of any unsupervised learning package.  I build up the model I want using nn and then write down an unsupervised objective and optimize it with optim.", "aSentId": 542, "answer": "Well, that's one way we could do it, thanks :).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 545, "question": "Predictive number of FB likes of the given article", "aSentId": 546, "answer": "There's a bunch of researchers who do this.  Mainly in the network science field.  Check out Tina Eliassi-Rad first.  I'll look around when I get to a pc later.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 545, "question": "Predictive number of FB likes of the given article", "aSentId": 548, "answer": "I think that outside of FB is going to get difficult to find it. Mostly because most of that data is private (specially who liked it).\n\nTry looking for retweets, I think you'll have an easier time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 545, "question": "Predictive number of FB likes of the given article", "aSentId": 550, "answer": "It's all about the hubs in the network.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 551, "question": "It's all about the hubs in the network.", "aSentId": 552, "answer": "Could you elaborate on saying that \" ... it is all about hubs in network ...\"?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 554, "question": "ML and human movement", "aSentId": 555, "answer": "&gt;Can a deep neural network ... extract a set of ... \u201cbasic\u201d movements? \n\n\nSure, when Graves was teaching his deep net handwriting, model learned to do chaotic strokes. Sometimes they were even forming letters but mostly not. Basic movements.\n\nWhen Alex Graves was teaching his net to speak, it learned mumbling, very rarely forming recognisable words. Essentially it learned basic parts of speech.\n\nSo sure, net could learn basic movements. It will form something from them, most likely it will resemble newborn laying on the ground trying to stand up or something.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 557, "question": "Memory Neural Networks (MemNN) Implementation?", "aSentId": 558, "answer": "Hello!\n\n&gt; If not, are there any other textual sequence-predicting implementations for tasks like these?\n\nI made something called HTFERL which I have also used for text prediction (I posted here recently on it). It can easily recite large paragraphs on its own, with as little as 5 iterations over the sequence. I have both a CPU and a GPU version, the GPU version supports hierarchies (much more efficient). If you would like I can help you get it running.\n\nHTFERL is based on HTM, and predicts sequences 1 step ahead of time. You can predict multiple timesteps by feeding the prediction back in as input. \n\nAside from text prediction, I have used it for reinforcement learning (the original purpose of it actually), and speech recognition. The GPU version runs extremely fast, I have tested it with over 400000 neurons and it still runs at 60 frames per second.\n\nLink to CPU version (no hierarchies, called RecurrentSparseAutoencoder): [https://github.com/222464/AILib/blob/master/Source/deep/RecurrentSparseAutoencoder.h](https://github.com/222464/AILib/blob/master/Source/deep/RecurrentSparseAutoencoder.h)\nLink to GPU version (hierarchies): [https://github.com/222464/HTFERL](https://github.com/222464/HTFERL)\n\nIf it interests you, and I can walk you through the setup!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 559, "question": "Hello!\n\n&gt; If not, are there any other textual sequence-predicting implementations for tasks like these?\n\nI made something called HTFERL which I have also used for text prediction (I posted here recently on it). It can easily recite large paragraphs on its own, with as little as 5 iterations over the sequence. I have both a CPU and a GPU version, the GPU version supports hierarchies (much more efficient). If you would like I can help you get it running.\n\nHTFERL is based on HTM, and predicts sequences 1 step ahead of time. You can predict multiple timesteps by feeding the prediction back in as input. \n\nAside from text prediction, I have used it for reinforcement learning (the original purpose of it actually), and speech recognition. The GPU version runs extremely fast, I have tested it with over 400000 neurons and it still runs at 60 frames per second.\n\nLink to CPU version (no hierarchies, called RecurrentSparseAutoencoder): [https://github.com/222464/AILib/blob/master/Source/deep/RecurrentSparseAutoencoder.h](https://github.com/222464/AILib/blob/master/Source/deep/RecurrentSparseAutoencoder.h)\nLink to GPU version (hierarchies): [https://github.com/222464/HTFERL](https://github.com/222464/HTFERL)\n\nIf it interests you, and I can walk you through the setup!", "aSentId": 560, "answer": "Great! Yes, interested. Can it be used via command line with file / stdio input and output?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 561, "question": "Great! Yes, interested. Can it be used via command line with file / stdio input and output?", "aSentId": 562, "answer": "Right now it is a C++ library, but I can write such an interface for you if you like (doesn't take long). I want to do something like that anyways :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 565, "question": "Would there be any practical differences between using the absolute value rather than the square in functions such as least square function? Isn't the square more computationally expensive?", "aSentId": 566, "answer": "If you look at a textbook discussing Regression, you'll find that it's commonly accepted that LAD (least absolute deviation) is a more robust risk framework than LS (least squares). It is less stable, though, and has no closed form singular solution to the risk minimization problem. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 567, "question": "If you look at a textbook discussing Regression, you'll find that it's commonly accepted that LAD (least absolute deviation) is a more robust risk framework than LS (least squares). It is less stable, though, and has no closed form singular solution to the risk minimization problem. ", "aSentId": 568, "answer": "More robust but less stable? Huh?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 569, "question": "More robust but less stable? Huh?", "aSentId": 570, "answer": "It is robust to outliers -- while large residuals in OLS are magnified due to the squaring, the absolute value does not weigh these outliers any differently than other points during the risk minimization. \n\nThe instability of LAD can be seen with some simple visualizations. A small horizontal adjustment in a datum results in a larger shift in the LAD line than the shift in the OLS line. This comes from the latching / two line bounding property. \n\nAlso, OLS has much more clean math behind the theory. The estimators exactly match the MLE theory if you take the residuals to be Gaussian, whereas for LAD, the residuals are taken to be Laplacian (which, as I mentioned, has no closed form solution). ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 565, "question": "Would there be any practical differences between using the absolute value rather than the square in functions such as least square function? Isn't the square more computationally expensive?", "aSentId": 572, "answer": "L1 norms encourage sparsity because the decreased cost in going from 1 to 0 is the same as going from 100 to 99. So values keep falling until a bunch are right at 0. L2 norm punishes large values while not really punishing anything close-ish to 0.\n\nSparse solutions are desirable in some cases but nonsensical in others.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 565, "question": "Would there be any practical differences between using the absolute value rather than the square in functions such as least square function? Isn't the square more computationally expensive?", "aSentId": 574, "answer": "Using square loss corresponds to estimating the mean for your output variable.  Using absolute error corresponds to estimating the median for your output variable.  \n\nThus they answer completely different questions.  As others have pointed out, the median is more robust than the mean.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 576, "question": "Yes there is.\nImagine you have two algorithms with the following errors for the same five data points:\n\n**Algo 1:** 0.5, 0.5, 0.5, 0.5, 1\n\n**Algo 2:** 3, 0, 0, 0, 0\n\nIf you compute the mean of the sum of the absolute values, you get an error of 0.6 for both.\nIf you compute the means square error (MSE) for both of them, you get 0.4 for **Algo 1** and 1.8 for **Algo 2**.\n\nWith MSE you are greatly rewarding algorithms for getting errors that are closer to zero and greatly punishing them otherwise. Using MSE we are setting a preference to algorithms that produce little variance in predictions while minimising the error. Using just using the mean of  sum of absolutes, you aren't expressing any preference.\n\nHope that helps.", "aSentId": 577, "answer": "Another intuition is that the number with the lowest squared error for any distribution is its mean. Whereas minimizing the absoulte error gives me weird results.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 578, "question": "Another intuition is that the number with the lowest squared error for any distribution is its mean. Whereas minimizing the absoulte error gives me weird results.", "aSentId": 579, "answer": "Minimizing the L2 loss gives you the mean. Minimizing L1 loss gives you the *median*. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 583, "question": "Request: advice for developing deep learning / computer vision based quadcopters (\"drones\") systems", "aSentId": 584, "answer": "A GPU's power consumption is pretty significant, so I'm not sure how that would work out in a drone setting. Most GPUs consume in the 100s of watts of power, way more than a typical drone.\n\nBut this is still a rapidly evolving field, and it's possible someone has an embedded GPU just for this task.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 585, "question": "A GPU's power consumption is pretty significant, so I'm not sure how that would work out in a drone setting. Most GPUs consume in the 100s of watts of power, way more than a typical drone.\n\nBut this is still a rapidly evolving field, and it's possible someone has an embedded GPU just for this task.", "aSentId": 586, "answer": "&gt; Most GPUs consume in the 100s of watts of power, way more than a typical drone. \n\nWhere you have got THAT number for mobile GPUs? Tegra K1 got power consumption of estimated 5W. With 47g 18650 cell holding ~12Wh. More then enough for 2h of powering GPU. And quadrocopters fly for &lt;30m usually.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 587, "question": "&gt; Most GPUs consume in the 100s of watts of power, way more than a typical drone. \n\nWhere you have got THAT number for mobile GPUs? Tegra K1 got power consumption of estimated 5W. With 47g 18650 cell holding ~12Wh. More then enough for 2h of powering GPU. And quadrocopters fly for &lt;30m usually.\n", "aSentId": 588, "answer": "Apologies. I was referring to the typical desktop GPU, and didn't look specifically at the Tegra K1.  According to this article has a rated peak consumption of ~11W : http://wccftech.com/nvidia-tegra-k1-performance-power-consumption-revealed-xiaomi-mipad-ship-32bit-64bit-denver-powered-chips/  \n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 591, "question": "[Question] I have a clustering data mining project where I am stuck on preprocessing.", "aSentId": 592, "answer": "This is not really a machine learning question, it's more like a basic programming question.\n\nWhat you need to do is to loop through your dataset and add together each of the values that are not '?' and count how many times you did that. Then when you're finished looping you calculate the mean (sum/count) and loop through the dataset once again replacing each '?' with that.\n\nIf this seems complicated, you need to study programming some more and not bother with machine learning too much right now.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 591, "question": "[Question] I have a clustering data mining project where I am stuck on preprocessing.", "aSentId": 594, "answer": "Post the pandas code you're using, and the error you get. \nSounds really trivial to be honest, just get for each column its (nonNan) values (I think pandas will do this automatically anyway if you ask for the mode or mean), and do a replace/map.. \n(BTW, StackOverflow is probably where you'll find code to do this / LetMeGoogleThatForYou)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 596, "question": "Background needed to learn EM algorithm?", "aSentId": 597, "answer": "EM takes 1-2 lectures in a typical ML course so it's doable.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 599, "question": "Can I use sentiment analysis to answer some simple questions?", "aSentId": 600, "answer": "You can. If you have some people that are discussing about this in their blog, you could detect the sentiment from the blog by analysing the content of the blog. But without any data you can't answer the question. To get started read more about supervised classification.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 604, "question": "Novel Supervised Machine Learning Algorithm Called Gravitational Clustering", "aSentId": 605, "answer": "In the paper, it seems like the PDF (equation 14) should have a negative exponent, like exp(-D/...) instead of exp(D/...)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 606, "question": "In the paper, it seems like the PDF (equation 14) should have a negative exponent, like exp(-D/...) instead of exp(D/...)", "aSentId": 607, "answer": "Yes you are right! Just fixed it. Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 608, "question": "Yes you are right! Just fixed it. Thank you.", "aSentId": 609, "answer": "p. 3:\n\nThe bottom of the fraction is the number of planets per class which insures that their is no bias due to the different amounts of clusters with\n-&gt;\nwhich insures that there is no bias\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 610, "question": "p. 3:\n\nThe bottom of the fraction is the number of planets per class which insures that their is no bias due to the different amounts of clusters with\n-&gt;\nwhich insures that there is no bias\n\n", "aSentId": 611, "answer": "Thank you! Just fixed it and pushed the new version to github. Thanks!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 604, "question": "Novel Supervised Machine Learning Algorithm Called Gravitational Clustering", "aSentId": 613, "answer": "This seems pretty similar to KNN/K-means. I'm not sure why there's this whole simulation instead of just finding the closest \"planet.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 614, "question": "This seems pretty similar to KNN/K-means. I'm not sure why there's this whole simulation instead of just finding the closest \"planet.\"", "aSentId": 615, "answer": "It's a minor variant of knn that seems to get reinvented every few years, and they're all reducible to an rbf neural network with various tweaks to the activation function or construction of the network. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 616, "question": "It's a minor variant of knn that seems to get reinvented every few years, and they're all reducible to an rbf neural network with various tweaks to the activation function or construction of the network. ", "aSentId": 617, "answer": "I partially agree with you. But I think the strongest part of the algorithm is the simulation aspect. It's something that rbf nets and knn dont do. Also the building of a prototypical system does not happen in knn. And my algorithm can learn from a few samples while rbf networks rarely can.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 614, "question": "This seems pretty similar to KNN/K-means. I'm not sure why there's this whole simulation instead of just finding the closest \"planet.\"", "aSentId": 619, "answer": "The assumption that the closest planet is the right planet is sometimes flawed! Heavier or more dense planets need to have more weight than light ones!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 620, "question": "The assumption that the closest planet is the right planet is sometimes flawed! Heavier or more dense planets need to have more weight than light ones!", "aSentId": 621, "answer": "I think that this is actually a problem in some ways. Momentum might make your test point completely miss a reasonable local point and go rocketing off to a distant one. Your basins of attraction may not be continuous or make any sort of sense. \n\nJust as a toy example, imagine three \"planets\" of equal weight at (1, 0), (-1, 0), and (0, -1) and now introduce a test point at (0, 1). If I understand the way you're simulating the system dynamics, then the attraction from the two points on the x axis will cancel and the test point will be labeled as the farthest point away from it, the one on the negative y axis. Which doesn't seem reasonable to me. And while that's a contrived example, finding other ones that will exhibit similar behavior is nowhere near the measure zero set that you'd want. While I haven't done out the math, I think it should be possible to show that your approach will have extremely high variance, and possibly be inconsistent in the asymptotic limit. \n\nIt's an interesting thought, but where it deviates from something like a 1NN approach I think it does so in ways that potentially don't make much sense from a classification perspective. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 622, "question": "I think that this is actually a problem in some ways. Momentum might make your test point completely miss a reasonable local point and go rocketing off to a distant one. Your basins of attraction may not be continuous or make any sort of sense. \n\nJust as a toy example, imagine three \"planets\" of equal weight at (1, 0), (-1, 0), and (0, -1) and now introduce a test point at (0, 1). If I understand the way you're simulating the system dynamics, then the attraction from the two points on the x axis will cancel and the test point will be labeled as the farthest point away from it, the one on the negative y axis. Which doesn't seem reasonable to me. And while that's a contrived example, finding other ones that will exhibit similar behavior is nowhere near the measure zero set that you'd want. While I haven't done out the math, I think it should be possible to show that your approach will have extremely high variance, and possibly be inconsistent in the asymptotic limit. \n\nIt's an interesting thought, but where it deviates from something like a 1NN approach I think it does so in ways that potentially don't make much sense from a classification perspective. ", "aSentId": 623, "answer": "Finally a great question! First of all I do not calculate the momentum exactly for that reason. At each point I calculate the summed force. Then I move my mass toward the summed force, by using a somewhat inverse function (greater the force the slower I go) this makes sure I will not overshoot the planet. But on the flip side that means that it might not get as close to a planet as I want. The error correction there relies on picking the right alpha step and radius. \nI ran into the exact problem you described when initially creating this algorithm.\nThanks for showing interest.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 620, "question": "The assumption that the closest planet is the right planet is sometimes flawed! Heavier or more dense planets need to have more weight than light ones!", "aSentId": 625, "answer": "This feels more like a Gaussian mixture model (GMM) with class labels being the highest probability class? The GMMs differs from K-means mainly because the different cluster covariance matrices can allow some clusters to have a larger \"radius\" than others. \n\n3 other things:\n\n- I have a hard time following some of your notation. You may want to add some additional detail about what variables are, etc. For instance you introduce variables with subscripts without defining them and things of that sort. \n\n- The details could be explained more in general. For instance, you might want to expand the details of your Testing Results section. For instance, did your method really have 92% accuracy on the remaining 147 values in the iris data when training with a sample size of n=3 or did you do something different? How did this vary when you draw a different set of 3 points? Or have 60% accuracy on the remaining 1787 values when training with n=10 for the digits dataset? What are the settings you used for your model for each of these datasets? What are the settings you used for the other methods? It feels like there are a lot of details that need expanding upon. \n\nEDIT: I misunderstood the algorithm a bit. A different recommendation is added\n~~You discuss that your method does not force you to choose a number of clusters, but do not discuss in detail the properties of the method: how the method depends on your choice of parameters, how well it identifies the correct number of clusters when the clusters are spatially segregated, how well it identifies the number of clusters when the clusters are partially overlapping, etc. A simulation study would be nice where you know the true number of clusters and test how well your method identifies them, compared with other methods like GMM, K-means, etc. Did your method always identify the correct number of clusters in the Iris and Digits sets or did you fix the number of clusters to the true number? You may have done this a bit, but don't make it clear.~~\n\n- A simulation study where you have chosen class boundaries such that other methods struggle but yours does well would be really nice. It both shows good performance for your method and gives readers an idea of the type of scenario where your method would be particularly useful. Sorry for the unhelpful comment above.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 626, "question": "This feels more like a Gaussian mixture model (GMM) with class labels being the highest probability class? The GMMs differs from K-means mainly because the different cluster covariance matrices can allow some clusters to have a larger \"radius\" than others. \n\n3 other things:\n\n- I have a hard time following some of your notation. You may want to add some additional detail about what variables are, etc. For instance you introduce variables with subscripts without defining them and things of that sort. \n\n- The details could be explained more in general. For instance, you might want to expand the details of your Testing Results section. For instance, did your method really have 92% accuracy on the remaining 147 values in the iris data when training with a sample size of n=3 or did you do something different? How did this vary when you draw a different set of 3 points? Or have 60% accuracy on the remaining 1787 values when training with n=10 for the digits dataset? What are the settings you used for your model for each of these datasets? What are the settings you used for the other methods? It feels like there are a lot of details that need expanding upon. \n\nEDIT: I misunderstood the algorithm a bit. A different recommendation is added\n~~You discuss that your method does not force you to choose a number of clusters, but do not discuss in detail the properties of the method: how the method depends on your choice of parameters, how well it identifies the correct number of clusters when the clusters are spatially segregated, how well it identifies the number of clusters when the clusters are partially overlapping, etc. A simulation study would be nice where you know the true number of clusters and test how well your method identifies them, compared with other methods like GMM, K-means, etc. Did your method always identify the correct number of clusters in the Iris and Digits sets or did you fix the number of clusters to the true number? You may have done this a bit, but don't make it clear.~~\n\n- A simulation study where you have chosen class boundaries such that other methods struggle but yours does well would be really nice. It both shows good performance for your method and gives readers an idea of the type of scenario where your method would be particularly useful. Sorry for the unhelpful comment above.", "aSentId": 627, "answer": "Okay thank you! The probabilistic model is kind of similar to GMM but I am not working with latent variables and my training is not statistical at all. The training makes no assumption about the distributions of my dataset. But I see where your coming from. Could you please expand on what parts of my notation are confusing, that would be very helpful. \nIn the testing section, when seeing if my algorithm could work with small amount of data. I just selected one example for each class in my dataset. And yes! I got those accuracies! You can check out the code for yourself. And thank you for the suggestion of the simulation study, I think that would be very helpful. And the algorithm dynamically creates the amount of clusters. It decides whether or not to add a new point depending on how far it is from a point with the same class and the radius of that point. I did not explicitly state the amount of clusters each algorithm should have. Seriously thank you for the feedback. It means a lot. Very helpful.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 628, "question": "Okay thank you! The probabilistic model is kind of similar to GMM but I am not working with latent variables and my training is not statistical at all. The training makes no assumption about the distributions of my dataset. But I see where your coming from. Could you please expand on what parts of my notation are confusing, that would be very helpful. \nIn the testing section, when seeing if my algorithm could work with small amount of data. I just selected one example for each class in my dataset. And yes! I got those accuracies! You can check out the code for yourself. And thank you for the suggestion of the simulation study, I think that would be very helpful. And the algorithm dynamically creates the amount of clusters. It decides whether or not to add a new point depending on how far it is from a point with the same class and the radius of that point. I did not explicitly state the amount of clusters each algorithm should have. Seriously thank you for the feedback. It means a lot. Very helpful.", "aSentId": 629, "answer": "Quick response now, longer to follow:\n\nIn your training section you mention h_x and h_theta without defining them for instance. While I assume that h_x is the x vector in the hybrid feature vector h, it is not obvious at first glance. If you are going to use h_x and h_theta, you should define them as such in your notation for your feature vector or you should explicitly state it. Anything that makes the paper harder to read will make the journal editor unhappy with it.\n\nAnd with that performance with those small sample sizes: how did that accuracy change when you select a different sample of size 3 or 10 respectively?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 630, "question": "Quick response now, longer to follow:\n\nIn your training section you mention h_x and h_theta without defining them for instance. While I assume that h_x is the x vector in the hybrid feature vector h, it is not obvious at first glance. If you are going to use h_x and h_theta, you should define them as such in your notation for your feature vector or you should explicitly state it. Anything that makes the paper harder to read will make the journal editor unhappy with it.\n\nAnd with that performance with those small sample sizes: how did that accuracy change when you select a different sample of size 3 or 10 respectively?", "aSentId": 631, "answer": "I lied, no longer response to follow as I have to take care of some other things.\n\nTake care and good luck!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 632, "question": "I lied, no longer response to follow as I have to take care of some other things.\n\nTake care and good luck!", "aSentId": 633, "answer": "Its fine! Thank you for everything!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 634, "question": "Its fine! Thank you for everything!", "aSentId": 635, "answer": "I lied again, I did take a look at it again and I understand it better now. I dont think it's not really that much like K-means or GMMs, I just misunderstood it a bit before. It's more like some sort of local neighborhood classifier. \n\nI still have concern about the cases where you train n=1 for each class. How do you get the \"planet radii\" for those cases? With 1 value for each class you have nothing to indicate how big each class should be, so the planets should have the same radii and mass. You should get identically the same results as 1-nearest neighbor or k-means for those problems because your method would basically predict that a new value is the same class as whichever data point it is nearest to. The performance then really just depends on a lot of things like how well separated the classes are, whether each class has approximately the same number of samples or not, how well connected the true class boundaries are etc.  \n\nFor instance, if I gave you n=2 (x=1, theta=1) and (x=10,theta=2) I think your method would classify anything greater than 5.5 to class 2 and anything less than class 1. This method would be really bad if the true classes were {class 1: odd integers}, {class 2: even integers}. It would also be ok if the classes were {class 1: x&lt;2}, {class 2: x&gt;=2}, but not really great. It would also be bad if {class 1:generated by N(1,0.01)} and {class 2: generated by N(0,100)}.\n\nIn truth, no classification algorithm will do well with such little data, unless the groups are really easily separable, in which case many things will do pretty much equally well/badly. I think your method is really neat, but I think that using it's performance with 1 sample per class to argue for it is somewhat misguided. I think focusing on your other examples is better possibly adding a case with a simulated data example that is designed to show a case where other methods work badly and yours works well.\n\nAlso, changing topic and going back to something I mentioned before: I really recommend adding details on how you choose some of your parameters like the initial planet radii and such. If you want people to use the algorithm, you'll want to make it very clear how to implement it so that it's easy for them to do so. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 614, "question": "This seems pretty similar to KNN/K-means. I'm not sure why there's this whole simulation instead of just finding the closest \"planet.\"", "aSentId": 637, "answer": "This paper is a fake paper.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 638, "question": "This paper is a fake paper.", "aSentId": 639, "answer": "I'm about to submit this later today! I just wanted feedback on it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 604, "question": "Novel Supervised Machine Learning Algorithm Called Gravitational Clustering", "aSentId": 641, "answer": "Wow I didn't expect this from you guys. But let me just clarify for anyone that says it's a fake and that I'm pretending to have a published. \nI just wrote this paper using an IEEE template, I had no intention of trying to make it look like I published something. I had to use this template because I'm submitting this to IEEE later today. It is not similar to knn due to the fact that it builds a prototypical system with which it classifies. It does not just compare with near by points. Please ask me before throwing out statements that might not be true. \nThank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 642, "question": "Wow I didn't expect this from you guys. But let me just clarify for anyone that says it's a fake and that I'm pretending to have a published. \nI just wrote this paper using an IEEE template, I had no intention of trying to make it look like I published something. I had to use this template because I'm submitting this to IEEE later today. It is not similar to knn due to the fact that it builds a prototypical system with which it classifies. It does not just compare with near by points. Please ask me before throwing out statements that might not be true. \nThank you.", "aSentId": 643, "answer": "It kinda tells you most people who lurk here have very little academic experience.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 644, "question": "It kinda tells you most people who lurk here have very little academic experience.", "aSentId": 645, "answer": "They ended up deleting their comments. They should leave their comment up as a reminder", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 647, "question": "Hey, great algorithm.\n\nBut did you check with IEEE if you are allowed to publish the paper before the conference/journal is printed? It seems that they normally have copyright for their articles etc.", "aSentId": 648, "answer": "I don't know about IEEE, but many journals allow it to be online before they accept it. Once it's slated for publication, they request it either be removed, or in some cases they say the site should clearly have a link to the IEEE page. They also then demand the non-IEEE version not have the journal's name in the actual PDF, etc. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 647, "question": "Hey, great algorithm.\n\nBut did you check with IEEE if you are allowed to publish the paper before the conference/journal is printed? It seems that they normally have copyright for their articles etc.", "aSentId": 650, "answer": "If they ask me to take it down I will :) I just wanted some feedback and just to generally put it out to the public. Although it seems I didn't get that many constructive comments, I still think it had a generally positive effect on the community. Thanks for the interest!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 652, "question": "New Talking Machines: Second part of conversation with Hinton, Bengio, LeCun", "aSentId": 653, "answer": "Is this me or Geoffrey Hinton implied that he might already have next big idea that will succeed Deep Learning?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 654, "question": "Is this me or Geoffrey Hinton implied that he might already have next big idea that will succeed Deep Learning?  ", "aSentId": 655, "answer": "I'm pretty sure Hinton has never given a talk or interview where he hasn't implied he already has the next big idea that will revolutionize AI.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 657, "question": "DeepNetwork Super-power: Can it recognize Arc de Triomphe?", "aSentId": 658, "answer": "Better yet, predictions from commercially deployed system, Clarifai:\n\ncity\n\ntravel \n\nbuilding \n\nnight \n\narchitecture \n\nhouse \n\nculture \n\nstreet \n\ntourism \n\nhistory\n\nAnd similar images all seems relevant.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 660, "question": "A little help with the calculus, in Hinton's NN course", "aSentId": 661, "answer": "It is not particularly difficult when you break it down, just tedious.\n\nhttp://imgur.com/i1jZUAC,29YtfLI\n\nFor the first one, dp/dx_i shouldn't have partial derivative signs, just regular ones. Too lazy to fix it now.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 662, "question": "It is not particularly difficult when you break it down, just tedious.\n\nhttp://imgur.com/i1jZUAC,29YtfLI\n\nFor the first one, dp/dx_i shouldn't have partial derivative signs, just regular ones. Too lazy to fix it now.", "aSentId": 663, "answer": "Thank you! I made the mistake (as rightly guessed by /u/dwf) that I didn't take into account \u2202p_j/\u2202x_i , since I assumed it was independent of x_i ; but it's not! \n\nThank you, /u/DomMk for the fully worked out problem (it was really helpful!), and to /u/dwf and /u/nkorslund  also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 660, "question": "A little help with the calculus, in Hinton's NN course", "aSentId": 665, "answer": "It's a bit tricky, you have to use the chain rule correctly here. Note that he's skipping a lot of lines of calculation, you're not supposed to instantly \"see\" that this is the correct result. It's worth doing it out in full on paper though, since the softmax function is so important in NNs.\n\nTo calculate dE/dxi, you have to use the chain rule via dE/dpi and dpi/dxi. However, since p_i depends on ALL the x's, not just x_i, you have to include the full sum:\n\n    dE/dx_i = sum(dE/dp_k * dp_k/dx_i , over k)\n\nThe rest is left as an exercise ;)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 660, "question": "A little help with the calculus, in Hinton's NN course", "aSentId": 667, "answer": "I haven't looked at that course and without more information I'm  not sure how much calculus you are comfortable with.  But if you are comfortable with partial derivatives and just aren't sure how they got the result into that form, you may want to try making a little example for yourself.\n\nWhen I worked through it the first thing I noticed was that the only place x_i shows up is in the p terms.  Important to notice that x_i is in the numerator only in p_i but is in the denominator for every p term.  If you make your example so that i is only over 1, 2 and 3 that simplifies what you are dealing with and you just have to use the quotient rule and some algebraic manipulation.  The manipulation is a little bit of a hassle, but knowing your target should help guide your choices.", "corpus": "reddit"}]