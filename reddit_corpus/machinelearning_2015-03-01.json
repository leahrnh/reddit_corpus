[{"docID": "t5_2r3gv", "qSentId": 33131, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 33132, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33133, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 33134, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33131, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 33136, "answer": "What are the next big things that you want to (or will) happen in the world of recurrent neural nets?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33131, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 33138, "answer": "How do you recognize a promising machine learning phd student?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33140, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 33141, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33142, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 33143, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33151, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 33152, "answer": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33153, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 33154, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33151, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 33156, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33151, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 33158, "answer": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33159, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 33160, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33161, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 33162, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33170, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 33171, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33172, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 33173, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33174, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 33175, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33184, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 33185, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33186, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 33187, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33184, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 33189, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33190, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 33191, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33192, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 33193, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33190, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 33195, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33196, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 33197, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33218, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 33219, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33223, "question": "What is the algorithm of love?\n", "aSentId": 33224, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33223, "question": "What is the algorithm of love?\n", "aSentId": 33226, "answer": "In response to the foolish comment: I am not a chinaman, but you are a racist village idiot.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33228, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 33229, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33232, "question": "Yann LeCun bashing the MIT review for bad reporting", "aSentId": 33233, "answer": "Convnets over sliding windows of the image is a decent solution for face detection, but it's rather slow given how easy the task is.  Viola-Jones has been behind the state of the art for quite a while, but it's still popular because it's very fast.  \n\nI suspect that the key to better face detection is mining hard negatives.  It's easy to get a dataset with lots of faces and random non-faces that you can train a classifier on, but the dataset won't have enough \"difficult non-faces\".  Hands, ears, and some organic patterns are easy to confuse with faces but unlikely to be found randomly.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33238, "question": "Machine Learning Done Wrong - Some common mistakes", "aSentId": 33239, "answer": "Are there any resources that describe different ways to customize an algorithm so that it is no longer \"off-the-shelf\"?\n\nIn the example of credit card fraud detection, the author says that you should weight false negatives heavier than false positives, which makes sense.  But if you made the dependent variable \"Amount defrauded\" you would already be doing this wouldn't you?  I understand the notion that in most real applications, minimizing MSE isn't really the objective, but I don't really understand what people mean when they say to customize an algorithm.  Unless they mean code a new algorithm with mechanics borrowed from off -the-shelf models, but a different optimization parameter, in which case, I understand, but don't see how a beginner would be expected to do so.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33240, "question": "Are there any resources that describe different ways to customize an algorithm so that it is no longer \"off-the-shelf\"?\n\nIn the example of credit card fraud detection, the author says that you should weight false negatives heavier than false positives, which makes sense.  But if you made the dependent variable \"Amount defrauded\" you would already be doing this wouldn't you?  I understand the notion that in most real applications, minimizing MSE isn't really the objective, but I don't really understand what people mean when they say to customize an algorithm.  Unless they mean code a new algorithm with mechanics borrowed from off -the-shelf models, but a different optimization parameter, in which case, I understand, but don't see how a beginner would be expected to do so.", "aSentId": 33241, "answer": "No, his point about loss function is a little more subtle. If you used \"amount defrauded\" as your output, an L2 loss would penalize predictions that (erroneously) predict large fraud the same as those that *miss* large fraud (ie. predict normal behavior when significant fraud is occurring). Maybe this is the right balance, but the business might prefer to play it conservatively and say \"I'm willing to flag potentially legit behavior as fraud so long as my model never misses real fraud\", in which case you really want to weight the loss function asymmetrically. \n\nEdit: After re-reading, it's possible you meant to keep it a classification problem and weight the cost of erroneous predictions by the amount defrauded (so that false 'fraud' predictions don't count against the model, since the defrauded amount is 0 for a false positive). That's not a bad idea and would probably work. I thought you meant to change it to a regression problem to predict for amount defrauded.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33240, "question": "Are there any resources that describe different ways to customize an algorithm so that it is no longer \"off-the-shelf\"?\n\nIn the example of credit card fraud detection, the author says that you should weight false negatives heavier than false positives, which makes sense.  But if you made the dependent variable \"Amount defrauded\" you would already be doing this wouldn't you?  I understand the notion that in most real applications, minimizing MSE isn't really the objective, but I don't really understand what people mean when they say to customize an algorithm.  Unless they mean code a new algorithm with mechanics borrowed from off -the-shelf models, but a different optimization parameter, in which case, I understand, but don't see how a beginner would be expected to do so.", "aSentId": 33243, "answer": "&gt;But if you made the dependent variable \"Amount defrauded\" you would already be doing this wouldn't you?  \n\nPretty much, yes. Asking yourself what you're really trying to do often gives you a better loss function.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33238, "question": "Machine Learning Done Wrong - Some common mistakes", "aSentId": 33245, "answer": "The whole article could be replaced with **DON'T USE TECHNIQUES YOU DON'T UNDERSTAND** in a 72pt font.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33246, "question": "The whole article could be replaced with **DON'T USE TECHNIQUES YOU DON'T UNDERSTAND** in a 72pt font.", "aSentId": 33247, "answer": "Sure, but that's not really helpful to anyone. In order to actually *get* understanding in the first place you have to learn it or be taught it somehow. Don't go all \"this knowledge is useless\" on this article just because you personally know it already. None of this stuff is obvious to beginners.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33248, "question": "Sure, but that's not really helpful to anyone. In order to actually *get* understanding in the first place you have to learn it or be taught it somehow. Don't go all \"this knowledge is useless\" on this article just because you personally know it already. None of this stuff is obvious to beginners.", "aSentId": 33249, "answer": "&gt; Don't go all \"this knowledge is useless\" on this article just because you personally know it already. \n\nAnyone who knows enough ML to make use of those points *should* have studied enough theory to be aware of those points already. If someone's read that article and been surprised by something in it, their practical skills have significantly exceeded their theoretical understanding, and they should stop coding and find a book before they do any more damage.\n\nThis is the best example:\n\n&gt; 5. L1/L2/... regularization without standardization\n\nThe only way you could apply regularization without bothering to standardize your data first is if you don't know what regularization actually is.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33250, "question": "&gt; Don't go all \"this knowledge is useless\" on this article just because you personally know it already. \n\nAnyone who knows enough ML to make use of those points *should* have studied enough theory to be aware of those points already. If someone's read that article and been surprised by something in it, their practical skills have significantly exceeded their theoretical understanding, and they should stop coding and find a book before they do any more damage.\n\nThis is the best example:\n\n&gt; 5. L1/L2/... regularization without standardization\n\nThe only way you could apply regularization without bothering to standardize your data first is if you don't know what regularization actually is.", "aSentId": 33251, "answer": "&gt; and they should stop coding and find a book before they do any more damage.\n\nNo. They should continue coding, as it provides valuable learning experiences, and guides them in strengthening their weaknesses on the theoretical side. Telling people to read 400 pages monographs before they are allowed to do regularized regression would turn 99% away from the field (maybe you would like that? In any case, it's not pragmatic)\n\n\nOf course, that code shouldn't end up in production without a thorough review, nor be relied upon for critical decisions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33238, "question": "Machine Learning Done Wrong - Some common mistakes", "aSentId": 33253, "answer": "In regards to the point about taking the default loss function for granted: I have this dataset I've been working on that has, along with the data relevant to the task, a probability estimate for the output class. In this problem, the data is very noisy and it's not like an MNIST set where you can achieve 98-99% accuracy. What I'm most interested in is finding where the given estimates are off from reality. I've been using the standard loss function and so far, the noisiness of the data seems to be problematic. Would it make sense to use some custom loss function that involves the differential from the probability estimate in the training data?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33254, "question": "In regards to the point about taking the default loss function for granted: I have this dataset I've been working on that has, along with the data relevant to the task, a probability estimate for the output class. In this problem, the data is very noisy and it's not like an MNIST set where you can achieve 98-99% accuracy. What I'm most interested in is finding where the given estimates are off from reality. I've been using the standard loss function and so far, the noisiness of the data seems to be problematic. Would it make sense to use some custom loss function that involves the differential from the probability estimate in the training data?", "aSentId": 33255, "answer": "&gt; What I'm most interested in is finding where the given estimates are off from reality\n\nWhat do you mean?  Where your model's estimates are off from reality?  If your model knew that it was off from reality, it would just produce different estimates.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33256, "question": "&gt; What I'm most interested in is finding where the given estimates are off from reality\n\nWhat do you mean?  Where your model's estimates are off from reality?  If your model knew that it was off from reality, it would just produce different estimates.  ", "aSentId": 33257, "answer": "Sorry for the ambiguity. The estimates are a feature in the training data not generated by my model. I'm interested in essentially doing better than these estimates. They are largely accurate and removing them from the training data seems to always decrease the accuracy and the AUC values.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33258, "question": "Sorry for the ambiguity. The estimates are a feature in the training data not generated by my model. I'm interested in essentially doing better than these estimates. They are largely accurate and removing them from the training data seems to always decrease the accuracy and the AUC values.", "aSentId": 33259, "answer": "Some random googling turned up this article: [Training Deep Neural Networks on Noisy Labels](http://arxiv.org/abs/1412.6596). Looks like it deals with exactly your problem.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33265, "question": "Visual explanation to Markov Chains", "aSentId": 33266, "answer": "These visualizations are great! May I ask which software was used to create them? Thanks.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33268, "question": "Library for Hyperparameter Optimization Over AWS", "aSentId": 33269, "answer": "please do, sounds awesome.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33268, "question": "Library for Hyperparameter Optimization Over AWS", "aSentId": 33271, "answer": "I think hyperopt supports a bunch of worker processes (potentially on different machines) coordinated by mongo db process. But they don't have a bayesiam parameter optimization implementation yet.\n\nContributing one could be a good use of you're time, I've found the open source spearmint to be quite buggy and unstable and the license they are doing new development under is pretty bad.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33275, "question": "Can we create a computer algorithm that untangles philosophical debates?", "aSentId": 33276, "answer": "How about this, you could straithjacket your philosophers by restricting your requirement of following a path and demand that their argumentations follow a notion of a logical order, whose topological sort is linear and then you have a precise notion of deviance from the path. In version zero you demand your philosophers to argue with a formal language and your algorithm is a theorem prover. In release you allow natural language in each step of the argument and start to look at the current state of the solutions to the [text entailment](http://aclweb.org/aclwiki/index.php?title=Textual_Entailment_Portal) task of computational linguistics. Practical results are one thing, but this is a positive-mood answer for the possibility question.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33277, "question": "How about this, you could straithjacket your philosophers by restricting your requirement of following a path and demand that their argumentations follow a notion of a logical order, whose topological sort is linear and then you have a precise notion of deviance from the path. In version zero you demand your philosophers to argue with a formal language and your algorithm is a theorem prover. In release you allow natural language in each step of the argument and start to look at the current state of the solutions to the [text entailment](http://aclweb.org/aclwiki/index.php?title=Textual_Entailment_Portal) task of computational linguistics. Practical results are one thing, but this is a positive-mood answer for the possibility question.", "aSentId": 33278, "answer": "Good idea! I just downloaded the RTE challenge paper about text entailment that you've linked to, and I don't see why it wouldn't work once the 'straithjacketing phase' and the 'proofing phase' have been overcome. Would you mind sketching a pseudocode for your proposal, so that I can visualize it more easily. Thank you very much:)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33279, "question": "Good idea! I just downloaded the RTE challenge paper about text entailment that you've linked to, and I don't see why it wouldn't work once the 'straithjacketing phase' and the 'proofing phase' have been overcome. Would you mind sketching a pseudocode for your proposal, so that I can visualize it more easily. Thank you very much:)", "aSentId": 33280, "answer": "Haven't thought much seriously really, but for the sake of the fun one can take inspiration from expert systems doing forward chaining, you could start with a bag of common sense facts in the vein of cyc. One argumentation would be a tree, leaves facts, and to verify an inner node you compound the text of the children in a big paragraph joining with full stops or maybe \"and\" conjunctions, and then would check if the big children's paragraph text-entail the parent's text. Doing this recursively you verify the root, the would-be conclusion (or would spot the offending input somewhere). Really instead of a tree, generally a directed acyclic graph. You demand that each step is labeled and that the philosopher say which previous intermediate states justify a new given one. But note the host of potential problems (coverage of common facts, weakness in RTE, brittleness...), it's true that we are not already there.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33275, "question": "Can we create a computer algorithm that untangles philosophical debates?", "aSentId": 33282, "answer": "The level of language understanding required for this is way beyond anything that has ever been built.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33283, "question": "The level of language understanding required for this is way beyond anything that has ever been built.", "aSentId": 33284, "answer": "The issue of high level understanding of human language that you raise is interesting, but couldn't something like HTM(Hierarchical Temporal Memory) proposed by Jeff Hawkins in his book *On Intelligence* work? \nGiven enough computational capability, a machine 'listening' to two sides debating would be able to catch or predict when one of the two parties fell into a fallacy, and thus either correct or present them with a 'truer'(or closer meaning to each argument) path that the debate could take.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33285, "question": "The issue of high level understanding of human language that you raise is interesting, but couldn't something like HTM(Hierarchical Temporal Memory) proposed by Jeff Hawkins in his book *On Intelligence* work? \nGiven enough computational capability, a machine 'listening' to two sides debating would be able to catch or predict when one of the two parties fell into a fallacy, and thus either correct or present them with a 'truer'(or closer meaning to each argument) path that the debate could take.", "aSentId": 33286, "answer": "I agree that there's no in-principle reason why your idea wouldn't be possible.  But the fact remains that no one has figured out how to build anything with even close to the level of language understanding that is needed to dissect a philosophical debate. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33275, "question": "Can we create a computer algorithm that untangles philosophical debates?", "aSentId": 33288, "answer": "Not even humans know what philosophers are on about, so I'd say it's a tall order at this point. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33291, "question": "Google's R Style Guide", "aSentId": 33292, "answer": "Now if someone can make this into a sublime package", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33291, "question": "Google's R Style Guide", "aSentId": 33294, "answer": "I have no clue why they thought that the 'variable.name' style would be a good idea.\n\nIn R a '.' in a function's name can have meaning - such as plot.lm, summary.lm, etc. These are methods for specific types of objects.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33295, "question": "I have no clue why they thought that the 'variable.name' style would be a good idea.\n\nIn R a '.' in a function's name can have meaning - such as plot.lm, summary.lm, etc. These are methods for specific types of objects.", "aSentId": 33296, "answer": "Most people use **.** instead of **_**, I think Google is just going by the most common convention here.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33295, "question": "I have no clue why they thought that the 'variable.name' style would be a good idea.\n\nIn R a '.' in a function's name can have meaning - such as plot.lm, summary.lm, etc. These are methods for specific types of objects.", "aSentId": 33298, "answer": "Google usually uses `_` for separation, but `.` is by far more common for `R` so they just went with what is idiomatic. For example, even though in the `R` language the `.` character can have meaning, R-core uses `.` for separation rather than `_`. ESS even defaults to overriding `_` with `&lt;-`. If I had to guess, the use of `.` in R-core might be related to legacy issues with S-plus. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33295, "question": "I have no clue why they thought that the 'variable.name' style would be a good idea.\n\nIn R a '.' in a function's name can have meaning - such as plot.lm, summary.lm, etc. These are methods for specific types of objects.", "aSentId": 33300, "answer": "This is not just Google - pretty much the standard naming convention in R", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33302, "question": "Running DeepMinds \"Atari AI\" on a HomePC,", "aSentId": 33303, "answer": "Your hardware is hugely more powerful than you need to run that network.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33304, "question": "Your hardware is hugely more powerful than you need to run that network.  ", "aSentId": 33305, "answer": "C'mon, the guy just wanted to brag about his two GPUs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33306, "question": "C'mon, the guy just wanted to brag about his two GPUs.", "aSentId": 33307, "answer": "Inb4 google employee brags about 5000 :P", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33304, "question": "Your hardware is hugely more powerful than you need to run that network.  ", "aSentId": 33309, "answer": "I would just like to ask out of genuine curiosity, if this network can be run on such cheap hardware, what does Deepmind do with the millions of dollars of investment it has?.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33310, "question": "I would just like to ask out of genuine curiosity, if this network can be run on such cheap hardware, what does Deepmind do with the millions of dollars of investment it has?.", "aSentId": 33311, "answer": "Presumably they use it to pay the people who come up with these ideas.\n\nThere's also a lot of other things going on at DeepMind that aren't atari-playing-convnets.  They've published several papers in the past few years that have nothing to do with atari, including their neural turing machine.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33310, "question": "I would just like to ask out of genuine curiosity, if this network can be run on such cheap hardware, what does Deepmind do with the millions of dollars of investment it has?.", "aSentId": 33313, "answer": "Its much easier/faster to run a network than to train it on a huge dataset.  When you do backprop you have to store intermediate information at each layer and if you have a large high-res conv-net and use mini-batches this can require a lot of GPU RAM (which wouldn't be needed to just run without training).  Also, if you have a large network then you generally want a very large dataset and running through that can take a long time if you don't parallelize it.  IIRC the atari game uses a convnet as its front-end and 50 million frames is large even by conv-net standards.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33302, "question": "Running DeepMinds \"Atari AI\" on a HomePC,", "aSentId": 33315, "answer": "If by \"run\" you mean that you just want to use the trained networks and see how they play, then that should be no problem.\n\nIf by \"tinker\" you mean that you want to change the parameters and train the network, then I'm not so sure. Apparently DeepMind trained each network every 4th frame for 50 million frames with minibatches of 32. For reference, just emulating the game at the default speed of 60 fps while training a minibatch at 15Hz would take 38.6 days. On your hardware it would presumably be a lot faster, but if you want to try out multiple parameter sets and games, then I suspect it would still be quite slow on one computer.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33302, "question": "Running DeepMinds \"Atari AI\" on a HomePC,", "aSentId": 33317, "answer": "Really the only requirement you would have to worry about for GPU running would be video memory. An amazon GPU instance has 4gb I believe, and the 970 has essentially 4gb, but the 970 should be faster. If you want to try it out I would recommend getting a linux build up and installing everything on that. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33319, "question": "Two GTX 970s will be more than enough to get it to run. \n\nI haven't gotten it to run yet, but after looking at the source code for a few hours to see what exactly it's doing, I'm pretty sure a mid-range laptop wouldn't have a hard time churning through it. Two super-powerful GPUs will be more than enough. \n\nI haven't been able to get it to actually work yet (I keep running into some issue with install Torch and/or Luajit, not sure which), but those two GPUs will be more than enough to burn through this. ", "aSentId": 33320, "answer": "I've been trying to get it running as well and I keep getting a Segfault. Using GDB it's this:\n\n    Program received signal SIGSEGV, Segmentation fault.\n    0x00007ffff313c54f in ale::StellaEnvironment::emulate(ale::Action, ale::Action, unsigned long) () from .../torch/lib/libxitari.so\n\nI tried Breakout. Did you have any luck?\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33321, "question": "I've been trying to get it running as well and I keep getting a Segfault. Using GDB it's this:\n\n    Program received signal SIGSEGV, Segmentation fault.\n    0x00007ffff313c54f in ale::StellaEnvironment::emulate(ale::Action, ale::Action, unsigned long) () from .../torch/lib/libxitari.so\n\nI tried Breakout. Did you have any luck?\n", "aSentId": 33322, "answer": "I ran the CPU version here without a problem.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33323, "question": "I ran the CPU version here without a problem.", "aSentId": 33324, "answer": "I get the same error on both CPU and GPU. Maybe I'll try it on an Ubuntu machine...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33323, "question": "I ran the CPU version here without a problem.", "aSentId": 33326, "answer": "Well, poop... I did it the same on a XUbuntu machine and Xitari still crashes with a segfault on both CPU and GPU. Can you tell me what system you ran it on? Did you use the provided \"install_dependencies.sh\" script?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33327, "question": "Well, poop... I did it the same on a XUbuntu machine and Xitari still crashes with a segfault on both CPU and GPU. Can you tell me what system you ran it on? Did you use the provided \"install_dependencies.sh\" script?", "aSentId": 33328, "answer": "I run Arch Linux and I used the dependency installer script. As some parts are Debian/Ubuntu-specific (apt-get), I edited those, but nothing else, really. It compiled and ran trivially afterwards. Make sure to run \"htop\" or something similar for shenanigans like running out of memory. I needed to edit some of the parameters in the run_cpu file as it ate my 8GB memory in a matter of seconds with the default parameter set. Try lowering some of the numbers that sound like they are memory-related (I'd look them up, but I'm on a different machine). Or just try to lower every parameter by orders of magnitude and see if it runs with that parameter set.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33329, "question": "I run Arch Linux and I used the dependency installer script. As some parts are Debian/Ubuntu-specific (apt-get), I edited those, but nothing else, really. It compiled and ran trivially afterwards. Make sure to run \"htop\" or something similar for shenanigans like running out of memory. I needed to edit some of the parameters in the run_cpu file as it ate my 8GB memory in a matter of seconds with the default parameter set. Try lowering some of the numbers that sound like they are memory-related (I'd look them up, but I'm on a different machine). Or just try to lower every parameter by orders of magnitude and see if it runs with that parameter set.", "aSentId": 33330, "answer": "No way man. I ran it on a 256 GB RAM computer with 32 cores so memory isn't an issue. It has to be a bug in the code, but it's annoying to debug since everything is compiled without symbols and GDB doesn't show anything. Cmake also didn't show any errors. A few Warning maybe, but I suppose everyone gets that.\n\nWell, thanks for the hints. I'll keep trying, I guess. Maybe recompiling it with debug symbols will help...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33329, "question": "I run Arch Linux and I used the dependency installer script. As some parts are Debian/Ubuntu-specific (apt-get), I edited those, but nothing else, really. It compiled and ran trivially afterwards. Make sure to run \"htop\" or something similar for shenanigans like running out of memory. I needed to edit some of the parameters in the run_cpu file as it ate my 8GB memory in a matter of seconds with the default parameter set. Try lowering some of the numbers that sound like they are memory-related (I'd look them up, but I'm on a different machine). Or just try to lower every parameter by orders of magnitude and see if it runs with that parameter set.", "aSentId": 33332, "answer": "One more idea. Maybe it's a bug in the ROM I downloaded. Can you let me know what rom you got?\n\nEDIT: alternatively can you confirm the md5sum for me of this: f34f08e5eb96e500e851a80be3277a56  Breakout.bin\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33335, "question": "Weka vs Scikit-learn?", "aSentId": 33336, "answer": "Weka (IMHO) is great for two things:  learning about data science, and testing very well-known machine learning algorithms on small datasets.  If feature engineering is where your work really is, then Weka might be appropriate.  Otherwise, scikit-learn (and virtually everything else) will probably be a better tool due to ease of integration, more modern algorithms, and better memory management.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33335, "question": "Weka vs Scikit-learn?", "aSentId": 33338, "answer": "Weka requires no code: just set your data sets, classifiers, and filters, and go. It's great for quick \"what if\" experimenting. Sklearn is better for more novel things.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33339, "question": "Weka requires no code: just set your data sets, classifiers, and filters, and go. It's great for quick \"what if\" experimenting. Sklearn is better for more novel things.", "aSentId": 33340, "answer": "i find sklearn super simple to play with :/", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33339, "question": "Weka requires no code: just set your data sets, classifiers, and filters, and go. It's great for quick \"what if\" experimenting. Sklearn is better for more novel things.", "aSentId": 33342, "answer": "You can embed Weka if you like, however.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33339, "question": "Weka requires no code: just set your data sets, classifiers, and filters, and go. It's great for quick \"what if\" experimenting. Sklearn is better for more novel things.", "aSentId": 33344, "answer": "Sounds a bit like: \"It's ok, this code isn't code!\". ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33349, "question": "Index-learning -- a novel form of NN for UL on high-entropy data (pdf)", "aSentId": 33350, "answer": "A somewhat similar approach to unsupervised learning was explored in this NIPS 2014 paper: http://arxiv.org/abs/1406.6909 They relied chiefly on aggressive data augmentation to make this work. The most interesting / novel thing about \"index-learning\" is probably the dropout-like procedure used in the output layer.\n\nFrom the paper it's hard to tell how this compares to more traditional approaches like autoencoders, though. Evaluating unsupervised learning is a bit of a challenge, but it would be interesting to train a shallow classifier on top of two low-dimensional representations, one learned with this method, and one learned with an autoencoder, to get some quantitative results.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33349, "question": "Index-learning -- a novel form of NN for UL on high-entropy data (pdf)", "aSentId": 33352, "answer": "My own random notes: \n\nAutoencoders are an unsupervised learning method.  They transform the input into a low-dimensional space (e.g., via a sequence of neural network layers) [encoder stage], and then try to reconstruct the input [decoder stage].  This can be useful for pretraining an artificial neural network (ANN).  After pretraining, throw away the decoder.  \n\nThe idea here is that, instead of reconstructing the input, just try to recover the *index* of the input.  So, for example, to pre-train on the MNIST dataset with 60,000 images, throw away the labels and train a network like: \n\t(big complicated neural net)-(100 unit layer)-(60,000 unit output layer).  \nThen throw away the last layer to get a 100-dimensional embedding of the data.  You can use principal components analysis (PCA) to reduce the dimensionality further.  \n\nHe gives a toy example where unsupervised index-learning should perform better than unsupervised auto-encoder learning.  There are two classes, p=.4 and p=.6.  To generate a data point in a class, you generate a binary string x in {0,1}^100 where Pr[x_j = x_{j-1}] = p, independently for each index.  \nIntuitively, since there are 97 bits of entropy (1 [for x_1] + 99 (-p Log[2, p] - (1 - p) Log[2, 1 - p])), an autoencoder with final size much less than that can't be expected to recover the input.  (This isn't rigorous since the signals are real numbers, so can store more than one bit per neuron unit, but close enough.)  \nBut, he shows, an index-learner can give a useful 100-dimensional embedding of the 10,000 data points.  See the first two PCA components in Fig. 1.  \n\nA problem is that the last layer is large, so training might be difficult, and especially so for large datasets.  He gives a couple ideas for how to train index learners.  \n\n1. Doubled-up minibatch gradient descent: Select mini-batches of the input, say 10 data points at a time, indices i_1,...,i_10.  Instead of worrying about the whole 60000x100 final weight matrix, just pick out the 10 rows i_1,...,i_10.  Perform gradient descent on that, with a softmax loss just on those 10 classes' scores.  This is faster than multiplying by the full matrix and computing the full softmax, and in practice apparently still helps the network learn.   \n\n2. Autoregressive dropout: This is a form of dropout on the entries of the last weight matrix (60000x100 in the above example).  Since each row of this matrix is used only once per iteration of the training set, there is a little bit of trickiness here.  I think dropout is extremely important here, to prevent overfitting on input noise.  \n\nThis is a simple and tentative paper, but perhaps Graham is right that there is potential for the idea.  We do need better ways of unsupervised learning.  \n(Note, though, that autoencoders are not so often used now.  They were used quite a lot around 2007, because deep nets would get stuck in training if the weights weren't first initialized by [layer-wise] autoencoder pretraining.  But recent image classification deep convolutional neural nets only do supervised training.  Dropout regularization, and better choice of the initial random weights, allows the networks to train successfully.)  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33349, "question": "Index-learning -- a novel form of NN for UL on high-entropy data (pdf)", "aSentId": 33354, "answer": "This looks to me like WSABIE with some minor tweaks.\n\n- The \"annotations\" are indexes into the training set instead of being arbitrary.\n- The loss function, and the way of dealing with lots of labels/annotations, is based on a softmax instead of max margin.\n- The data encoder is deep (it's shallow in the original WSABIE paper, but fancier versions of WSABIE have been done).\n\nIt's also similar to siamese nets, although there you're usually pairing inputs and you use the same encoder for both of them.  The loss function there is different too.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33359, "question": "Beginning deep learning with 500 lines of Julia", "aSentId": 33360, "answer": "Link? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33362, "question": "Build a monster machine, or master AWS?", "aSentId": 33363, "answer": "AWS can get very expensive. Unless you need a distributed environment go for the bare metal option.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33362, "question": "Build a monster machine, or master AWS?", "aSentId": 33365, "answer": "I'm biased towards building the PC so that you actually have it, although I have heard good arguments for doing the cloud approach. You can build a fine desktop for about $1000 that also doubles for a gaming PC, then upgrade the components as needed.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33366, "question": "I'm biased towards building the PC so that you actually have it, although I have heard good arguments for doing the cloud approach. You can build a fine desktop for about $1000 that also doubles for a gaming PC, then upgrade the components as needed.\n\n", "aSentId": 33367, "answer": "I agree. That flexibility is a big thing.\n\nA cloud is nice because you can leverage large amounts of processing power from any device with ssh capabilities and you don't have to worry about replacing hardware. But you really can't do much as with it\n\nA PC could provide a comparable amount of power for a fraction of the cost over time (depending on how you build it of course) but you aren't limited to using it just for its processing power. You can browse the internet, play games, etc.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 33362, "question": "Build a monster machine, or master AWS?", "aSentId": 33369, "answer": "I got a GTX 970, bought 16GB of RAM from someone that bought DDR3 but actually needed DDR2, so never actually used it. Bought some shitty 5 or so year old motheboard used from some dude, which came with a gpu. Put on my favourite open source OS. Cases are stupid cheap. \n\nMy internet connection is bad (1Mb/s) that I can't really stand sshing into MS Azure or AWS, plus i3 is really really awesome.\n\n400 + 125 + 20 == 545$", "corpus": "reddit"}]