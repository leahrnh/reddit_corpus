[{"docID": "t5_2r3gv", "qSentId": 46167, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 46168, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46169, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 46170, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46171, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 46172, "answer": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46173, "question": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "aSentId": 46174, "answer": "RNNLIB is provided as source, which you have to compile yourself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46175, "question": "RNNLIB is provided as source, which you have to compile yourself.", "aSentId": 46176, "answer": "RNNLIB is the exception rather than the rule as far as I can tell.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46167, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 46178, "answer": "What are the next big things that you a) want to or b) will happen in the world of recurrent neural nets?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46167, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 46180, "answer": "What do you think about learning selective attention with recurrent neural networks?  What do you think are the promising methods in this area?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46191, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 46192, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46193, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 46194, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46195, "question": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "aSentId": 46196, "answer": "As you see, they may have better personal relationships ... that's it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46199, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 46200, "answer": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46201, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 46202, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46203, "question": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "aSentId": 46204, "answer": "An exponential activation would have as its derivative... an exponential. Gradient descent would be pretty messy with such a wild dynamic range.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46199, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 46206, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46199, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 46208, "answer": "I think I recall Hinton giving an answer to this in his MOOC: we like activations, from which derivatives can be computed easily in terms of the function value itself. For sigmoid the derivative is s(x) * (1 - s(x)) for example.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46211, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 46212, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46213, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 46214, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46236, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 46237, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46238, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 46239, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46240, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 46241, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46245, "question": "(in relation to the Atari paper and partly on your statement about it)\n\nWhat do you personally think about using a diverse selection of video games as a learning problem / \"dataset\"?\n\nOne thing I found interesting about the DeepMind Nature paper is that they could not solve Montezuma's Revenge at all (the game, not the travel problem), which is an action-adventure game requiring some kind of real-world knowledge / thinking - and temporal planning, of course. As any Atari game, conceptually it is still rather simple.\n\nI wonder what would happen if we found an AI succeeding over a wide range of complex game concepts like e.g. Alpha Centauri / Civilization, SimCity, Monkey Island II (for humorous puns, such as \"monkey wrench\"), put it into a robot and unleash it on the real world.", "aSentId": 46246, "answer": "&gt; in relation to the Atari paper and partly on your statement about it\n\nCan you point me to his statement about it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46250, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 46251, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46252, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 46253, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46250, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 46255, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46256, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 46257, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46258, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 46259, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46256, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 46261, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46262, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 46263, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46267, "question": "Two questions, if I may:\n\n1. With Moore's law gradually coming to an end, it would seem that we won't be achieving anything even close to General AI on today's hardware, at least not economically. As a researcher at the forefront of the field, are you aware of any hardware \"game changers\" that may simplify training and execution of extremely large neural networks that may be capable of intelligence?\n\n2. What are some of the most exciting papers that you have read (or written) in the past year?", "aSentId": 46268, "answer": "&gt; With Moore's law gradually coming to an end\n\nSource? GPUs have just picked up the Moore torch and is now carrying the field. Ive seen no reason why this won't continue for 1 or 2 more cycles before something new  like graphene will be in production.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46291, "question": "What is the algorithm of love?\n", "aSentId": 46292, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46291, "question": "What is the algorithm of love?\n", "aSentId": 46294, "answer": "Great question!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46291, "question": "What is the algorithm of love?\n", "aSentId": 46296, "answer": "In response to the foolish comment: I am not a chinaman, but you are a racist village idiot.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46302, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 46303, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46309, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 46310, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46315, "question": "Facebook Research on Understanding Natural Language with Deep Neural Networks Using Torch", "aSentId": 46316, "answer": "I'm surprised that he says the LSTM model has problems learning base-ten integer addition.  The first RNN I trained, totally vanilla, was to do addition.  I used simple curriculum learning, starting with easy addition problems and getting harder.  It learned base-two addition quite well.  I don't remember exactly, but think it only rarely made mistakes on inputs many times longer than it had ever been trained on.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46318, "question": "What kinds of ML tutorials would you like to see?", "aSentId": 46319, "answer": "I always liked tutorials that talk about basic concepts and offer a practical example for each one detailing in the code what happens and then building upon them.\n\nThe tutorials that talked a lot about the concepts then gave the code for a piece of software that uses all the concepts tend to be confusing.\n\nSomething like: \"This is concept A. This is how you implement concept A. This is concept B. This is how you implement concept B. This is how you use concept A and B to do this cool thing.\"\n\nI skimmed through the tutorials and they seem to follow that process; I'm gonna give them a proper read when I get home.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46318, "question": "What kinds of ML tutorials would you like to see?", "aSentId": 46321, "answer": "Some sort of GPU accelerated deep NN for regression.. perhaps with hebel? Every damn tutorial is about image (or at least some other form of) classification.. :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46318, "question": "What kinds of ML tutorials would you like to see?", "aSentId": 46323, "answer": "One way to approach it that could be valuable is to take a look at https://github.com/josephmisiti/awesome-machine-learning which lists a very large number of machine learning libraries &amp; software.\n\nIf you were to find 1-3 tutorials / blog posts for each one that could be very valuable as a starting point for someone looking to get started in any of the myriad frameworks/languages.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46324, "question": "One way to approach it that could be valuable is to take a look at https://github.com/josephmisiti/awesome-machine-learning which lists a very large number of machine learning libraries &amp; software.\n\nIf you were to find 1-3 tutorials / blog posts for each one that could be very valuable as a starting point for someone looking to get started in any of the myriad frameworks/languages.", "aSentId": 46325, "answer": "Very good suggestion, thank you!\n\nQuick question: would you prefer tutorials be separated by language first or field first? For example, which makes more sense to you:  \n\nMachine Learning &gt; Facial Recognition &gt; C++  \n\nMachine Learning &gt; Facial Recognition &gt; Python\n  \n\nor ...\n\n\nMachine Learning &gt; Python &gt; Facial Recognition  \n\nMachine Learning &gt; C++ &gt; NLP\n\netc", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46326, "question": "Very good suggestion, thank you!\n\nQuick question: would you prefer tutorials be separated by language first or field first? For example, which makes more sense to you:  \n\nMachine Learning &gt; Facial Recognition &gt; C++  \n\nMachine Learning &gt; Facial Recognition &gt; Python\n  \n\nor ...\n\n\nMachine Learning &gt; Python &gt; Facial Recognition  \n\nMachine Learning &gt; C++ &gt; NLP\n\netc", "aSentId": 46327, "answer": "I would think using a filterable list of all your tutorials with 2 drop downs(or check boxes) one to filter by topic(s)and one by language(s).\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46332, "question": "I've been finding that there's a distinct lack of information about making predictions of time-series data. Like, in R, there's a lot of articles that tell you how to create a  time-series object and then you can plot it or whatever. But then it's like, \"yeah, but what do I actually *do* with it now that I have it?\"", "aSentId": 46333, "answer": "I'm taking a course in time series this semester (in R).\n\nI would suggest Googling and finding a couple of the free Time-Series-in-R books. There are 4 or 5 that I've found. But it's not too terribly easy. Not impossible, but not something to be taken lightly.\n\nYou create your time series object.\n\nThen you need to make a few determinations about it, primarily, is it stationary. If not, you need to make it so, and there are several ways to do this.\n\nOnce it's stationary, you work at developing a model. Right now we've only gotten as far as ARIMA models with seasonality, but there are more we'll be covering.\n\nThen you evaluate the model. In general, this is done by checking residuals, just as in linear regression.\n\nOnce you have a valid model, you simply run one of the forecasting functions.\n\nIt probably wouldn't be too hard to create some simple ARIMA tutorials, but again, there are models that go beyond that, and I'm not sure how difficult that would end up being.\n\n\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46336, "question": "As someone just starting to dive in I can't seem to find a simple tutorial of setting up a neural net in Java. \n\nThis is the [best I found](http://stackoverflow.com/a/12653770/2669575) but it doesn't really explain too much.\n\n    float[][] train = new float[][]{new float[]{0, 0}, new float[]{0, 1}, new float[]{1, 0}, new float[]{1, 1}};\n\n    float[][] res = new float[][]{new float[]{0}, new float[]{1}, new float[]{1}, new float[]{0}};\n\nI understand that the train 0,0 is used to point to the float 0, however how am I supposed to use this after? Does it need to be trained every time or should the weights be saved. Also how would this work if I wanted to train it with Strings rather than numbers?\n\n", "aSentId": 46337, "answer": "That's a good question. I don't work in Java myself, but maybe I can offer some guidance.\n\nGenerally the weights are stored in RAM (or wherever live variables are stored, I'm no computer scientist) and they are reproduced every time you run the code, because people usually write the training and testing in the same script/code. In fact, this is important, because as you modify the data or make slight changes to the algorithm, you want those changes to be reflected in the weights (so it makes sense to train/test every time you run the code). \n\n\nIf, however, you just want to train once, then you need to look for some kind of load/save feature in the ML package you are using (or create your own). For example, if you use [an implementation of SVM in scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), you can get the support vectors by calling:  \n\n    support_vectors = LinearSVC().`support_vectors_`\n\nThen save the support vectors for later and use them to recreate the ML classifier.  \n\nThough, as I suggested, you usually won't need to split the training and the testing into different processes unless you are dealing with an usual situation (such as writing production code or dealing with an algorithm that trains **very slowly**).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46339, "question": "Some DIY ML to get by insights about myself would be neat. What sort I'd things can I do to improve or even just color my daily life. Like if I take some data from Mint and do something on it I can learn ...?\n\nI would jump all over the \"coding for fun\" equivalent to ml.", "aSentId": 46340, "answer": "Wow that's really interesting, I've never thought of that before. It could be called ... Intralytics or something?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46343, "question": "Factor Analysis explained with classic example", "aSentId": 46344, "answer": "I love posts like these. Nice, simple, self contained. Though a bit more explanation on the theory / interpretation would make it perfect. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46346, "question": "Is PCA useful for 3 dimensions of data?", "aSentId": 46347, "answer": "See here\nhttp://setosa.io/ev/principal-component-analysis/", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46346, "question": "Is PCA useful for 3 dimensions of data?", "aSentId": 46349, "answer": "For 1D its useless, it wont do anything. For 2D+, it wont just give you what feature alone has the maximum variance as the first principal component, but what convex combination (basically a weighted average where the weights have to sum to 1) of the features has maximum variance as the first principal component vector. This vector is just those weights all lined up into one vector. Then it looks at all vectors ORTHOGONAL to the first, and finds what vector (what new weighted combination) maximizes the variance now, given the first constraint. This vector is the second principal component. The third and so on follow the same argument all being orthogonal to the previous PC's.\n\nImagine two 2D cases. The first is when you plot your data, it looks like a plus sign but with the bar along the x axis being longer than the one along the y axis.. In this case, the PC's would just be the features, the first being the one with larger variance. The second case would be one where the plus sign was rotated so it was no longer perfectly on the axes, and is now an x, where one brach of the x is longer than the other The longer branch would be the first PC, the second would be the second branch.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46351, "question": "Help with clustering recipe ingredients", "aSentId": 46352, "answer": "I'm a newbie on machine learning but have several years business experience with data analysis. If you provide the dataset I can have a look, it sounds pretty interesting", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46353, "question": "I'm a newbie on machine learning but have several years business experience with data analysis. If you provide the dataset I can have a look, it sounds pretty interesting", "aSentId": 46354, "answer": "I'll upload it and update you in a bit. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46351, "question": "Help with clustering recipe ingredients", "aSentId": 46356, "answer": "I have a minor issue with that paper. They list certain ingredients as \"spice\"; for example, \"ginger garlic paste\", which is a paste of ginger and garlic; shouldn't it be separated out? Similar for \"garam masala\" or \"chole masala\" or \"rasam powder\" (from what I gather of Indian cooking). \n\nTake, for example, \"rasam powder\". I've heard every family has their own recipe for making this powder from various ingredients. Grouping it into 1 ingredient under \"spice\" is a bit weak, IMHO.\n\n// source: amateur cook here, dabble in Asian cooking sometimes", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46357, "question": "I have a minor issue with that paper. They list certain ingredients as \"spice\"; for example, \"ginger garlic paste\", which is a paste of ginger and garlic; shouldn't it be separated out? Similar for \"garam masala\" or \"chole masala\" or \"rasam powder\" (from what I gather of Indian cooking). \n\nTake, for example, \"rasam powder\". I've heard every family has their own recipe for making this powder from various ingredients. Grouping it into 1 ingredient under \"spice\" is a bit weak, IMHO.\n\n// source: amateur cook here, dabble in Asian cooking sometimes", "aSentId": 46358, "answer": "that's kind of a huge issue with this dataset. As well as hindi/english names for the same ingredients in different recipes. I've tried to replace them as much as possible. \n\nAlso, should I consider dried figs and figs the same? Should I consider mango powder and mango the same thing? raw mango and ripe mango? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46351, "question": "Help with clustering recipe ingredients", "aSentId": 46360, "answer": "What meaning are you looking for? What clustering methods did you try and how did you build the features?\n\nYou could try to build a graph with the edge weights being how many time each ingredient appears in each recipe and then look into graph partitioning/community detection algorithms or super nodes that get used in tons of recopies etc. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46361, "question": "What meaning are you looking for? What clustering methods did you try and how did you build the features?\n\nYou could try to build a graph with the edge weights being how many time each ingredient appears in each recipe and then look into graph partitioning/community detection algorithms or super nodes that get used in tons of recopies etc. ", "aSentId": 46362, "answer": "My dataset is a set of documents which contain a list of ingredients each. \n\nso now each data point is an ingredient, and the features are the documents. my features look like: \n\ndoc1,doc2,doc3...docn. \n\nso each data point looks like ingredient1: 0,1,0,0....1,1,1. \n\nThe methods I have tried are all the clustering methods in scikit-learn, including hierarchical clustering with the number of clusters set between 10 and 25, and affinity propagation. I find i get one huge cluster with 90% of the ingredients and the rest in clusters of size 1-3 data points. \n\ni'll try graph partitioning. it seems to be more appropriate than just trying to cluster items. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46363, "question": "My dataset is a set of documents which contain a list of ingredients each. \n\nso now each data point is an ingredient, and the features are the documents. my features look like: \n\ndoc1,doc2,doc3...docn. \n\nso each data point looks like ingredient1: 0,1,0,0....1,1,1. \n\nThe methods I have tried are all the clustering methods in scikit-learn, including hierarchical clustering with the number of clusters set between 10 and 25, and affinity propagation. I find i get one huge cluster with 90% of the ingredients and the rest in clusters of size 1-3 data points. \n\ni'll try graph partitioning. it seems to be more appropriate than just trying to cluster items. ", "aSentId": 46364, "answer": "Also try some matrix decomposition methods directly or dimensionality reduction. Looking at egienvectors/dimensions instead of clusters has the advantage that they don't need to be mutually exclusive. \n\nYou might find that the first eigenvector or two are uninteresting/obvious (like cuisine type, or sweet vs savory or whatever) while the rest hold more interesting behavior (say \"in season in the spring\" or whatever) and you'll be able to see the position of each food in each dimension so you can see \"sweet and in season in the spring\".\n\nNote: i'm totally making up these categories. You'll have to do some guessing or statistics to assign meaning to the different dimension.\n\nEDIT: thinking about it, this seems like a great use case for non negative matrix factorization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46365, "question": "Also try some matrix decomposition methods directly or dimensionality reduction. Looking at egienvectors/dimensions instead of clusters has the advantage that they don't need to be mutually exclusive. \n\nYou might find that the first eigenvector or two are uninteresting/obvious (like cuisine type, or sweet vs savory or whatever) while the rest hold more interesting behavior (say \"in season in the spring\" or whatever) and you'll be able to see the position of each food in each dimension so you can see \"sweet and in season in the spring\".\n\nNote: i'm totally making up these categories. You'll have to do some guessing or statistics to assign meaning to the different dimension.\n\nEDIT: thinking about it, this seems like a great use case for non negative matrix factorization.", "aSentId": 46366, "answer": "Thanks. these are things that seem like a good place to start. and i'll look up non-negative matrix factorization as well. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46368, "question": "Visualizing semantic Hashing", "aSentId": 46369, "answer": "Are you using *linear* units for as the 2-wide bottleneck layer?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46370, "question": "Are you using *linear* units for as the 2-wide bottleneck layer?", "aSentId": 46371, "answer": "I haven't tried that yet.\n\nIn the finetuning phase, I have a layer with, say, 128 nodes, then 2 and then 128 again. The noise would be added add the two nodes. Question: If the two nodes are linear, wouldn't it be the same if i leave them out and add the noise at one of the layers with 128 nodes?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46368, "question": "Visualizing semantic Hashing", "aSentId": 46373, "answer": "&gt; I do not add deterministic noise because I havn't found out yet how to do that in pylearn2\n\nMaybe you want to try a [corruptor](https://github.com/lisa-lab/pylearn2/blob/aabde405122b35b4a2a00c311d0507b06354bcb7/pylearn2/corruption.py)?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46375, "question": "Resources About Engineering Machine Learning Systems?", "aSentId": 46376, "answer": "Interesting point on why TDD fails here.\n\nI would adhere to a standard close to the business your startup is in. Often times, a pipeline is flexible enough to accommodate changes on the fly (see the pipes-and-filters design pattern): input -&gt; feature engineering -&gt; machine learning -&gt; output. It's a matter of keeping abstractions clear and extend them as necessary. That works for me.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46378, "question": "Deep Learning architecture questions", "aSentId": 46379, "answer": "224 / 4 is 56. You're going to lose some pixels at the border from a \"valid\" mode convolution, but you can make the output size whatever you want by just zero padding the input. I suspect that's what's done here, as there is explicit support for it in Alex's code.\n\nThe 96 is simply a free parameter or \"hyperparameter\", probably chosen by measuring error on a validation set (like all the other free parameters).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46378, "question": "Deep Learning architecture questions", "aSentId": 46381, "answer": "That's because the layers are convolutional. Each 11x11x3 kernel is applied repeatedly over the image in a grid. Since the image is 224x224 pixels, and the stride is 4, that means the kernel is repeated 55 times in each direction, giving a grid of 55x55 values from *each* kernel. They repeat this process for 96 different kernels, so the output from the layer has 96 \"channels\".\n\n&gt; .... where did this 96 come from?\n\nIt's just a choice, you can pick as many kernels as you want per layer, it's similar to choosing the number of hidden units.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46382, "question": "That's because the layers are convolutional. Each 11x11x3 kernel is applied repeatedly over the image in a grid. Since the image is 224x224 pixels, and the stride is 4, that means the kernel is repeated 55 times in each direction, giving a grid of 55x55 values from *each* kernel. They repeat this process for 96 different kernels, so the output from the layer has 96 \"channels\".\n\n&gt; .... where did this 96 come from?\n\nIt's just a choice, you can pick as many kernels as you want per layer, it's similar to choosing the number of hidden units.", "aSentId": 46383, "answer": "So, if I'm understanding it correctly: the \"96\" is just a choice. It could have been 32; or it could have been 216 (just to pick some random numbers). The thing that makes it work is that these weights are initialized randomly, so each \"channel\" ends up doing something different. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46384, "question": "So, if I'm understanding it correctly: the \"96\" is just a choice. It could have been 32; or it could have been 216 (just to pick some random numbers). The thing that makes it work is that these weights are initialized randomly, so each \"channel\" ends up doing something different. ", "aSentId": 46385, "answer": "That's pretty much it, yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46378, "question": "Deep Learning architecture questions", "aSentId": 46387, "answer": "~~Other comments touched on where the 55x55 dimension came from, but there is one thing to note about how the '3rd' dimension is created.~~\n\n~~The first layer has 96 filters, each which produces a 2d output that resides in its own channel, similar to how the RGB layers are represented. In this paper they use a pooling strategy that pools across these channels, which is why the first layer has 96 filters, but the next layer only sees 48 channels. This continues for the rest of the conv layers, the numbers of channels presented to a layer is equal to the number of previous filters divided by 2.~~\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46388, "question": "~~Other comments touched on where the 55x55 dimension came from, but there is one thing to note about how the '3rd' dimension is created.~~\n\n~~The first layer has 96 filters, each which produces a 2d output that resides in its own channel, similar to how the RGB layers are represented. In this paper they use a pooling strategy that pools across these channels, which is why the first layer has 96 filters, but the next layer only sees 48 channels. This continues for the rest of the conv layers, the numbers of channels presented to a layer is equal to the number of previous filters divided by 2.~~\n\n", "aSentId": 46389, "answer": "are you sure about this? they split the kernels between GPUs, but it doesn't look to me like the number of channels decreases like that (which would be an unusual arrangment).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46390, "question": "are you sure about this? they split the kernels between GPUs, but it doesn't look to me like the number of channels decreases like that (which would be an unusual arrangment).", "aSentId": 46391, "answer": "Yea, it was kind of blowing my mind when I originally looked at it, but that's not what is happening, its just a 2-gpu split. That's what I get for skimming section 3.4 and just briefly looking at the figure.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46396, "question": "Best book for machine learning in python ?", "aSentId": 46397, "answer": "Collective Intelligence -  Toby Segaran.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46396, "question": "Best book for machine learning in python ?", "aSentId": 46399, "answer": "Scikit-learn documentation", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46396, "question": "Best book for machine learning in python ?", "aSentId": 46401, "answer": "A blogger ported the R book *Machine Learning for Hackers* into python in a series of blog posts. I highly recommend it: http://slendermeans.org/pages/will-it-python.html", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46405, "question": "Google, Stanford use machine learning on 37.8m data points for drug discovery", "aSentId": 46406, "answer": "Link to the [arXiv paper](http://arxiv.org/pdf/1502.02072v1.pdf) .\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46405, "question": "Google, Stanford use machine learning on 37.8m data points for drug discovery", "aSentId": 46408, "answer": "TIL what stratified K-fold x-val is", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46405, "question": "Google, Stanford use machine learning on 37.8m data points for drug discovery", "aSentId": 46410, "answer": "Multi-task learning *started* with neural networks. \n\nNeural networks for drug discovery is decades old. \n\nWhat's new in this paper?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46414, "question": "Keeping the world's elevators running smoothly with machine learning and IoT", "aSentId": 46415, "answer": "Thank, a good read without buzzword overload.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46418, "question": "Mapping your music collection with machine learning", "aSentId": 46419, "answer": "And it's down. Over quota \u2013 must have been reddit-hugged.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46420, "question": "And it's down. Over quota \u2013 must have been reddit-hugged.", "aSentId": 46421, "answer": "Either OP is using a server from the 80's or there are a lot of lurkers in this sub!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46422, "question": "Either OP is using a server from the 80's or there are a lot of lurkers in this sub!", "aSentId": 46423, "answer": "Lurker here. Can confirm", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46425, "question": "Networks to vectors: using PageRank to recover latent embeddings and densities.", "aSentId": 46426, "answer": "Disclosure: I am one of the authors of this paper. \n\nI'm hopeful this is relevant and I'm interested to hear what /r/MachineLearning thinks are interesting / gaps / future directions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46427, "question": "Disclosure: I am one of the authors of this paper. \n\nI'm hopeful this is relevant and I'm interested to hear what /r/MachineLearning thinks are interesting / gaps / future directions.", "aSentId": 46428, "answer": "Thanks for sharing! I'll have to read the paper sometime this week, but the interplay of networks and vectors is hugely important within ML.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46430, "question": "Instart Logic brings machine learning to HTML and JavaScript code delivery", "aSentId": 46431, "answer": "This is interesting. I wonder what kind of provisions have been made to account for the messy html out in the wild.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46433, "question": "Monday's \"Simple Questions Thread\" - 20150302", "aSentId": 46434, "answer": "I'll bite: logistic regression and support vector machines seem really similar. When should one be used over the other and why?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46435, "question": "I'll bite: logistic regression and support vector machines seem really similar. When should one be used over the other and why?", "aSentId": 46436, "answer": "I would disagree with rasbt. SVMs and LR are really similar. Both have the same form lambda*||w||\\_2 + 1/N * sum\\_{i=1}^N Loss(w^T x\\_i, y\\_i). The only difference is the Loss function used, where both the Logistic loss and SVM loss are upper-bounds on the 0/1 loss (also known as surrogate losses). Both SVMs and LR are margin-maximizing algorithms (though SVMs get the *largest* margin). Both have similar performance across most problems,  and both have been used with other regularizes and still get similar performance. Both can be kernelized as well. In my library there are a number of general classes that can switch between LR and SVMs by just changing one line of code because they are so similar (and the difference between them is literally just the loss function). \n\nWhen to use one over the other? \n\nWhen you need a linear mode trained quickly, use LR. For the linear case, despite Logistic Regression involving relatively expensive exp/log operations, The LR loss is easier to solve since it is strongly convex. SVM solvers tend to be a bit slower to converge in terms of wallclock time.\n\nWhen you need good probabilities, use LR. SVMs just don't have probabilities. \n\nWhen you need an kernelized version, usually use SVMs. A property of the SVM loss function is that it is more efficient to kernelize, as you don't need to keep everything around . [The nature of this is that the SVM loss introduces exact zeros, which can be thrown away  since they have zero contribution. The LR loss does not introduce any hard zeros, so you have to keep everything. These zeros are in the *dual* space, not the primal space - so this is different from L_1 regularization if you have heard of that). \n\nIf you suspect that there are a few strong and large outliers in your data, SVMs might perform somewhat better - their loss does not grow as quickly as the LR loss does.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46435, "question": "I'll bite: logistic regression and support vector machines seem really similar. When should one be used over the other and why?", "aSentId": 46438, "answer": "linear SVM and LR can be formulated such that their only difference is their loss functions. Linear SVM has a hinge loss, whereas LR has a softmax loss. In this sense, LR will always make a parameter update during training because it is maximizing the probability of the correct class. SVM will *only* make a parameter update if it predicts thing incorrectly. This could make it more robust to outliers, but also might not give scores as accurately as LR. \n\nAdd in kernelization of SVM and it becomes a non-linear classifier and can learn much more complicated decision boundaries than LR. This takes longer to train/test and is much more difficult to scale, though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46433, "question": "Monday's \"Simple Questions Thread\" - 20150302", "aSentId": 46440, "answer": "Is deep learning useful if I'm not interested in picture analysis or semantic/textual analysis?\n\nI have a database that's all numbers basically, and it seems like every example/the hot topics in machine learning these days is applying deep learning to NLP and/or pictures. Will basic machine learning algorithms suffice or should I be looking to go down the deep neural net route?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46441, "question": "Is deep learning useful if I'm not interested in picture analysis or semantic/textual analysis?\n\nI have a database that's all numbers basically, and it seems like every example/the hot topics in machine learning these days is applying deep learning to NLP and/or pictures. Will basic machine learning algorithms suffice or should I be looking to go down the deep neural net route?", "aSentId": 46442, "answer": "\"Is deep learning useful if I'm not interested in picture analysis or semantic/textual analysis?\"\n\nML has focused on these problems for a few reasons: \n\n1.  The instances usually have independent, or close to independent errors.  \n2.  We know that human beings can do these tasks with nearly perfect accuracy\n3.  There's lots of publicly available labeled and unlabeled data.  \n4.  They're known to be difficult (they've been studied long enough by domain experts that there probably isn't a simple trick that will lead to high accuracy)\n\nI think that #1/#2 are the most important factors.  \n\n\"I have a database that's all numbers basically\"\n\nYou could say that about basically any dataset.  What do the numbers mean?  How many numbers are there?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46441, "question": "Is deep learning useful if I'm not interested in picture analysis or semantic/textual analysis?\n\nI have a database that's all numbers basically, and it seems like every example/the hot topics in machine learning these days is applying deep learning to NLP and/or pictures. Will basic machine learning algorithms suffice or should I be looking to go down the deep neural net route?", "aSentId": 46444, "answer": "You should almost always try the simpler stuff first. Linear models can get you surprisingly far, provided you use sensible encodings of your features. Deep learning can be applied if you have lots of labeled data (or even if you don't, though you need to be more careful), but try a few of the simpler off-the-shelf approaches before considering cutting edge stuff.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46433, "question": "Monday's \"Simple Questions Thread\" - 20150302", "aSentId": 46446, "answer": "What is the difference between a loss function and an error function?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46447, "question": "What is the difference between a loss function and an error function?", "aSentId": 46448, "answer": "The loss (or sometimes also called cost) function is basically the function to be minimized. Typically, this is some sort of error measure or (\"error function\"), e.g., the \"sum of squares errors\" in linear regression. There may be special cases where the loss function is not an \"error measure,\" but in general, I would say that they are the same.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46451, "question": "Is there a way to use deep learning to find the most visually similar images vs just outputing labels? Say you have a bunch of shoes, just using a label 'running shoe' doesn't work since some are mesh and others could have a striped patter. All the papers I have seen just output labels vs actually saying which image is most similar. Maybe replace the svm layer at the end of most deep nets with a knn layer that takes in the features produced by the net?", "aSentId": 46452, "answer": "One way I have seen (heard?) of people using DNNs in this way is to train a DNN for classification as you mentioned, then remove the last layer.  You are then left with some k-dimensional latent space representation instead of a classification prediction, and you can compare the latent space representations of different images to see how similar they are.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46453, "question": "One way I have seen (heard?) of people using DNNs in this way is to train a DNN for classification as you mentioned, then remove the last layer.  You are then left with some k-dimensional latent space representation instead of a classification prediction, and you can compare the latent space representations of different images to see how similar they are.", "aSentId": 46454, "answer": "Cool that's what I was thinking, do yo have any recommendations on specific papers/trials?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46461, "question": "Data scientist vs Research Engineer?", "aSentId": 46462, "answer": "I don't know, but \"Research Engineer\" sounds a lot more sensible than \"Data Scientist\". I mean, what type of scientist doesn't deal in data?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46461, "question": "Data scientist vs Research Engineer?", "aSentId": 46464, "answer": "It's probably a question of company culture.  Research engineer probably means that they have technical problems, but they want someone who can code and is willing to focus on production code and systems (as opposed to someone who only wants to do research).  \n\nI think that Data Scientist is just a reworking of the older term \"Data Analyst\".  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46461, "question": "Data scientist vs Research Engineer?", "aSentId": 46466, "answer": "I was a research engineer earlier. The reason (I think) the company had the post of research engineer was that they had two profiles which were close to Data Scientist, a Software Research Engineer and another, less technical and more functional, Analyst. So research engineer was more about converting the Excel/SAS/SQL the other guys wrote into production systems. However, there was a lot of overlapping between tasks of two positions.  \nLater, there was an \"Organizational Restructuring\" and most research engineers were charged with general software engineering tasks (which involved among other things, changing the button on dashboard from blue to red color). I had to fight hard to stay back on Data Science projects.", "corpus": "reddit"}]