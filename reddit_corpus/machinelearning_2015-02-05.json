[{"docID": "t5_2r3gv","qSentId": 10111,"question": "WikiGalaxy: Explore Wikipedia in 3D","aSentId": 10112,"answer": "That's pretty cool, but what is it doing in /r/MachineLearning? (is it using ML behind the scenes? Can't find anything in the about)","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10113,"question": "That's pretty cool, but what is it doing in /r/MachineLearning? (is it using ML behind the scenes? Can't find anything in the about)","aSentId": 10114,"answer": "It's probably using T-SNE or something of sorts to map everything in a 3D environment","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10117,"question": "A Neural Turing Machine implementation using Torch","aSentId": 10118,"answer": "Anyone have any examples of tasks that NTMs have been shown to perform well on? Or are they too new?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10119,"question": "Anyone have any examples of tasks that NTMs have been shown to perform well on? Or are they too new?","aSentId": 10120,"answer": "Other than the ones in the paper I haven't heard anything. The assumption is that a NTM should be as good as or better as LSTM, so anywhere a LSTM rnn is used should be a good place to look.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10121,"question": "Other than the ones in the paper I haven't heard anything. The assumption is that a NTM should be as good as or better as LSTM, so anywhere a LSTM rnn is used should be a good place to look.","aSentId": 10122,"answer": "I asked Ilya Sutskever if he considered using NTM for his NIPS Sequence to Sequence Learning paper.  He said that he'd only expect NTM to provide value for learning from really long sequences and that single sentences would be fine with LSTM.  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10123,"question": "I asked Ilya Sutskever if he considered using NTM for his NIPS Sequence to Sequence Learning paper.  He said that he'd only expect NTM to provide value for learning from really long sequences and that single sentences would be fine with LSTM.  ","aSentId": 10124,"answer": "The one I really wanna try an NTM on is his generating text with recurrent neural network paper, that's gonna be one of the first things I do assuming I can get an NTM that replicates(or gets close to) the five published results. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10119,"question": "Anyone have any examples of tasks that NTMs have been shown to perform well on? Or are they too new?","aSentId": 10126,"answer": "No but I know a lot of places will hire you if you have machine learning on your resume..","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10117,"question": "A Neural Turing Machine implementation using Torch","aSentId": 10128,"answer": "Google says they're publishing they're work, but it's more like \"Hey, look how awesome stuff we can build. Now good luck trying to replicate this\". \n\nHave any1 compared the above implementation performance with the original paper?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10129,"question": "Google says they're publishing they're work, but it's more like \"Hey, look how awesome stuff we can build. Now good luck trying to replicate this\". \n\nHave any1 compared the above implementation performance with the original paper?","aSentId": 10130,"answer": "Don't think so, to be honest, most of DeepMind's papers are poorly written in terms of details and reproducibility.\n","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10117,"question": "A Neural Turing Machine implementation using Torch","aSentId": 10132,"answer": "Is this the first open-source NTM?\n\nHow hard was it to go from the paper to actually building it?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10133,"question": "Is this the first open-source NTM?\n\nHow hard was it to go from the paper to actually building it?","aSentId": 10134,"answer": "[This](https://github.com/shawntan/neural-turing-machines) one was posted a few months ago, it can't yet replicate the results that were published in the paper. The big challenge for building a NTM is designing the controller, there are basically no details in the paper, the one I linked uses a feed-forward controller while the torch one uses an LSTM controller. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10135,"question": "[This](https://github.com/shawntan/neural-turing-machines) one was posted a few months ago, it can't yet replicate the results that were published in the paper. The big challenge for building a NTM is designing the controller, there are basically no details in the paper, the one I linked uses a feed-forward controller while the torch one uses an LSTM controller. ","aSentId": 10136,"answer": "seems like it's time for conference/journal paper acceptance to require publishing working code.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10137,"question": "seems like it's time for conference/journal paper acceptance to require publishing working code.","aSentId": 10138,"answer": "That would be nice, but I'm just glad there is a decent culture of publishing in general. NTMs could potentially outperform LSTM (pending more research with them) in most/all scenarios, and since LSTMs have been involved in a bunch of really interesting stuff lately it could be a big advantage to keep NTMs internal to Google. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10139,"question": "That would be nice, but I'm just glad there is a decent culture of publishing in general. NTMs could potentially outperform LSTM (pending more research with them) in most/all scenarios, and since LSTMs have been involved in a bunch of really interesting stuff lately it could be a big advantage to keep NTMs internal to Google. ","aSentId": 10140,"answer": "&gt;  it could be a big advantage to keep NTMs internal to Google\n\nPerhaps. Or google could be trolling facebook/microsoft by holding back a bunch of vital details. \n\nUntil they release code or someone replicates their results it's hard to say.\n\nI think the contrast between opinions on NTM/DeepMind and HTM/Numenta is strange, given that empirical evidence for both is similar.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10141,"question": "&gt;  it could be a big advantage to keep NTMs internal to Google\n\nPerhaps. Or google could be trolling facebook/microsoft by holding back a bunch of vital details. \n\nUntil they release code or someone replicates their results it's hard to say.\n\nI think the contrast between opinions on NTM/DeepMind and HTM/Numenta is strange, given that empirical evidence for both is similar.","aSentId": 10142,"answer": "\"I think the contrast between opinions on NTM/DeepMind and HTM/Numenta is strange, given that empirical evidence for both is similar.\"\n\nIt's pretty different, because NTM came from researchers with a track record of producing good results.  See Alex Graves's results on forecasting, speech recognition, and handwriting synthesis.  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10141,"question": "&gt;  it could be a big advantage to keep NTMs internal to Google\n\nPerhaps. Or google could be trolling facebook/microsoft by holding back a bunch of vital details. \n\nUntil they release code or someone replicates their results it's hard to say.\n\nI think the contrast between opinions on NTM/DeepMind and HTM/Numenta is strange, given that empirical evidence for both is similar.","aSentId": 10144,"answer": "I've replicated the copy and repeat copy task results personally, the remaining problem is to make sure it happens every time. The owner of this repository seems to have associative recall done, so I wouldn't be surprised to see a code package pretty soon that will replicate all 5 published results. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10141,"question": "&gt;  it could be a big advantage to keep NTMs internal to Google\n\nPerhaps. Or google could be trolling facebook/microsoft by holding back a bunch of vital details. \n\nUntil they release code or someone replicates their results it's hard to say.\n\nI think the contrast between opinions on NTM/DeepMind and HTM/Numenta is strange, given that empirical evidence for both is similar.","aSentId": 10146,"answer": "Numenta has been around for a while now, and I haven't heard of it revolutionizing anything.  Plus the goal of the NTM is to replicate human working memory.  Working memory is extremely important to higher level cognition.  Research estimates that more than 50% of the variance in human IQ is explained by working memory alone.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10137,"question": "seems like it's time for conference/journal paper acceptance to require publishing working code.","aSentId": 10148,"answer": "yeah that might be a bad idea.  In that case Google would have published nothing.  At least with their paper they have put enough info out there for people to figure it out eventually.\n\nmaybe they are just using it for recruiting, and they are going to hire whoever successfully clones it first.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10137,"question": "seems like it's time for conference/journal paper acceptance to require publishing working code.","aSentId": 10150,"answer": "Was the NTM paper published in any journals or conferences? I just remember it being on arxiv...","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10154,"question": "Is it possible to model the demand for parking space based upon parking ticket data?","aSentId": 10155,"answer": "Do you have *some* data about demand itself?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10158,"question": "[Question] Where is the DataScience WOW value in Google self-driving car","aSentId": 10159,"answer": "High speed (or high momentum) real life situation with varying conditions and human lives at risk? ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10160,"question": "High speed (or high momentum) real life situation with varying conditions and human lives at risk? ","aSentId": 10161,"answer": "The solution still in the early stage, risk is a big factor in most of these solutions ( eg: the plane at the early days )\n\nI was trying to find their paper where they describe their model but couldn't find it. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10158,"question": "[Question] Where is the DataScience WOW value in Google self-driving car","aSentId": 10163,"answer": "For a project like this, the practical implementation difficulty is the real challenge- anyone can write a simulation-bot that correctly picks a path through a maze and then populate the maze with street data, but the ability to react in real time to traffic changes, pedestrians, etc., and actually control a real automobile is a much more complex task.\n\nIn terms of data analysis, the car is very good at picking out what are and aren't significant features in its surroundings in real time- that's a pretty substantial problem in computer vision and integrating the processing of stored data (both abstract, like maps, and concrete, like recordings of previous runs) with live data from sensor arrays.\n\n*edit: completed a sentence.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10158,"question": "[Question] Where is the DataScience WOW value in Google self-driving car","aSentId": 10165,"answer": "The WOW value is the billions of dollars that go to whoever is able to use, sell, market them to a mass market first.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10168,"question": "Question about SVM solver algorithms, in matlab specifically","aSentId": 10169,"answer": "&gt; Furthermore the minimum found with L1Qp isn't necessarily better than what's found with SMO, but I haven't been able to rigorously test this.\n\nThe SVM objective function is convex. There is one minimum. If the SMO solver is getting you there quicker... well, you know what to do.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10170,"question": "&gt; Furthermore the minimum found with L1Qp isn't necessarily better than what's found with SMO, but I haven't been able to rigorously test this.\n\nThe SVM objective function is convex. There is one minimum. If the SMO solver is getting you there quicker... well, you know what to do.","aSentId": 10171,"answer": "Do you have any idea of why SMO is getting there more quickly? It sounds like in principle L1Qp should.  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10172,"question": "Do you have any idea of why SMO is getting there more quickly? It sounds like in principle L1Qp should.  ","aSentId": 10173,"answer": "Not off the top of my head, but I imagine the conditions under which one optimizer beats the other are somewhat problem dependent.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10168,"question": "Question about SVM solver algorithms, in matlab specifically","aSentId": 10175,"answer": "You might want to send this over to /r/MLQuestions","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10168,"question": "Question about SVM solver algorithms, in matlab specifically","aSentId": 10177,"answer": "&gt;So, my question is: what are the benefits of using L1Qp?\n\nNone. L1Qp is using a generalized algorithm for QP problems. SMO is a specialized algorithm for SVMs. \n\n&gt;A second question is: what is matlab doing to the Kernel via the KernelScale argument pair? In the documentation it says it divides the kernel by the kernel scale elementwise and then applies the 'appropriate kernel norm'. It's this last part that I'm a little confused by -- are they normalizing each column/row vector to unit length?\n\nThe appropriate Kernel is the one you selected for use. If you picked RBF, then it will use the RBF kernel *after* re-scaling the dimensions of the problem. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10179,"question": "Which of the two MOOCs will be a better option? Illinois DM Specialization or Stanford's Massive Data Mining?","aSentId": 10180,"answer": "Option One is a series of courses. Option Two is _one_ course. So I'm not sure these can be compared. \n\nI've taken the MMDS course and I loved it. I would recommend you take it, for it will give you a broad overview. You can also download a free book on mmds.org. After taking the course/while taking the course you will be able to dive into the book more effectively.\n\nThe MMDS course will not give you many artefacts to prove your competence, sadly. But the lectures are very good if you're interested in the subject. I found Jure Leskovec's lectures outstanding, in particular, and I listened to them very avidly. \n \nI can't speak much about the Data Mining Specialisation but given that you have six months why don't you do *both*. You can always drop a course along the way if you find that you don't have much time.\n\nThere are a lot of Statistics/Data Mining/Machine Learning MOOCs around. Anything on Coursera/Edx/Stanford Online etc. is of very high quality. The trick is to take any course, remain dedicated to it and complete it! You can't go wrong if you do that.\n\nIn general I'm not too excited about Coursera's mini specializations -- the courses &amp; specializations seem to be broken into too many small bites to make things look more impressive than they actually might be (just my impression). \n\nIn summary, I would recommend that you just start out on something. MMDS is a good place. If Data Mining proves to be your cup of tea then take more courses/a specialization along the way.\n\nAlso with regard to future employers -- I don't think its necessary to have a \"specialization\" -- if you can list out a series of good courses you took, they will be able to see your passion for the subject.\n\n\n\n\n\n \n\n","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10182,"question": "HTML5 Genetic Algorithm Biped Walkers","aSentId": 10183,"answer": "[Champions fall early, traveled not as far as some non champions but still have higher score? Why?](http://s29.postimg.org/h3voybnhz/Untitled.jpg)","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10184,"question": "[Champions fall early, traveled not as far as some non champions but still have higher score? Why?](http://s29.postimg.org/h3voybnhz/Untitled.jpg)","aSentId": 10185,"answer": "&gt; In order to promote upright walking, each creature receives points based on how high the head is in relation to its feet, and how much it advances while upright. Bonus points are given for each proper step forward. \n\n\nMy guess is the champion was walking very upright and took \"proper\" steps while the other guys kind of stumbled forward.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10184,"question": "[Champions fall early, traveled not as far as some non champions but still have higher score? Why?](http://s29.postimg.org/h3voybnhz/Untitled.jpg)","aSentId": 10187,"answer": "&gt; Elitist selection.\n\nChampions (genomes with highest fitness/score) from the previous generation are competing with mutated genomes in the current generation, which might perform better.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10182,"question": "HTML5 Genetic Algorithm Biped Walkers","aSentId": 10189,"answer": "I'd watch it all day long.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10182,"question": "HTML5 Genetic Algorithm Biped Walkers","aSentId": 10191,"answer": "Are the champions actually mating and having offspring or are they just being copied to the next gen?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10193,"question": "so basically a QWOP solver\n\nalso, my \"champion\" got 620.87 on the 62nd generation. 100 gens later and still the winner","aSentId": 10194,"answer": "Qovezo Kizoko?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10196,"question": "This is awesome...did you write this? \n\nDoes anyone have information on what the typical peak score is?","aSentId": 10197,"answer": "Nope.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10201,"question": "Very fun project! Kudos.\n\nI took a peek at your code and noticed that the Walker genes encode sinusoid coefficients to set joint motor speeds in Walker.simulationStep(). I was a bit disappointed because that means you don't use any feedback from \"sensors\" like joint position, head-foot-ground angle, travel speed, etc. \n\nDo you plan on adding these feedback mechanisms?\nIt would also be interesting to see average speed included in the fitness function so it would push them to start running.","aSentId": 10202,"answer": "You'll have to ask the creator: http://rednuht.org/ :-)","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10203,"question": "You'll have to ask the creator: http://rednuht.org/ :-)","aSentId": 10204,"answer": "haha, oops. I should have checked that first.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10206,"question": "Blocks vs Pylearn2 vs Groundhog for RNN","aSentId": 10207,"answer": "I have tried all 3 in some depth, though my main experience is with pylearn2 RNN and lots of reading of GroundHog and blocks.\n\nLasagne is also close to having RNNs, look at issue 17 on the GitHub repo. That might be another place to look, or wait for.\n\nblocks is basically the up-and comer where RNNs are for sure first class citizens, GroundHog is more research code which *inspired* blocks, and pylearn2 is basically trying to add in some significant changes to input spaces/sources while retaining existing functionality and backwards compatibility. \n\npylearn2 is a lot better established, with better documentation (relatively) and a larger user base. So there may be more help available instead of pinging the developers. However, it is likely that blocks will be the home of most of the newer RNN approaches from LISA if that is what you want to try, with backports to pylearn2 happening sooner or later depending on who wrote the algorithm.\n\nThe plan is to have a wrapper to go from blocks to pylearn2 and vice versa if I recall correctly, which means you may not have to choose. I do not recommend GroundHog unless you are planning tweaks to their existing experiments, much of the codebase is very text centered and has specific assumptions related to that.\n\nI ended up writing my own RNN in Theano, but that is probably not the best approach if you just want to *apply* RNNs to your data. As my goal/plan is to do new research on recurrent data / sequence to sequence modeling I took the hard road :)\n\nDo note that you are very likely to *need* some kind of sequence mapping (CTC cost from Alex Graves, encode-decode RNNs, or precomputed approximate alignments using HMMs) unless you are really lucky and have a dataset where input dim and output dim match with given alignments. All 3 of these libraries (unsure on pylearn2) are likely to have this capability now or in the near future.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10206,"question": "Blocks vs Pylearn2 vs Groundhog for RNN","aSentId": 10209,"answer": "One of the main authors of Blocks wrote the RNN module in pylearn2's sandbox but is now mostly working on Blocks. I'd therefore consider the pylearn2 RNN stuff essentially unmaintained (which is why it's in the sandbox).","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10211,"question": "Looking for a corpus of contracts and other legal documents","aSentId": 10212,"answer": "Many states have pre done starter contracts for use by the public, you could mine those. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10214,"question": "[x-post /r/sysadmin] Backblaze releases hard drive reliability dataset","aSentId": 10215,"answer": "I saw this on /r/sysadmin, figured someone here might find it an interesting problem to work on.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10219,"question": "Help with analyzing multiple sequences of data for overall outcome prediction","aSentId": 10220,"answer": "A few approaches: \n\n1.  Try to turn each time series into a bag of features and then feed everything into a standard regression / classification model.  What features you want to extract from the time series depends on the nature of your problem.  Perhaps mean, variance, and median are good starting points?  Maybe a histogram of values?  Maybe have a set of template time series, do dynamic time warping against those time series, and then include a feature which gives the distance for the dynamic time warping.  \n\n2.  You could use a neural network which exploits the structure in the input time series.  Convolutional neural networks and recurrent neural networks are two possible solutions, and which one works better depends on what kind of structure exists in your time series.  \n\nRegarding the question of determining how much of the sequence you need to see before you make a prediction, one possible solution is to train separate models that use different fractions of the sequence (i.e. one is trained on 10%, one is trained on 20%, and so on).  Then you could make the outputs probabilistic so that you know the likelihood of the output.  So what you could do is run the model trained on 10% of the data, see if the confidence is above some threshold, and then run the model trained on 20% of the data if the confidence isn't high enough.  I'm not sure about how you would set those thresholds though.  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10221,"question": "A few approaches: \n\n1.  Try to turn each time series into a bag of features and then feed everything into a standard regression / classification model.  What features you want to extract from the time series depends on the nature of your problem.  Perhaps mean, variance, and median are good starting points?  Maybe a histogram of values?  Maybe have a set of template time series, do dynamic time warping against those time series, and then include a feature which gives the distance for the dynamic time warping.  \n\n2.  You could use a neural network which exploits the structure in the input time series.  Convolutional neural networks and recurrent neural networks are two possible solutions, and which one works better depends on what kind of structure exists in your time series.  \n\nRegarding the question of determining how much of the sequence you need to see before you make a prediction, one possible solution is to train separate models that use different fractions of the sequence (i.e. one is trained on 10%, one is trained on 20%, and so on).  Then you could make the outputs probabilistic so that you know the likelihood of the output.  So what you could do is run the model trained on 10% of the data, see if the confidence is above some threshold, and then run the model trained on 20% of the data if the confidence isn't high enough.  I'm not sure about how you would set those thresholds though.  ","aSentId": 10222,"answer": "Thanks for your reply! For your number 2, do you have any advice on adapting a neural network that predicts the next time step into one that predicts my overall outcome value? I see many examples for the former, but haven't found one for my particular application yet. I don't have any experience in implementing neural networks.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10223,"question": "Thanks for your reply! For your number 2, do you have any advice on adapting a neural network that predicts the next time step into one that predicts my overall outcome value? I see many examples for the former, but haven't found one for my particular application yet. I don't have any experience in implementing neural networks.","aSentId": 10224,"answer": "In theory, there's no difficulty in having a recurrent neural network that takes a sequence of inputs and produces a single output.  \n\nYou could also use convnets with 1D convolutions over the time series.  \n\n\"I don't have any experience in implementing neural networks.\"\n\nThis could be tricky then.  Perhaps learn to use theano?  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10226,"question": "Mining Massive Datasets Question on SVD","aSentId": 10227,"answer": "You can do it with something called probabilistic matrix factorization (PMF). This was used for the Netflix challenge for example. There are some resources online for it, and if you want to see some (terrible) example code I may be able to dig mine up.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10228,"question": "You can do it with something called probabilistic matrix factorization (PMF). This was used for the Netflix challenge for example. There are some resources online for it, and if you want to see some (terrible) example code I may be able to dig mine up.","aSentId": 10229,"answer": "*turrible","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10226,"question": "Mining Massive Datasets Question on SVD","aSentId": 10231,"answer": "P and Q are composed of these q_i and p_x (these vectors are rows of matrices). Basically, you search through all possible matrices R and Q and look at that functional to be minimized. If you have enough data in R, then you'll find the solution (though, it's not necessary unique).\n\nOf course, if whole row (or column) is missing, then any vector for it would be as good as any other.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10226,"question": "Mining Massive Datasets Question on SVD","aSentId": 10233,"answer": "That looks to me to be a matrix completion problem. Generally, this is solved via some form of rank constraint over the completed matrix.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10235,"question": "[Question] When making a decision tree, how do you choose the best decision for each split point?","aSentId": 10236,"answer": "The other answers so far are good. It is common to grow a tree by greedily selecting the split that minimizes some criteria like gini impurity, entropy or l2 error.\n\nHowever for single decision trees this will often overfit. Random forests address this by growing each tree on a random sample of the data any by only examining a random selection of the possible features to split on for each split.\n\nHowever it is also possible (though difficult) to fit a decision tree via an optimization problem where you attempt to improve the overall accuracy of the tree by selecting/changing splits that may not show up in greedy tree growth. This can be computationally intensive but there are some methods based on this approach. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10235,"question": "[Question] When making a decision tree, how do you choose the best decision for each split point?","aSentId": 10238,"answer": "Usually you split using some criteria for branch purity.  I.e. you want to split the data such that the branches are as uniform as possible.  For categorical targets, entropy is a good measure of purity.  For numerical targets, variance is a good measure of purity.  ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10239,"question": "Usually you split using some criteria for branch purity.  I.e. you want to split the data such that the branches are as uniform as possible.  For categorical targets, entropy is a good measure of purity.  For numerical targets, variance is a good measure of purity.  ","aSentId": 10240,"answer": "That was super clear and refined, you should teach!","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10235,"question": "[Question] When making a decision tree, how do you choose the best decision for each split point?","aSentId": 10242,"answer": "I think the previous posts pretty much cover it, but this is a cool subject so just thought I'd also throw out conditional inference trees as a topic in case you want to read up on them.\n\nUnlike some methods, a conditional tree performs one or more significance (permutation) tests on the variables to try and choose appropriate ones, rather than going for a greedy split. ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10243,"question": "I think the previous posts pretty much cover it, but this is a cool subject so just thought I'd also throw out conditional inference trees as a topic in case you want to read up on them.\n\nUnlike some methods, a conditional tree performs one or more significance (permutation) tests on the variables to try and choose appropriate ones, rather than going for a greedy split. ","aSentId": 10244,"answer": "Beautiful, I will look into this too! Thanks!","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10246,"question": "Prototype ML/NLP Code Tutorial Series Lesson 1: Working With Text","aSentId": 10247,"answer": "Great stuff. There's always a relevant xkcd.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10246,"question": "Prototype ML/NLP Code Tutorial Series Lesson 1: Working With Text","aSentId": 10249,"answer": "Very cool, liking the lesson","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10246,"question": "Prototype ML/NLP Code Tutorial Series Lesson 1: Working With Text","aSentId": 10251,"answer": "Great lesson, thanks for this.\n","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10253,"question": "What is the best way to preform sentiment analysis on data that has both qualitative and quantitative variables?","aSentId": 10254,"answer": "It depends on how many samples you have. But unless you're crowdsourcing this online, I assume you're going to have a very limited data set. You could use a bag of words model and use every significant keyword as a feature and see if you can map certain words to ranges in the mood scale (e.g. angry, mad, sad, depressed would be closer to 1).\n\nYou could also try to restrict your survey a bit by asking people to write 5 words that describe their day. You're going to have to do a bit of data cleaning to get rid of non-informative words.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10257,"question": "Feedback on my intro to machine learning presentation?","aSentId": 10258,"answer": "Good stuff.\n\nOn slide 102, \"an apple misclassified as a pair\" should be \"pear\".","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10259,"question": "Good stuff.\n\nOn slide 102, \"an apple misclassified as a pair\" should be \"pear\".","aSentId": 10260,"answer": "Whoops, good catch!","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10257,"question": "Feedback on my intro to machine learning presentation?","aSentId": 10262,"answer": "* That is ~3 hours long\n* Lots of text\n* Sometimes the font is too small","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10263,"question": "* That is ~3 hours long\n* Lots of text\n* Sometimes the font is too small","aSentId": 10264,"answer": "75 minutes, I timed it.\n\nWhen I give the actual presentation, I'll have less text, because there's no point in reading slides at people. I put the standalone version here.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10265,"question": "75 minutes, I timed it.\n\nWhen I give the actual presentation, I'll have less text, because there's no point in reading slides at people. I put the standalone version here.","aSentId": 10266,"answer": "Hmm, I see now there are lots of transitions. Still seems like you are going *fast*.\n\nI agree and hate when I'm forced to talk about stuff I'm not familiar with. Then I need lots of reminders on the slides and it gets quite boring for me and the people watching.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10268,"question": "Identifying a small group in a big data set?","aSentId": 10269,"answer": "Here are a couple things to play around with:\n\n1.) Adjust the loss function/class weights, so the decision boundary favors the minority class.\n\n2.) Downsample the majority class.\n\n3.) Upsample the minority class by generating similar, slightly noisy data (there are methods for doing this if you look around). Doing this well tends to be trickier than downsampling.\n\nNote that these tricks might still not be able to solve your problem.\n\nThis is a common problem, try googling topics like \"unbalanced classes in machine learning\",\"imbalanced datasets\", and \"skewed classes in machine learning\".","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10270,"question": "Here are a couple things to play around with:\n\n1.) Adjust the loss function/class weights, so the decision boundary favors the minority class.\n\n2.) Downsample the majority class.\n\n3.) Upsample the minority class by generating similar, slightly noisy data (there are methods for doing this if you look around). Doing this well tends to be trickier than downsampling.\n\nNote that these tricks might still not be able to solve your problem.\n\nThis is a common problem, try googling topics like \"unbalanced classes in machine learning\",\"imbalanced datasets\", and \"skewed classes in machine learning\".","aSentId": 10271,"answer": "Thank you very much for the ideas!  I really appreciate you taking the time to respond.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10268,"question": "Identifying a small group in a big data set?","aSentId": 10273,"answer": "For random forests, there is a post on [how to implement downsampling in the caret package in R](http://www.r-bloggers.com/down-sampling-using-random-forests/). I have actually implemented his recommendations with great success (but then again, my data set, was not *quite* as unbalanced as yours). ","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10274,"question": "For random forests, there is a post on [how to implement downsampling in the caret package in R](http://www.r-bloggers.com/down-sampling-using-random-forests/). I have actually implemented his recommendations with great success (but then again, my data set, was not *quite* as unbalanced as yours). ","aSentId": 10275,"answer": "This looks very interesting, I will check it out.  Thanks a bunch!","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10277,"question": "What is coadaptation in the context of neural network?","aSentId": 10278,"answer": "It's easiest to explain with reference to an example. Imagine that two linear hidden units have weight vectors \n\n* Unit a's incoming weights: [-0.5, 0.5, 1.91, 2.54, 3.62]\n* Unit b's incoming weights: [-0.5, 0.5, -1.92, -2.52, -3.59] \n\nFor the sake of simplicity let's say the biases are zero, and that the weights connecting them to a unit in the next layer are both 1. These will both fire if they see -5 and 5 in the first two input variables, and the opposite signs on the remaining columns will more or less cancel each other out from the higher level hidden unit's perspective (due to them having the same outgoing weight).\n\nIt's pretty obvious that if the relevant pattern to detect is that negative, positive thing, then the [-a, a, 0, 0, 0] for some value of a is a good thing to do, and having two hidden units do the same thing with weights that cancel each other out in the rest of the fields is a waste of computation. Yet these sorts of things, and more complicated variations, are exactly the sorts of things that naively implemented gradient descent tends to find when training neural networks -- lots of different hidden units with weight vectors that look very similar to one another, because they're all making very greedy, local choices to try and suppress each other's spurious crap.\n\nIt's conceivable, then, that you'd like each hidden unit to do something useful/discriminative _in isolation_, without relying on other hidden units in the same layer to do anything in particular to make its contribution worthwhile.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10279,"question": "It's easiest to explain with reference to an example. Imagine that two linear hidden units have weight vectors \n\n* Unit a's incoming weights: [-0.5, 0.5, 1.91, 2.54, 3.62]\n* Unit b's incoming weights: [-0.5, 0.5, -1.92, -2.52, -3.59] \n\nFor the sake of simplicity let's say the biases are zero, and that the weights connecting them to a unit in the next layer are both 1. These will both fire if they see -5 and 5 in the first two input variables, and the opposite signs on the remaining columns will more or less cancel each other out from the higher level hidden unit's perspective (due to them having the same outgoing weight).\n\nIt's pretty obvious that if the relevant pattern to detect is that negative, positive thing, then the [-a, a, 0, 0, 0] for some value of a is a good thing to do, and having two hidden units do the same thing with weights that cancel each other out in the rest of the fields is a waste of computation. Yet these sorts of things, and more complicated variations, are exactly the sorts of things that naively implemented gradient descent tends to find when training neural networks -- lots of different hidden units with weight vectors that look very similar to one another, because they're all making very greedy, local choices to try and suppress each other's spurious crap.\n\nIt's conceivable, then, that you'd like each hidden unit to do something useful/discriminative _in isolation_, without relying on other hidden units in the same layer to do anything in particular to make its contribution worthwhile.","aSentId": 10280,"answer": "Ah thank you. That's clear. It's easy to see how that leads to over fitting. What are the most popular and the most cutting edge methods for reducing coadaptation?","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10281,"question": "Ah thank you. That's clear. It's easy to see how that leads to over fitting. What are the most popular and the most cutting edge methods for reducing coadaptation?","aSentId": 10282,"answer": "Dropout was the first method to really address the issue of overfitting in these terms, with these metaphors in hand. There have been a few different variations but dropout remains king (though \"fast dropout\" is interesting and worth a look).","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10279,"question": "It's easiest to explain with reference to an example. Imagine that two linear hidden units have weight vectors \n\n* Unit a's incoming weights: [-0.5, 0.5, 1.91, 2.54, 3.62]\n* Unit b's incoming weights: [-0.5, 0.5, -1.92, -2.52, -3.59] \n\nFor the sake of simplicity let's say the biases are zero, and that the weights connecting them to a unit in the next layer are both 1. These will both fire if they see -5 and 5 in the first two input variables, and the opposite signs on the remaining columns will more or less cancel each other out from the higher level hidden unit's perspective (due to them having the same outgoing weight).\n\nIt's pretty obvious that if the relevant pattern to detect is that negative, positive thing, then the [-a, a, 0, 0, 0] for some value of a is a good thing to do, and having two hidden units do the same thing with weights that cancel each other out in the rest of the fields is a waste of computation. Yet these sorts of things, and more complicated variations, are exactly the sorts of things that naively implemented gradient descent tends to find when training neural networks -- lots of different hidden units with weight vectors that look very similar to one another, because they're all making very greedy, local choices to try and suppress each other's spurious crap.\n\nIt's conceivable, then, that you'd like each hidden unit to do something useful/discriminative _in isolation_, without relying on other hidden units in the same layer to do anything in particular to make its contribution worthwhile.","aSentId": 10284,"answer": "Fair to say it's correlation of weights? Coadaptation is a sign of overfitting, so in addition to Dropout (which works well) you could also put priors on your weights or add a regularization term to the function you minimize.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10285,"question": "Fair to say it's correlation of weights? Coadaptation is a sign of overfitting, so in addition to Dropout (which works well) you could also put priors on your weights or add a regularization term to the function you minimize.","aSentId": 10286,"answer": "Correlation and anti-correlation, sure, that's a simple case. But you also do see complicated conspiracies of 3 or more units all co-adapting, so any penalty based on pairwise correlation probably wouldn't help too much.","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10279,"question": "It's easiest to explain with reference to an example. Imagine that two linear hidden units have weight vectors \n\n* Unit a's incoming weights: [-0.5, 0.5, 1.91, 2.54, 3.62]\n* Unit b's incoming weights: [-0.5, 0.5, -1.92, -2.52, -3.59] \n\nFor the sake of simplicity let's say the biases are zero, and that the weights connecting them to a unit in the next layer are both 1. These will both fire if they see -5 and 5 in the first two input variables, and the opposite signs on the remaining columns will more or less cancel each other out from the higher level hidden unit's perspective (due to them having the same outgoing weight).\n\nIt's pretty obvious that if the relevant pattern to detect is that negative, positive thing, then the [-a, a, 0, 0, 0] for some value of a is a good thing to do, and having two hidden units do the same thing with weights that cancel each other out in the rest of the fields is a waste of computation. Yet these sorts of things, and more complicated variations, are exactly the sorts of things that naively implemented gradient descent tends to find when training neural networks -- lots of different hidden units with weight vectors that look very similar to one another, because they're all making very greedy, local choices to try and suppress each other's spurious crap.\n\nIt's conceivable, then, that you'd like each hidden unit to do something useful/discriminative _in isolation_, without relying on other hidden units in the same layer to do anything in particular to make its contribution worthwhile.","aSentId": 10288,"answer": "So this is one form of co-adaptation that wastes computational power. Hinton mentioned in his paper that \"Complex co-adaptations can be trained to work well\non a training set, but on novel test data they are far more likely to fail than multiple simpler co-adaptations that achieve the same thing.\"\nI cant see how co-adaptation can harm the network and lead it to detect the features that are specific to the training dataset but do not generalize well for testing dataset.  \n","corpus": "reddit"},{"docID": "t5_2r3gv","qSentId": 10289,"question": "So this is one form of co-adaptation that wastes computational power. Hinton mentioned in his paper that \"Complex co-adaptations can be trained to work well\non a training set, but on novel test data they are far more likely to fail than multiple simpler co-adaptations that achieve the same thing.\"\nI cant see how co-adaptation can harm the network and lead it to detect the features that are specific to the training dataset but do not generalize well for testing dataset.  \n","aSentId": 10290,"answer": "All of the other crap that it learns to add and cancel out typically works fine on the training set, but when it encounters a slightly different distribution on the test set you see it interfering more.","corpus": "reddit"}]