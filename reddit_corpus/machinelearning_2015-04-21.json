[{"docID": "t5_2r3gv", "qSentId": 57778, "question": "AMA Andrew Ng and Adam Coates", "aSentId": 57779, "answer": "What motivates some big companies to publish their ML tricks, like e.g. the recent Batch Normalization from Google? Aren't they giving away their secret sauce to competitors?\n\nDo you think the published results are just the tip of the iceberg, and the very best findings are kept secret?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57780, "question": "What motivates some big companies to publish their ML tricks, like e.g. the recent Batch Normalization from Google? Aren't they giving away their secret sauce to competitors?\n\nDo you think the published results are just the tip of the iceberg, and the very best findings are kept secret?", "aSentId": 57781, "answer": "As a research organization, Baidu Research and others want to be part of the community, and we want to learn from as well as contribute to it.  Of course, publishing also helps us attract talent, and also give our team better internal and external visibility.  But underlying this is that we're researchers and just want to invent ideas that help make the world a better place!  \n\nHaving said that, the mission of the Baidu's AI Lab is to develop hard AI technologies that let us impact hundreds of millions of users.  Thus our focus is on developing and shipping technologies.  It's just that we're pretty open and transparent and are happy to publish a lot of what we learn along the way.  \n\n(By the way, Adam Coates and I are sitting together, so you should assume all these answers are written by both of us.) ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57780, "question": "What motivates some big companies to publish their ML tricks, like e.g. the recent Batch Normalization from Google? Aren't they giving away their secret sauce to competitors?\n\nDo you think the published results are just the tip of the iceberg, and the very best findings are kept secret?", "aSentId": 57783, "answer": "To hire the best researchers they have to demonstrate how world class their research is, which in turn requires publishing lots of good papers. \n\nGoogle publish papers about the majority of advancements in ML.  The thing they rarely talk about is which specific services within Google use ML.   For example,  there are no papers about machine learning in web search.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57780, "question": "What motivates some big companies to publish their ML tricks, like e.g. the recent Batch Normalization from Google? Aren't they giving away their secret sauce to competitors?\n\nDo you think the published results are just the tip of the iceberg, and the very best findings are kept secret?", "aSentId": 57785, "answer": "I wonder whether these techniques are actually patented so that Google profits if others build upon them (because they can demand licensing fees).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57786, "question": "I wonder whether these techniques are actually patented so that Google profits if others build upon them (because they can demand licensing fees).", "aSentId": 57787, "answer": "To my knowledge there aren't any credible patents in deep learning.  \n\nThis is unlike much of computer vision, which has a minefield of patents holding back progress.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57788, "question": "To my knowledge there aren't any credible patents in deep learning.  \n\nThis is unlike much of computer vision, which has a minefield of patents holding back progress.  ", "aSentId": 57789, "answer": "Patents take a year or two to go through the system.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57790, "question": "Patents take a year or two to go through the system.", "aSentId": 57791, "answer": "Neural networks have been around for decades and I haven't seen any credible patents.  The really industrially relevant work in deep learning is more than 1-2 years old.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57792, "question": "Neural networks have been around for decades and I haven't seen any credible patents.  The really industrially relevant work in deep learning is more than 1-2 years old.  ", "aSentId": 57793, "answer": "The question was specifically about newer work from Google, Facebook etc.\n\n\"What motivates some big companies to publish their ML tricks, like e.g. the recent Batch Normalization from Google?\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57778, "question": "AMA Andrew Ng and Adam Coates", "aSentId": 57796, "answer": "I am a big fan of your work Dr. Ng, your coursera course was what introduced me to Machine Learning. My question is do you think a PhD or Masters degree is a strong requirement for those who wish to do ML research in industry or can a Bachelors and independent learning be enough? Thanks.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57797, "question": "I am a big fan of your work Dr. Ng, your coursera course was what introduced me to Machine Learning. My question is do you think a PhD or Masters degree is a strong requirement for those who wish to do ML research in industry or can a Bachelors and independent learning be enough? Thanks.", "aSentId": 57798, "answer": "This question is very common. I would try to help answer this question. It depends what company you are trying to work for. The bigger the company the more they want to see a Masters or PhD degree although that is not always the case. The smaller/newer companies are more willing to accept Bachelors with independent learning. I was looking for entry jobs in the data science field one day and notice a company write out in the job description \"Online degree or certificate can replace 1 year of relevant job experience.\" Just think about this, there are more and more companies wanting people with data analytic/mining skills to get an edge in their respective industries. I believe online learning is also on the rise. Sooner or later companies will accept online certificate (free or not). Masters/PhD are for people wanting to focusing on a area within ML. Bachelors and independent learning is for people who want to get their feet in the door then get the small company pay for your Masters/PhD. Some smaller company pay competitively and raises are based on performance of the company/your contribution.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57799, "question": "This question is very common. I would try to help answer this question. It depends what company you are trying to work for. The bigger the company the more they want to see a Masters or PhD degree although that is not always the case. The smaller/newer companies are more willing to accept Bachelors with independent learning. I was looking for entry jobs in the data science field one day and notice a company write out in the job description \"Online degree or certificate can replace 1 year of relevant job experience.\" Just think about this, there are more and more companies wanting people with data analytic/mining skills to get an edge in their respective industries. I believe online learning is also on the rise. Sooner or later companies will accept online certificate (free or not). Masters/PhD are for people wanting to focusing on a area within ML. Bachelors and independent learning is for people who want to get their feet in the door then get the small company pay for your Masters/PhD. Some smaller company pay competitively and raises are based on performance of the company/your contribution.", "aSentId": 57800, "answer": "I agree that the newer companies---ones that know how to evaluate machine learning talent---care more about your ability, and less about the credential (such as MS or PhD).  For example, at Baidu Research, we do hire top machine learning researchers and machine learning engineers that don't have a graduate degree, but have great software skills and have knowledge of ML from elsewhere. \n\nOver time, companies are also increasingly valuing certificates earned from MOOCs.  \n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57799, "question": "This question is very common. I would try to help answer this question. It depends what company you are trying to work for. The bigger the company the more they want to see a Masters or PhD degree although that is not always the case. The smaller/newer companies are more willing to accept Bachelors with independent learning. I was looking for entry jobs in the data science field one day and notice a company write out in the job description \"Online degree or certificate can replace 1 year of relevant job experience.\" Just think about this, there are more and more companies wanting people with data analytic/mining skills to get an edge in their respective industries. I believe online learning is also on the rise. Sooner or later companies will accept online certificate (free or not). Masters/PhD are for people wanting to focusing on a area within ML. Bachelors and independent learning is for people who want to get their feet in the door then get the small company pay for your Masters/PhD. Some smaller company pay competitively and raises are based on performance of the company/your contribution.", "aSentId": 57802, "answer": "There really isn't much specialization within ML at the Masters level, even at the Top 10 schools - that's mostly reserved for PhDs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57803, "question": "There really isn't much specialization within ML at the Masters level, even at the Top 10 schools - that's mostly reserved for PhDs.", "aSentId": 57804, "answer": "respected Dr. Ng , can you please share your perspective on Online MS in Data Science from Berkely and Online MS with Specilization in MS from Georgia Tech ? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57803, "question": "There really isn't much specialization within ML at the Masters level, even at the Top 10 schools - that's mostly reserved for PhDs.", "aSentId": 57806, "answer": "That's the entire point of getting a PhD in anything. A masters is too general and you want to specialize on a very specific topic.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57797, "question": "I am a big fan of your work Dr. Ng, your coursera course was what introduced me to Machine Learning. My question is do you think a PhD or Masters degree is a strong requirement for those who wish to do ML research in industry or can a Bachelors and independent learning be enough? Thanks.", "aSentId": 57808, "answer": "Same question. Very relevant because a huge number of students are taking your ML courses to start with.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57797, "question": "I am a big fan of your work Dr. Ng, your coursera course was what introduced me to Machine Learning. My question is do you think a PhD or Masters degree is a strong requirement for those who wish to do ML research in industry or can a Bachelors and independent learning be enough? Thanks.", "aSentId": 57810, "answer": "If you want to do ML research, where research means developing new algorithms, methods, anything not in the already present \"ML cookbooks\" - you need a PhD (or a Master's and significant experience in research).\n\nFrom what I've heard from a few friends currently working in Facebook &amp; Google - there they don't let you touch research (or even ML) without a PhD in the field.\n\nFrom my personal experience, I got a few job opportunities (NLP, ML), and on each of the interviews, the company / team leader already had a set plan for which methods will be used for the problem.\n\nThe only options I see possible, as /u/hachidan05 already wrote, is aiming for startups/smaller companies, which usually have lower standards - and finding one that will allow you to do research for them.\n\nAlternatively, set up a strong GitHub account. Employers often check those things, and if you have coded SVM's, regression models, clustering from scratch (and applied it successfully to some known datasets), that could be proof enough of your skill.\n\n*My background - MSc in Computer Science - ML+NLP &amp; 1 year of work in the field*\n\nSince I'm kind of late to the party, I'll piggyback off of your comment and try to ask prof. Ng a question as well -\n\n1. Which European universities do you consider best for ML? Or, more specific, which professors do you consider the best in Europe?\n\nMy \"field of expertise\" is ML + NLP with a bit of information retrieval.\n\nI'm planning to apply for a PhD and this would be significant help - thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57811, "question": "If you want to do ML research, where research means developing new algorithms, methods, anything not in the already present \"ML cookbooks\" - you need a PhD (or a Master's and significant experience in research).\n\nFrom what I've heard from a few friends currently working in Facebook &amp; Google - there they don't let you touch research (or even ML) without a PhD in the field.\n\nFrom my personal experience, I got a few job opportunities (NLP, ML), and on each of the interviews, the company / team leader already had a set plan for which methods will be used for the problem.\n\nThe only options I see possible, as /u/hachidan05 already wrote, is aiming for startups/smaller companies, which usually have lower standards - and finding one that will allow you to do research for them.\n\nAlternatively, set up a strong GitHub account. Employers often check those things, and if you have coded SVM's, regression models, clustering from scratch (and applied it successfully to some known datasets), that could be proof enough of your skill.\n\n*My background - MSc in Computer Science - ML+NLP &amp; 1 year of work in the field*\n\nSince I'm kind of late to the party, I'll piggyback off of your comment and try to ask prof. Ng a question as well -\n\n1. Which European universities do you consider best for ML? Or, more specific, which professors do you consider the best in Europe?\n\nMy \"field of expertise\" is ML + NLP with a bit of information retrieval.\n\nI'm planning to apply for a PhD and this would be significant help - thank you.", "aSentId": 57812, "answer": "PHD opens doors, but not everyone has that requirement. I personally try to run a selection process that is as resume blind as possible. Using PHD as an argument for or against either hiring or utilizing someone, is something I have never said. But I have heard it from others. For example, my recruiters are much more likely to pass me a PHD, even though I tell them to stop it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57778, "question": "AMA Andrew Ng and Adam Coates", "aSentId": 57815, "answer": "Hinton seems to think that the next neural abstraction after the layer is the artificial cortical column. Have you done any work toward this end goal? \n\nAlso what are your thoughts on HTM and the CLA (Numenta)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57816, "question": "Hinton seems to think that the next neural abstraction after the layer is the artificial cortical column. Have you done any work toward this end goal? \n\nAlso what are your thoughts on HTM and the CLA (Numenta)", "aSentId": 57817, "answer": "Why did they ignore this question? It seems like plenty of others wanted to hear the answer.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57816, "question": "Hinton seems to think that the next neural abstraction after the layer is the artificial cortical column. Have you done any work toward this end goal? \n\nAlso what are your thoughts on HTM and the CLA (Numenta)", "aSentId": 57819, "answer": "Do you have any links to Geoff speaking on this?\n\nI'd like to understand it before the answering starts", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57816, "question": "Hinton seems to think that the next neural abstraction after the layer is the artificial cortical column. Have you done any work toward this end goal? \n\nAlso what are your thoughts on HTM and the CLA (Numenta)", "aSentId": 57821, "answer": "That sounds a lot more like Jeff Hawkins than Geoff Hinton. Are you sure you're not getting them mixed up?\n\nEdit: It looks like you did actually mean Hinton after all. Thanks /u/tabacof for clearing up the confusion. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57822, "question": "That sounds a lot more like Jeff Hawkins than Geoff Hinton. Are you sure you're not getting them mixed up?\n\nEdit: It looks like you did actually mean Hinton after all. Thanks /u/tabacof for clearing up the confusion. ", "aSentId": 57823, "answer": "I'm not sure why you're being downvoted without explanation. I'm confused about this as well. I read Jeff Hawkins book and thought this was his work. Can anybody explain? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57825, "question": "@andrewyng \n\nWhat kind of self projects and follow up courses would you recommend after the Coursera ML course?", "aSentId": 57826, "answer": "There seems to be some \"general ML wisdom\" which is not taught in courses like yours or Daphne Kollers PGM, but it enables people (experts) in the field to understand each other's research/presentations. How/where can one acquire this knowledge?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57830, "question": "Hi Andrew and Adam! Many thanks for taking the time for this!\n\n(1) What are your thoughts on the role that theory is to play in the future of ML, particularly as models grow in complexity? It often seems like that the gap between theory and practice is widening.\n\n(2) What are your thoughts on the future of unsupervised learning, especially now that (properly initialized and regularized) supervised techniques are leading the pack? Will layer-by-layer pretraining end up as a historical footnote?", "aSentId": 57831, "answer": "Hi Eldeemon, \n\nGreat question.  I think that 50 years ago, CS theory was really driving progress in CS practice. For example, the theoretical work figuring out that sorting is O(n log n), and Don Knuth's early books, really helped advance the field.  Today, there're some areas of theory that're still driving practice, such as computer security: If you find a flaw in crypto and publish a theoretical paper about it, this can cause code to be written all around the world. \n\nBut in machine learning, progress is increasingly driven by empirical work rather than theory.  Both still remain important (for example, I'm inspired by a lot of Yoshua Bengio's theoretical work), but in the future I hope we can do a better job connecting theory and practice. \n\nAs for unsupervised learning, I remain optimistic about it, but just have no idea what the right algorithm is.  I think layer-by-layer pretraining was a good first attempt.  But it really remains to be seen if researchers come up with something dramatically different in the coming years!  (I'm seeing some early signs of this.) ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57832, "question": "Hi Eldeemon, \n\nGreat question.  I think that 50 years ago, CS theory was really driving progress in CS practice. For example, the theoretical work figuring out that sorting is O(n log n), and Don Knuth's early books, really helped advance the field.  Today, there're some areas of theory that're still driving practice, such as computer security: If you find a flaw in crypto and publish a theoretical paper about it, this can cause code to be written all around the world. \n\nBut in machine learning, progress is increasingly driven by empirical work rather than theory.  Both still remain important (for example, I'm inspired by a lot of Yoshua Bengio's theoretical work), but in the future I hope we can do a better job connecting theory and practice. \n\nAs for unsupervised learning, I remain optimistic about it, but just have no idea what the right algorithm is.  I think layer-by-layer pretraining was a good first attempt.  But it really remains to be seen if researchers come up with something dramatically different in the coming years!  (I'm seeing some early signs of this.) ", "aSentId": 57833, "answer": "&gt; As for unsupervised learning, I remain optimistic about it, but just have no idea what the right algorithm is. I think layer-by-layer pretraining was a good first attempt. But it really remains to be seen if researchers come up with something dramatically different in the coming years! (I'm seeing some early signs of this.)\n\nCan you share those early signs with the rest of us?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57835, "question": "What are your thoughts on ML competitions (the most well-known example being kaggle)? And more generally, do you think gamification is beneficial to (ML) research?", "aSentId": 57836, "answer": "Is it just me that fears this? I am worried it will lead to talented people giving their skills and time away and driving their worth down. Why hire an expert when you can run a competition for the fraction of the cost?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57837, "question": "Is it just me that fears this? I am worried it will lead to talented people giving their skills and time away and driving their worth down. Why hire an expert when you can run a competition for the fraction of the cost?", "aSentId": 57838, "answer": "Isn't it just the reality of a market economy? If people are willing to give it away for free then the expert isn't worth her high fee.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57839, "question": "Isn't it just the reality of a market economy? If people are willing to give it away for free then the expert isn't worth her high fee.", "aSentId": 57840, "answer": "it's a dumb fear anyway. You can get to 90% of a winning kaggle score with sklearn or other off the shelf software, but you'll still need a professional to build a robust pipeline.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57841, "question": "it's a dumb fear anyway. You can get to 90% of a winning kaggle score with sklearn or other off the shelf software, but you'll still need a professional to build a robust pipeline.", "aSentId": 57842, "answer": "That's irrelevant - if the professional is willing to give it away it devalues everyone ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57843, "question": "That's irrelevant - if the professional is willing to give it away it devalues everyone ", "aSentId": 57844, "answer": "give what away?\n\nkaggle competitions are about taking preprocessed data and building an ungodly ensemble to squeeze every last drop from a performance metric.\n\nthe solutions are very different from a usable product.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57845, "question": "give what away?\n\nkaggle competitions are about taking preprocessed data and building an ungodly ensemble to squeeze every last drop from a performance metric.\n\nthe solutions are very different from a usable product.", "aSentId": 57846, "answer": "Couldn't agree with you more. Typically, the competition results provide a benchmark --- given the current data, what performance is feasible? --- and often, winners are invited to discuss their solutions with the company in question.\n\nI don't think it promotes 'research', because as you said, ungodly ensembles are often the winner. However, the gamification/competition aspect does seem to lead to the creation of new 'tricks': classifier ensembles that haven't been used before, hacks that reduce runtime, smart sampling or featurespace-reduction, etc.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57847, "question": "Couldn't agree with you more. Typically, the competition results provide a benchmark --- given the current data, what performance is feasible? --- and often, winners are invited to discuss their solutions with the company in question.\n\nI don't think it promotes 'research', because as you said, ungodly ensembles are often the winner. However, the gamification/competition aspect does seem to lead to the creation of new 'tricks': classifier ensembles that haven't been used before, hacks that reduce runtime, smart sampling or featurespace-reduction, etc.", "aSentId": 57848, "answer": "What do you mean by ungodly ensemble? I'm halfway through the coursera ML course and haven't heard this sort of description. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57839, "question": "Isn't it just the reality of a market economy? If people are willing to give it away for free then the expert isn't worth her high fee.", "aSentId": 57850, "answer": "Exactly my thought yeah", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57852, "question": "Can you touch on what makes Baidu, in terms of the work being done (applications of the research etc.) and the work environment (autonomy, benefits, career growth / mobility etc.), a more attractive workplace for machine learning and AI engineers vs. other companies like Google or Facebook?", "aSentId": 57853, "answer": "I think Baidu, Google and Facebook are all great places to work! \n\nI don't want to compare Baidu against any other company (since I think they're all great).  But Baidu Research is very much a startup environment.  With ~40 people in our Silicon Valley team, we tend to act with the nimbleness of a startup of a commensurate size (albeit with the access to computational power and data of a $75B company).  We also invest a lot in employee development, and so I see that people here are all working hard and learning rapidly about deep learning, HPC, etc.  I think these things make the best possible combination for driving machine learning research, which is why both of us (Adam &amp; Andrew) had decided to join Baidu.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57857, "question": "Hey Andrew, huge fan of your work, mainly Machine Learning Coursera course that basically started my interest in ML area. \n\nQuestion: I have seen that your work is focused in DL, however I have not seen or read any work of yours focusing on Recurrent Neural Networks (RNN). Works in this area like the one that has been done by Schmidhuber with Long Short-Term Memories (LSTM)  are very famous and started to win some contests. Have you never thought about working and researching with RNNs? With your experience, can you point some pros and cons of RNNs?\n\nThanks a lot!", "aSentId": 57858, "answer": "I think RNNs are an exciting class of models for temporal data!  In fact, our recent breakthrough in speech recognition used bi-directional RNNs.  See http://bit.ly/deepspeech   We also considered LSTMs.  For our particular application, we found that the simplicity of RNNs (compared to LSTMs) allowed us to scale up to larger models, and thus we were able to get RNNs to perform better.  But at Baidu we are also applying LSTMs to a few problems were there is are longer-range dependencies in the temporal data. \n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57862, "question": "What do you wish you had known at the start of your career?", "aSentId": 57863, "answer": "One of the things both of us (Adam &amp; Andrew) talk about frequently is the impact of research.  At Baidu, our goal is to develop hard AI technologies that impact hundreds of millions of users.  Over time, I think we've both learned to be more strategic, and to learn to see more steps out ahead--beyond just writing a paper--to plot a path to seeing our technology benefit huge numbers of people.  These days, this is one of the things that really excite us about our work! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57866, "question": "J\u00fcrgen Schmidhuber QUOTE: *\"Since BP was 3-5 decades old by then, and pattern deformations 2 decades, these results seemed to suggest that advances in exploiting modern computing hardware were more important than advances in algorithms.\"* [1]\n\nYann LeCun QUOTE: *\"Basically we limited by computational power. So, the faster, you know, the next generation of Nvidia GPU will be the more progress we'll make.\"* [2]\n\nWhat is your opinion about the matter?\n\n[1] Juergen Schmidhuber, 2014, Deep Learning in Neural Networks: An Overview\n\n[2] Yann LeCun, 2014, Convolutional Networks- Machine Learning for Computer Perception (Nvidia webinar, 2014) ", "aSentId": 57867, "answer": "&gt; [1] Juergen Schmidhuber, 2014, Deep Learning in Neural Networks: An Overview\n\nFor those interested, reference [1] points to section 5.18 (page 23)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57869, "question": "Do you think neural networks will continue to be the dominant paradigm in ML, or will we see a swing back to greater diversity, with things like Bayesian nonparametrics and deep architectures constructed out of non-NN layers?", "aSentId": 57870, "answer": "Linear/logistic regression and k-means clustering are probably the dominant paradigms in ML, and likely will always be. There's just too much bang for the buck.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57869, "question": "Do you think neural networks will continue to be the dominant paradigm in ML, or will we see a swing back to greater diversity, with things like Bayesian nonparametrics and deep architectures constructed out of non-NN layers?", "aSentId": 57872, "answer": "Neural networks are certainly not the dominant paradigm in ML.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57873, "question": "Neural networks are certainly not the dominant paradigm in ML.", "aSentId": 57874, "answer": "aren't they in terms of state-of-the-art progress on numerous tasks?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57875, "question": "aren't they in terms of state-of-the-art progress on numerous tasks?", "aSentId": 57876, "answer": "They are state-of-the-art on a few supervised tasks for which there is a large amount of data.  While that set of tasks is growing, machine learning is a large field and deep learning is still a relatively small part of it in both industry and academia.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57877, "question": "They are state-of-the-art on a few supervised tasks for which there is a large amount of data.  While that set of tasks is growing, machine learning is a large field and deep learning is still a relatively small part of it in both industry and academia.", "aSentId": 57878, "answer": "Computer vision, reinforcement learning and language processing are very broad subjects though.. Of course, DL is often used in combination with some other method, but it is very prominent nowadays. \n\nI'm not saying that you should just forget about Bayesian methods or manually constructed features, but, in my opinion, it is not unlikely that CNNs will be taught in CV courses soon.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57879, "question": "Computer vision, reinforcement learning and language processing are very broad subjects though.. Of course, DL is often used in combination with some other method, but it is very prominent nowadays. \n\nI'm not saying that you should just forget about Bayesian methods or manually constructed features, but, in my opinion, it is not unlikely that CNNs will be taught in CV courses soon.", "aSentId": 57880, "answer": "Sure.  Note that I did not say that neural networks were unimportant.  I said that it is incorrect to call them the dominant paradigm in machine learning.  I'd agree that CNNs will be taught in computer vision courses soon, and they obviously should be, but that doesn't change my point.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57881, "question": "Sure.  Note that I did not say that neural networks were unimportant.  I said that it is incorrect to call them the dominant paradigm in machine learning.  I'd agree that CNNs will be taught in computer vision courses soon, and they obviously should be, but that doesn't change my point.", "aSentId": 57882, "answer": "fair enough.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57879, "question": "Computer vision, reinforcement learning and language processing are very broad subjects though.. Of course, DL is often used in combination with some other method, but it is very prominent nowadays. \n\nI'm not saying that you should just forget about Bayesian methods or manually constructed features, but, in my opinion, it is not unlikely that CNNs will be taught in CV courses soon.", "aSentId": 57884, "answer": "There's a course at Stanford that was offered for the first time this year that is actually called \"Convolutional Neural Networks for Computer Vision\". I'm inclined to agree with you that NN is quickly becoming the dominant paradigm. I can think of a number of models in NLP that can be represented as one-hidden-layer neural networks even if they aren't taught as such, and I wouldn't be surprised if that was the case (implicit NNs) in other fields.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57873, "question": "Neural networks are certainly not the dominant paradigm in ML.", "aSentId": 57886, "answer": "Thank you! You'd never know it from this sub, since every other post is on some deep learning NN. In my field (computational biology) I never see enough data that would justify this approach. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57893, "question": "Is contrastive divergence still useful for training or has it been supplanted by other methods?", "aSentId": 57894, "answer": "In the early days of deep learning, Hinton had developed a few probabilistic deep learning algorithms such as Restricted Boltzmann Machines, which trained using contrastive divergence.  But these models were really complicated, and computing the normalization constant (partition function) was intractable, leading to really complex MCMC and other algorithms for training them. \n\nOver the next few years, we realized that these probabilistic formalisms didn't offer any advantage in most settings, but just added a lot of complexity.  Thus, almost all of deep learning has since moved away from these probabilistic formalisms, to instead use neural networks with deterministic computations.  One notable exception is that there're still a few groups (such as Ruslan Salakhutdinov's) doing very cool work on generative models using RBMs; but this is a minority.  Most of deep learning is now done using backpropagation, and contrastive divergence is very rarely used.  \n\nAs an aside, most of deep learning's successes today are due to supervised learning (trained with backprop).  Looking a little further out, I'm still very excited about the potential of unsupervised learning, since we have a lot more unlabeled data than labeled data; it's just that we just don't know what are the right algorithms are for unsupervised, and lots more research is needed here! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57895, "question": "In the early days of deep learning, Hinton had developed a few probabilistic deep learning algorithms such as Restricted Boltzmann Machines, which trained using contrastive divergence.  But these models were really complicated, and computing the normalization constant (partition function) was intractable, leading to really complex MCMC and other algorithms for training them. \n\nOver the next few years, we realized that these probabilistic formalisms didn't offer any advantage in most settings, but just added a lot of complexity.  Thus, almost all of deep learning has since moved away from these probabilistic formalisms, to instead use neural networks with deterministic computations.  One notable exception is that there're still a few groups (such as Ruslan Salakhutdinov's) doing very cool work on generative models using RBMs; but this is a minority.  Most of deep learning is now done using backpropagation, and contrastive divergence is very rarely used.  \n\nAs an aside, most of deep learning's successes today are due to supervised learning (trained with backprop).  Looking a little further out, I'm still very excited about the potential of unsupervised learning, since we have a lot more unlabeled data than labeled data; it's just that we just don't know what are the right algorithms are for unsupervised, and lots more research is needed here! ", "aSentId": 57896, "answer": "Thanks! So are RBMs still the best for making generative models or even there auto-encoders, etc. are ahead?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57897, "question": "Thanks! So are RBMs still the best for making generative models or even there auto-encoders, etc. are ahead?", "aSentId": 57898, "answer": "I think that variational autoencoders have been getting the best results for generative modeling.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57899, "question": "I think that variational autoencoders have been getting the best results for generative modeling.  ", "aSentId": 57900, "answer": "How do you judge performance at generative modeling? Like, if the task is image recognition and you train the model on cats and dogs, and you ask for a cat, it spits something out, and then what? Does some person say \"yep that looks like a cat\"?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57901, "question": "How do you judge performance at generative modeling? Like, if the task is image recognition and you train the model on cats and dogs, and you ask for a cat, it spits something out, and then what? Does some person say \"yep that looks like a cat\"?", "aSentId": 57902, "answer": "So typically the model doesn't just give samples from the distribution p(x), it also lets you evaluate p(x).  So one evaluation metric is the observed values p(x) on the test data.  \n\nThis is actually kind of weak because: \n  -No one knows what a good likelihood is.  It's hard to interpret.  \n  -A model could make really good generative samples and not be good at estimating likelihood.  \n\nEvaluation metrics for generative models is definitely an area that could use work.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57907, "question": "@andrewyng\nFirst of all I wanted to say that your ML course on Coursera was amazing. Thank you!\n\n(1)\nHow much learning others helped you to develop your own skills in ML? You definitely put a lot of effort to prepare your online materials. Do you do this only to help others or maybe while preparing your materials you have also learned a lot - for example maybe you often investigated some concepts more deeply than you knew them before only because you wanted to explain them to others as clearly as possible.\n\n(2)\nYou have both outstanding academic and commercial experience.\nAre there any ML concepts or intuitions which are easier or faster to learn when you work for companies? And inversely - are there things which are easier / faster to learn in the academic world? I'm asking because lot of ML engineers seems to have PhD. So how is it helpful? Are those paths (commercial vs academic) somehow different?\n\n(3)\nWhich set of skills you find the most important in the ML field - is it practical application of ML, statistics or maybe domain knowledge of a particular problem?\nFor example lets assume that I want to develop a speech recognition system and I'm an expert in ML, but I do know nothing about audio processing. Do I have a chance to be successful?", "aSentId": 57908, "answer": "Thank you for taking the Coursera ML MOOC! \n\n(1) The old saw that teaching others helps you to learn really is true.  FWIW though I think one of the reasons I've had a few successes in research is because I'm a decent teacher.  This helps me to build a great team, and it's usually the team (not me) that comes up with many of the great ideas you see us publish and write about.  I think innovation often requires the combination of dozens of ideas from multiple team members, so I spend a lot of time trying to build that great team that can have those ideas.\n\n(2) A lot of deep learning progress is driven by computational scale, and by data.  For example, I think the bleeding edge of deep learning is shifting to HPC (high performance computing aka supercomputers), which is what we're working on at Baidu.  I've found it easier to build new HPC technologies and access huge amounts of data in a corporate context.  I hope that governments will increase funding of basic research, so as to make these resources easier for universities all around the world to get. \n\n(3) The skillset needed for different problems is different.  But broadly, the two sources of \"knowledge\" a program can have about a problem are (i) what you hand-engineer, and (ii) what it learns by itself from data.  In some fields (such as computer vision; and I predict increasingly so speech recognition and NLP in the future), the rapidly rising flood of data means that (ii) is now the dominant force, and thus the domain knowledge and the ability to hand-engineer little features is becoming less and less important.  5 years ago, it was really difficult to get involved in computer vision or speech recognition research, because there was a lot of domain knowledge you had to acquire.  But thanks to the rise of deep learning and the rise of data, I think the learning curve is now easier/shallower, because what's driving progress is machine learning+data, and it's now less critical to know about and be able to hand-engineer as many corner cases for these domains.  I'm probably over-simplifying a bit, but now the winning approach is increasingly to code up a learning algorithm, using only a modest amount of domain knowledge, and then to give it a ton of data, and let the algorithm figure things out from the data. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57912, "question": "A common weakness of Coursera and edX MOOCs is that they are watered down superficial versions of live courses. Students are not asked to solve any hard problems for fear of losing the audience, but as a result are not able to really learn the content of the course in a way that will allow them to apply it in real life scenarios. There are very few exceptions like Daphne Koller's PGM course or the ML course from Caltech on edX.\n\nDo you see any place for advanced Masters or PhD level courses on the Coursera platform, and if so, what steps are you taking to encourage their creation?", "aSentId": 57913, "answer": "My experience is the opposite. I have much more interaction with the material on Coursera and understand it better than I do in offline universities because of Coursera's automation.\n\nI see a very high correlation between making a course computer-based and my results in it. For me, barriers are lowered through the direct feedback of the quizzes and the automated direct assessment of your own code. Being able to selectively pause, rewind, and re-watch lectures has not been offered to me by offline universities and vastly improves understanding for me as well. When you're sitting in a hall with 100 students, I've found that fellow students *don't* like it when questions are asked, because everyone has different aspects they get stuck on, and what is unclear for you may well be clear to others. That's demotivating, but doesn't apply to Coursera.\n\nIn offline universities, it usually takes weeks for your results to get back to you, and by that time you've been put on new assignments already.\n\nI don't know if MOOCs will overtake offline universities, but I do know that they are more effective for me.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57914, "question": "My experience is the opposite. I have much more interaction with the material on Coursera and understand it better than I do in offline universities because of Coursera's automation.\n\nI see a very high correlation between making a course computer-based and my results in it. For me, barriers are lowered through the direct feedback of the quizzes and the automated direct assessment of your own code. Being able to selectively pause, rewind, and re-watch lectures has not been offered to me by offline universities and vastly improves understanding for me as well. When you're sitting in a hall with 100 students, I've found that fellow students *don't* like it when questions are asked, because everyone has different aspects they get stuck on, and what is unclear for you may well be clear to others. That's demotivating, but doesn't apply to Coursera.\n\nIn offline universities, it usually takes weeks for your results to get back to you, and by that time you've been put on new assignments already.\n\nI don't know if MOOCs will overtake offline universities, but I do know that they are more effective for me.", "aSentId": 57915, "answer": "Thanks for weighing in. I don't think we actually disagree. I also like all the things you mentioned about MOOCs. My comment relates to the level of the material that is presented and the difficulty of the homeworks. I've completed close to two dozen Coursera and edX courses now and only a couple come anywhere near the level of complexity of higher level undergrad or graduate courses. This has mostly to do with the fact that a typical homework takes the shape of a multiple choice quiz that gives you 100 tries and can be completed in half an hour with only a vague understanding of the material. An upper level university course on the other hand involves independent problem solving and development of ideas - activities that require you to incorporate course concepts into your working memory.\n\nI see the same Intro to Stats/Data Science or Single Variable Calculus popping up over and over again on Coursera but not a single Bayesian Inference, or Group Theory, or any other \"Insert Advanced Subject Here\". Having these would be quite nice as many on Coursera already have university degrees and are not well served by the innumerable introductory courses. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57916, "question": "Thanks for weighing in. I don't think we actually disagree. I also like all the things you mentioned about MOOCs. My comment relates to the level of the material that is presented and the difficulty of the homeworks. I've completed close to two dozen Coursera and edX courses now and only a couple come anywhere near the level of complexity of higher level undergrad or graduate courses. This has mostly to do with the fact that a typical homework takes the shape of a multiple choice quiz that gives you 100 tries and can be completed in half an hour with only a vague understanding of the material. An upper level university course on the other hand involves independent problem solving and development of ideas - activities that require you to incorporate course concepts into your working memory.\n\nI see the same Intro to Stats/Data Science or Single Variable Calculus popping up over and over again on Coursera but not a single Bayesian Inference, or Group Theory, or any other \"Insert Advanced Subject Here\". Having these would be quite nice as many on Coursera already have university degrees and are not well served by the innumerable introductory courses. ", "aSentId": 57917, "answer": "Well, our experiences certainly don't match up, but note that I'm not necessarily arguing from an objective basis, just relaying my own experiences.\n\nWhile there are ample courses that are less advanced on Coursera, the fact that they have the interaction I never got in university more than makes up for it for me. I'm fairly certain I simply learn more in any given Coursera course than offline course because of the reasons I've given.\n\n&gt; This has mostly to do with the fact that a typical homework takes the shape of a multiple choice quiz that gives you 100 tries and can be completed in half an hour with only a vague understanding of the material.\n\nTry a course where you do need to do so, especially the courses where you're encouraged to code up solutions to problems. Try guessing a number then or getting to the answer with only partial understanding...\n\n&gt; I see the same Intro to Stats/Data Science or Single Variable Calculus popping up over and over again on Coursera but not a single Bayesian Inference, or Group Theory, or any other \"Insert Advanced Subject Here\".\n\nI haven't even seen those (but I haven't looked since I'm supposed to be past that level anyway). Try cryptography. Algorithms. Ng's machine learning (did you do that one already?). Electrical engineering.\n\nI do agree that more advanced courses would be better though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57916, "question": "Thanks for weighing in. I don't think we actually disagree. I also like all the things you mentioned about MOOCs. My comment relates to the level of the material that is presented and the difficulty of the homeworks. I've completed close to two dozen Coursera and edX courses now and only a couple come anywhere near the level of complexity of higher level undergrad or graduate courses. This has mostly to do with the fact that a typical homework takes the shape of a multiple choice quiz that gives you 100 tries and can be completed in half an hour with only a vague understanding of the material. An upper level university course on the other hand involves independent problem solving and development of ideas - activities that require you to incorporate course concepts into your working memory.\n\nI see the same Intro to Stats/Data Science or Single Variable Calculus popping up over and over again on Coursera but not a single Bayesian Inference, or Group Theory, or any other \"Insert Advanced Subject Here\". Having these would be quite nice as many on Coursera already have university degrees and are not well served by the innumerable introductory courses. ", "aSentId": 57919, "answer": "I think Udacity has some Bayesian inference stuff. \n\nThe absence of advanced mathematics beyond basic linear algebra is pretty disappointing, though my hope is that some recent books that have combined functional programming and discrete mathematics, logic, and proofs might translate into a MOOC within the next few years. And Sussman's written two books on using Scheme to learn classical mechanics and basic differential geometry. \n\nAnd edx has some graduate level physics courses like in Effective Field Theory and I think there was a basic functional analysis course offered. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57912, "question": "A common weakness of Coursera and edX MOOCs is that they are watered down superficial versions of live courses. Students are not asked to solve any hard problems for fear of losing the audience, but as a result are not able to really learn the content of the course in a way that will allow them to apply it in real life scenarios. There are very few exceptions like Daphne Koller's PGM course or the ML course from Caltech on edX.\n\nDo you see any place for advanced Masters or PhD level courses on the Coursera platform, and if so, what steps are you taking to encourage their creation?", "aSentId": 57921, "answer": "I agree, one can see a great gap between Andrew's course taught in Stanford and the Coursera version. A lot of math is ommited, theories are simplified - that's surely a big disadvantage of MOOC (i've taken a few other courses and all of them had that lack-of-deep-math problem).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57932, "question": "This one is for Adam.\n\nYour work that I'm most familiar with was exploring/describing single layer networks that performed better than the more complex/deep learning learning methods of the time on the CIFAR dataset.\n\nDo you think that simpler configurations are possible that can compete with todays large network performance? Would it only be for certain dataset configurations that are difficult for large networks and their variants?\n\nThanks!", "aSentId": 57933, "answer": "One of the reasons we looked at single layer networks was so that we could rapidly explore a lot of characteristics that we felt could influence how these models performed without a lot of the complexity that deep networks brought at the time (e.g., needing to train layer-by-layer).  There is lots of evidence (empirical and theoretical) today, however, that deep networks can represent far more complex functions than shallow ones and, thus, to make use of the very large training datasets available, it is probably important to continue using large/deep networks for these problems.\n\nThankfully, while deep networks can be tricky to get working compared to some of the simplest models in 2011, today we have the benefit of much better tools and faster computers --- this lets us iterate quickly and explore in a way that we couldn't do in 2011.  In some sense, building better systems for DL has enabled us to explore large, deep models at a pace similar to what we could do in 2011 only for very simple models.  This is one of the reasons we invest a lot in systems research for deep learning here in the AI Lab:  the faster we are able to run experiments, the more rapidly we can learn, and the easier it is to find models that are successful and understand all of the trade-offs.   \n\nSometimes the \"best\" model ends up being a bit more complex than we want, but the good news is that the *process* of finding these models has been simplified a lot!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57934, "question": "One of the reasons we looked at single layer networks was so that we could rapidly explore a lot of characteristics that we felt could influence how these models performed without a lot of the complexity that deep networks brought at the time (e.g., needing to train layer-by-layer).  There is lots of evidence (empirical and theoretical) today, however, that deep networks can represent far more complex functions than shallow ones and, thus, to make use of the very large training datasets available, it is probably important to continue using large/deep networks for these problems.\n\nThankfully, while deep networks can be tricky to get working compared to some of the simplest models in 2011, today we have the benefit of much better tools and faster computers --- this lets us iterate quickly and explore in a way that we couldn't do in 2011.  In some sense, building better systems for DL has enabled us to explore large, deep models at a pace similar to what we could do in 2011 only for very simple models.  This is one of the reasons we invest a lot in systems research for deep learning here in the AI Lab:  the faster we are able to run experiments, the more rapidly we can learn, and the easier it is to find models that are successful and understand all of the trade-offs.   \n\nSometimes the \"best\" model ends up being a bit more complex than we want, but the good news is that the *process* of finding these models has been simplified a lot!", "aSentId": 57935, "answer": "Hi Adam!\nI have a follow up question regarding your answer. Do you have any recommended reading for the *process* of finding models? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57938, "question": "If you would have 1000 times the memory (disk/ram) available compared to what you've used so far, what technique would become viable that is currently not, if any? What about 1000000?\n\nIf you would have 1000 times the processing power (in parallel) available compared to what you've used so far, what technique would become viable that is currently not, if any? What about 1000000?\n\nIf you would have 1000 times the processing power (not in parallel, so pure speed/hz) available compared to what you've used so far, what technique would become viable that is currently not, if any? What about 1000000?", "aSentId": 57939, "answer": "ITT: Same techniques, bigger nets.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57943, "question": "Hi Andrew, I have followed your work with interest and audited a few of your machine learning courses online.  They have been an incredible resource.  I actually made use of your homework exercises on the sparse autoencoder in my research on neural activity. So thanks for your dedication to education!  I wanted to ask: when you are confronted with a large/high-dimensional/complex data set, what are the main early considerations that you use in determining what family of learning algorithms you will try with it?  Do you have a recommended standard approach (e.g. start simple and linear and move to more complex techniques if those fail?) or are there things that you might notice in a data set that suggest that particular types of algorithms might be really well suited?", "aSentId": 57944, "answer": "He mentions in the Coursera course that he does start simple, plotting learning curves and such.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57943, "question": "Hi Andrew, I have followed your work with interest and audited a few of your machine learning courses online.  They have been an incredible resource.  I actually made use of your homework exercises on the sparse autoencoder in my research on neural activity. So thanks for your dedication to education!  I wanted to ask: when you are confronted with a large/high-dimensional/complex data set, what are the main early considerations that you use in determining what family of learning algorithms you will try with it?  Do you have a recommended standard approach (e.g. start simple and linear and move to more complex techniques if those fail?) or are there things that you might notice in a data set that suggest that particular types of algorithms might be really well suited?", "aSentId": 57946, "answer": "Pick the simplest model that can actually learn your function.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57976, "question": "Dear Dr. Ng and Dr. Coates,\nWould you please give suggestions on what are the next coursera classes (or other online resources) to take, after Dr. Ng's ML class, for beginners to become more proficient in ML? I understand it probably depends on the learning purpose. I want to use ML to handle some new metabolomics data, where the features are largely unknown.\nThanks, Jen", "aSentId": 57977, "answer": "Dear Andrew, \nOn a separate note, would you please tell us how to correctly pronounce your last name? :) Thanks!\nJen", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57992, "question": "Hi Adam\n\nWhich framework, e.g. Hadoop Map Reduce, Spark, did you use for distributing the tasks between CPUs/GPUs for training billions of connections size neural net?", "aSentId": 57993, "answer": "Many of the current frameworks out there for large scale computation are very successful for problems involving huge amounts of data and relatively less computation.  One of the things I worked on with Bryan Catanzaro and Andrew was how to do distributed computation for deep learning using tools/techniques that are specifically meant to handle very intense computational problems (like MPI/CUDA that come from the HPC/supercomputing world).  There's more in our paper on that topic here:  http://stanford.io/1JHzBwx\n\nSince a lot of the HPC tools ecosystem isn't as well developed for our problems, in the AI Lab / at Baidu Research the systems team is building a platform that let's DL researchers build experiments rapidly (like Hadoop/Spark do for cloud systems) but that run much faster!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 57994, "question": "Many of the current frameworks out there for large scale computation are very successful for problems involving huge amounts of data and relatively less computation.  One of the things I worked on with Bryan Catanzaro and Andrew was how to do distributed computation for deep learning using tools/techniques that are specifically meant to handle very intense computational problems (like MPI/CUDA that come from the HPC/supercomputing world).  There's more in our paper on that topic here:  http://stanford.io/1JHzBwx\n\nSince a lot of the HPC tools ecosystem isn't as well developed for our problems, in the AI Lab / at Baidu Research the systems team is building a platform that let's DL researchers build experiments rapidly (like Hadoop/Spark do for cloud systems) but that run much faster!", "aSentId": 57995, "answer": "Thanks!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58034, "question": "Did you feel uncomfortable working for Baidu during their involvement in the GitHub ddos?", "aSentId": 58035, "answer": "Why would he answer that, it contributes nothing. \n\nThey weren't even involved. You should [get informed](http://krebsonsecurity.com/2015/04/dont-be-fodder-for-chinas-great-cannon/) before you make yourself look very dumb.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58036, "question": "Why would he answer that, it contributes nothing. \n\nThey weren't even involved. You should [get informed](http://krebsonsecurity.com/2015/04/dont-be-fodder-for-chinas-great-cannon/) before you make yourself look very dumb.", "aSentId": 58037, "answer": "Hadn't read that content. I appreciate the link.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58036, "question": "Why would he answer that, it contributes nothing. \n\nThey weren't even involved. You should [get informed](http://krebsonsecurity.com/2015/04/dont-be-fodder-for-chinas-great-cannon/) before you make yourself look very dumb.", "aSentId": 58039, "answer": "In all fairness, Baidu were at least negligent, but definitely not responsible.\n\nTheir code should have been served over HTTPS, making a man-in-the-middle attack at least another level of difficulty. As it is, their inaction allowed their code to be subverted.\n\nBut yes, possibly off-topic for this thread.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58073, "question": "I haven't seen a lot of talk about podcasts on here. Here's a list of ML podcasts I enjoy. Hope it's helpful.", "aSentId": 58074, "answer": "Hey! this is awesome, I was planning to get together a list of resources for ML content and post it here. \n\n\"Linear Digressions\" is pretty cool!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58073, "question": "I haven't seen a lot of talk about podcasts on here. Here's a list of ML podcasts I enjoy. Hope it's helpful.", "aSentId": 58076, "answer": "FWIW, I found the hosts of Partially Derivative to be a bit obnoxious. \"lol we're drunk let's talk data science!\" Not my style.\n\nI enjoyed the two episodes of Talking Machines I listened to.\n\nI hadn't heard of the others. Thanks for the recommendations!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58077, "question": "FWIW, I found the hosts of Partially Derivative to be a bit obnoxious. \"lol we're drunk let's talk data science!\" Not my style.\n\nI enjoyed the two episodes of Talking Machines I listened to.\n\nI hadn't heard of the others. Thanks for the recommendations!", "aSentId": 58078, "answer": "The PartiallyD guys are really good guys who perhaps go a bit overboard with the slapstick humor. Give them another chance.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58073, "question": "I haven't seen a lot of talk about podcasts on here. Here's a list of ML podcasts I enjoy. Hope it's helpful.", "aSentId": 58080, "answer": "Awesome... I was actually thinking about posting in this sub to get recommendations. Any suggestions for statistics podcasts?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58081, "question": "Awesome... I was actually thinking about posting in this sub to get recommendations. Any suggestions for statistics podcasts?", "aSentId": 58082, "answer": "I love The Data Skeptic podcast: http://dataskeptic.com/\n\nIts a combo of mini 15-min episodes explaining statistics concepts from the POV of a layperson and full fledged interviews with industry folks lasting about an hour.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58087, "question": "Applying Deep Learning on Large(~10 million) Sparse high-dimensional(~1000 dimension) real valued medical data", "aSentId": 58088, "answer": "Hard to say -- what kind of medical data are you talking about and what kind of classification do you want to do?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58089, "question": "Hard to say -- what kind of medical data are you talking about and what kind of classification do you want to do?", "aSentId": 58090, "answer": "Predicting the disease - based on various features like symptoms, medication etc. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58091, "question": "Predicting the disease - based on various features like symptoms, medication etc. ", "aSentId": 58092, "answer": "How much labeled data do you have? I'd try a decision tree for something like this first. In general though, deep learning is turning out to be good for a surprising number of applications so it may work.\n\nI haven't found a ton of literature applying deep learning to the bioinformatics or medical domain. There's a few papers on predicting protein folds, drug target interactions, etc. but I doubt much of that is applicable to your situation.\n\nIn general I'd recommend, reading up on deep learning and mining the literature to see what tricks work and what don't and go from there.\n\nAs for what literature -- deeplearning.net has a big overview -- in general feedforward NN are the most common. You can have a look at autoencoders and deep boltzmann machines if you have a ton of unsupervised data. If you can obtain an underlying common description of the symptoms and/or the medication, that would I think be even better as input to the deep net, I think.\n\nGood luck!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58095, "question": "Minimum Probability Flow Learning", "aSentId": 58096, "answer": "They make the claim that K(\\theta) is convex in section 2.4. Can that be true even though they have hidden units?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58097, "question": "They make the claim that K(\\theta) is convex in section 2.4. Can that be true even though they have hidden units?", "aSentId": 58098, "answer": "I think the unstated assumption is that the exponential models have no hidden units. MPF would be convex in this case.\n\nThe RBM MPF objective function is not convex and discussed later in the paper. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58099, "question": "I think the unstated assumption is that the exponential models have no hidden units. MPF would be convex in this case.\n\nThe RBM MPF objective function is not convex and discussed later in the paper. ", "aSentId": 58100, "answer": "From the summary: \"MPF works for any parametric  model  without  hidden  state  variables\".\n\nBTW - Matlab code:\nhttps://github.com/Sohl-Dickstein/Minimum-Probability-Flow-Learning", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58095, "question": "Minimum Probability Flow Learning", "aSentId": 58102, "answer": "I don't understand why minimizing the KL divergence of the data distribution (**p**^(0)) to the dynamically warped distribution (**p**^(epsilon)) is a good idea. Does anyone have any intuition for why this works?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58104, "question": "A Tutorial on Sparse Distributed Representations (Sparse Codes)", "aSentId": 58105, "answer": "&gt;SDRs are also the way the brain stores information. \n\nThat has been figured out with a consensus already?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58104, "question": "A Tutorial on Sparse Distributed Representations (Sparse Codes)", "aSentId": 58107, "answer": "&gt; I have recently created a semi-new method of generating sparse codes in a very fast manner that, to my knowledge, is biologically plausible.\n\nDisclaimer: I don't even play a neuroscientist on TV\n\nI'm not sure your model is biologically plausible. To calculate the updates, you calculate the reconstructions and to do that, you send the signal backwards via the same connections. Real neurons are not thought to be capable of that.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58108, "question": "&gt; I have recently created a semi-new method of generating sparse codes in a very fast manner that, to my knowledge, is biologically plausible.\n\nDisclaimer: I don't even play a neuroscientist on TV\n\nI'm not sure your model is biologically plausible. To calculate the updates, you calculate the reconstructions and to do that, you send the signal backwards via the same connections. Real neurons are not thought to be capable of that.\n", "aSentId": 58109, "answer": "You are right, but it isn't too difficult to use Oja's rule instead. It makes the reconstruction less accurate, but it achieves a similar effect.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58104, "question": "A Tutorial on Sparse Distributed Representations (Sparse Codes)", "aSentId": 58111, "answer": "&gt; &amp;quot;&amp;quot;&amp;quot;Sparse Autoencoder&amp;quot;&amp;quot;&amp;quo\n\nI think some pyhton code wasn't pasted correctly.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58114, "question": "Some practical experiences bringing a machine learning feature to our product", "aSentId": 58115, "answer": "&gt; delivered a solution that allowed us to automate our customer\u2019s actions with greater than 95% accuracy.\n\nThat doesn't mean that ML was used successfully. This customer shipping problem reminds me of a classic example: If you always predict \"not-Spam\" in Email-spam filtering, you'd probably also get something like 98% accuracy. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58116, "question": "&gt; delivered a solution that allowed us to automate our customer\u2019s actions with greater than 95% accuracy.\n\nThat doesn't mean that ML was used successfully. This customer shipping problem reminds me of a classic example: If you always predict \"not-Spam\" in Email-spam filtering, you'd probably also get something like 98% accuracy. ", "aSentId": 58117, "answer": "I disagree.  In your spam example, there are 2 classes, spam and not spam, of which the vast majority are not spam.\n\nIn shipping, you need to predict a carrier (a few), the service of the carrier (many), different types of packaging that can physically contain the assorted physical items that comprise an order (many), as well as different add-on services like insurance and signature required (many).  Customers can have many combinations of these, not just two, and one combination does not dominate.  Randomly selecting a combination of these possibilities does not yield 95% success.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58118, "question": "I disagree.  In your spam example, there are 2 classes, spam and not spam, of which the vast majority are not spam.\n\nIn shipping, you need to predict a carrier (a few), the service of the carrier (many), different types of packaging that can physically contain the assorted physical items that comprise an order (many), as well as different add-on services like insurance and signature required (many).  Customers can have many combinations of these, not just two, and one combination does not dominate.  Randomly selecting a combination of these possibilities does not yield 95% success.", "aSentId": 58119, "answer": "rasbt's answer still has merit. You need to really consider the overall performance of your classiifer/ML system and not just accuracy. Do you have an estimate of the F1-score for instance? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58120, "question": "rasbt's answer still has merit. You need to really consider the overall performance of your classiifer/ML system and not just accuracy. Do you have an estimate of the F1-score for instance? ", "aSentId": 58121, "answer": "As alluded to in other answer to rasbt, that varies from customer data set to customer data set.  The vast majority of our customers have 88+% of their orders with confident predictions, and we get &gt; 95% accuracy on those.  Some customers may be at 93%, some are at 99%.  A very few just don't do well in our system.  We are working with them to see what their decision making is based on that we are not accounting for.  Have any suggestions on how to sniff this out?\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58118, "question": "I disagree.  In your spam example, there are 2 classes, spam and not spam, of which the vast majority are not spam.\n\nIn shipping, you need to predict a carrier (a few), the service of the carrier (many), different types of packaging that can physically contain the assorted physical items that comprise an order (many), as well as different add-on services like insurance and signature required (many).  Customers can have many combinations of these, not just two, and one combination does not dominate.  Randomly selecting a combination of these possibilities does not yield 95% success.", "aSentId": 58123, "answer": "I don't mean to criticize here, I am just suggesting that the 95% accuracy statement doesn't have much meaning without more context . In your particular shipping prediction, e.g., a scenario could be that a customer previously selected 9 / 10 times the same shipping option. Random selection from the pool of previous selection would then yield a 90% accuracy in your training set.\nI am not saying that you should discuss the approach of your system in detail in your post, but it just sounds a little bit weird to throw in the accuracy without context. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58124, "question": "I don't mean to criticize here, I am just suggesting that the 95% accuracy statement doesn't have much meaning without more context . In your particular shipping prediction, e.g., a scenario could be that a customer previously selected 9 / 10 times the same shipping option. Random selection from the pool of previous selection would then yield a 90% accuracy in your training set.\nI am not saying that you should discuss the approach of your system in detail in your post, but it just sounds a little bit weird to throw in the accuracy without context. ", "aSentId": 58125, "answer": "That makes sense.  There are a few reasons for this, first is that I come from an informal background with regards to data science, so I am somewhat ignorant of what would constitute 'proof' from a scientific perspective.  So a mea culpa there.  \n\nAnother reason for the generalization is because we have many different sets of data, one per customer, and you can only describe accuracy in more precise terms within a customer's set of data.  Some will, like you say, choose the same carrier 90% of the time, but most do not.  Its a bit all over the map. For building my knowledge, I would be interested in how you and others more experienced in the field might present information that is split across multiple data sets?\n\nSecond was that the person I was attempting to reach would be someone like myself, having a first foray into machine learning, with informal or latent training.  I was intentionally trying to demystify some aspects of machine learning and how it is explained.  I think having a big table of results would deter the uninitiated.\n\nLastly, the 95% number was our business' goal to consider this a success, and I can show that we've achieved that to their satisfaction.  Again, trying to speak to the practical application of this amazing field, statistical validation was not what I was being paid to deliver.  A usable feature of value to our customers was the ultimate goal, so perhaps the best measure of 'success' would be the number of people using this feature over using the old mechanisms of making shipments.\n\nThanks a bunch for your comments and I welcome all!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58114, "question": "Some practical experiences bringing a machine learning feature to our product", "aSentId": 58127, "answer": "love the username", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58128, "question": "love the username", "aSentId": 58129, "answer": "Thanks!  Yeah, I am not sure how this was not taken a long time ago.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58131, "question": "Python help? json/csv /pandas", "aSentId": 58132, "answer": "Its best to decide what you want to do, and then decide how you want to do that, and then decide if the way you want to do that requires that you convert the data to another format.\n\nIn short: there's no best answer, do whatever is easiest for you and gets the result you want.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58135, "question": "Why GEMM is at the heart of deep learning", "aSentId": 58136, "answer": "The multiplication diagrams don't even make sense. I'm not going to comment on the rest of the article because that made me give up reading it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58137, "question": "The multiplication diagrams don't even make sense. I'm not going to comment on the rest of the article because that made me give up reading it.", "aSentId": 58138, "answer": "Yeah, this really bothered me. Glad I'm not crazy.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58137, "question": "The multiplication diagrams don't even make sense. I'm not going to comment on the rest of the article because that made me give up reading it.", "aSentId": 58140, "answer": "Apologies for the confusion, the diagrams should be fixed now.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58141, "question": "Apologies for the confusion, the diagrams should be fixed now.", "aSentId": 58142, "answer": "Cool :) it can get confusing with the column versus row major languages. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58137, "question": "The multiplication diagrams don't even make sense. I'm not going to comment on the rest of the article because that made me give up reading it.", "aSentId": 58144, "answer": "gemm is a Fortran routine because BLAS was a Fortran standard. The matrices are column-major in Fortran. I guess that is why his illustration is different. But it is mistake nontheless.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58135, "question": "Why GEMM is at the heart of deep learning", "aSentId": 58146, "answer": "Krizhevsky's implementation didn't actually use GEMM for convolution. There are also alternatives based on FFTs, for example, that are quite competitive from my understanding.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58147, "question": "Krizhevsky's implementation didn't actually use GEMM for convolution. There are also alternatives based on FFTs, for example, that are quite competitive from my understanding.", "aSentId": 58148, "answer": "Yes, it seems reasonable that FFT:s should be better. The general algorithms really have to be O(n^3 ) at least unless the kernel is very small.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58149, "question": "Yes, it seems reasonable that FFT:s should be better. The general algorithms really have to be O(n^3 ) at least unless the kernel is very small.", "aSentId": 58150, "answer": "For many years with convolutional nets (before they exploded in 2012), that was definitely the case. Spatial-domain convolution was king because kernels were generally very small. There are also reasons to prefer spatial domain convolution over frequency domain if you are memory-limited, rather than flop-limited, as the FFT approach will require somewhat large temporary buffers.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58149, "question": "Yes, it seems reasonable that FFT:s should be better. The general algorithms really have to be O(n^3 ) at least unless the kernel is very small.", "aSentId": 58152, "answer": "Indeed, FFT is great for large kernel sizes - unfortunately the current trend is towards smaller and smaller kernels (3x3 and even 2x2), so the GEMM approach is still looking like the best all-round match. The increased memory usage can also be an issue.\n\nThings change rapidly when the dimensionality increases though - for 3D convolutions, the FFT approach will probably be hard to beat.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58153, "question": "Indeed, FFT is great for large kernel sizes - unfortunately the current trend is towards smaller and smaller kernels (3x3 and even 2x2), so the GEMM approach is still looking like the best all-round match. The increased memory usage can also be an issue.\n\nThings change rapidly when the dimensionality increases though - for 3D convolutions, the FFT approach will probably be hard to beat.", "aSentId": 58154, "answer": "From what I've seen, the other thing that puts FFT at a disadvantage compared to  the spatial domain is when there's a stride, which is near-universal in the networks I use.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58155, "question": "From what I've seen, the other thing that puts FFT at a disadvantage compared to  the spatial domain is when there's a stride, which is near-universal in the networks I use.", "aSentId": 58156, "answer": "I might be putting my foot in my mouth, but if FFT scratch space isn't an issue, couldn't you just subsample the output after the inverse transform? Or, if you wanted to get fancy, you might even be able to avoid ever computing parts of the inverse transform.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58153, "question": "Indeed, FFT is great for large kernel sizes - unfortunately the current trend is towards smaller and smaller kernels (3x3 and even 2x2), so the GEMM approach is still looking like the best all-round match. The increased memory usage can also be an issue.\n\nThings change rapidly when the dimensionality increases though - for 3D convolutions, the FFT approach will probably be hard to beat.", "aSentId": 58158, "answer": "I see. I had not expected that kernels would be small beforehand, but it seems reasonable in the light of knowing that people search for simple features and try to build complicated features from them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58160, "question": "Clarification about softmax regression", "aSentId": 58161, "answer": "No, \"j\" is the argument of the equation. The gradient is calculated with respect to the argument \"j\". That means that for N parameters in theta, the gradient computation will give you N values (indexed by j) that you can use to modify those parameters.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58163, "question": "Question about ROC Curve", "aSentId": 58164, "answer": "The TPR and FPR do not need to have a linear relationship with one another. In fact, whenever a classifier is non-random they have a relationship where at different discrimination threshold values for a response they form a curve. An ROC curve. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58163, "question": "Question about ROC Curve", "aSentId": 58166, "answer": "So yes, this has been answered below: the classifier outputs a score, and you are free to choose a threshold, and as you change the threshold you trace the ROC curve in FPR TPR space.\n\nI also wanted to point out another useful interpretation of the area under the ROC curve (AuC): the probability that a randomly chosen negative example will have a smaller score than a randomly chosen positive example. For a random classifier (one that returns a random score for each item), this probability will be 0.5. The ROC corresponding to this classifier is the diagonal line FPR=TPR.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58171, "question": "REINFORCEjs: Reinforcement Learning in Javascript, by Andrej Karpathy", "aSentId": 58172, "answer": "I guess the first question everyone asks: why javascript? What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58173, "question": "I guess the first question everyone asks: why javascript? What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?", "aSentId": 58174, "answer": ":D This project is mostly a result of me trying to refresh on / learn more Reinforcement Learning. The most efficient way of learning something on a sufficiently deep level (that I know of, at least) is to implement all the things, which is how this project came about: I went down Sutton's RL book and a few followup papers on more modern topics, implemented all the most interesting ideas, and then condensed it, cleaned it up, packed it up into a library, briefly explained it, and uploaded it.\n\nI wouldn't look for deep reasons behind the choice of JS. Most of it is just for fun, but if you insist on utility: JS is easy to write, debug in Inspector, it's surprisingly fast, it lets you easily and quickly visualize things, and runs in anyone's browser. I hope that the demos/code can be educational to others (writing it all from scratch certainly was for me), or perhaps even useful/fun to play with for various games/applications. \n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58173, "question": "I guess the first question everyone asks: why javascript? What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?", "aSentId": 58176, "answer": "&gt; What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?\n\nSame use case that justifies all Javascript: you want it to run in a web browser.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58177, "question": "&gt; What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?\n\nSame use case that justifies all Javascript: you want it to run in a web browser.", "aSentId": 58178, "answer": "OK, one step closer, why do you want to run reinforcement learning in the browser - as opposed to having a thin JS client for something running behind a REST interface?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58179, "question": "OK, one step closer, why do you want to run reinforcement learning in the browser - as opposed to having a thin JS client for something running behind a REST interface?", "aSentId": 58180, "answer": "Running it in javascript means you can offload the computation onto the client's computer, but I think the main rationale behind Karpathy's javascript efforts is educational. If it's in javascript, the internals are intentionally exposed to anyone who knows javascript. I think that's actually the main reason.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58177, "question": "&gt; What's the rationale behind this being implemented in js, what are the use-cases that didn't occur to me for which one needs pure js implementation?\n\nSame use case that justifies all Javascript: you want it to run in a web browser.", "aSentId": 58182, "answer": ".. apart from node.js. ;-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58184, "question": "Hierarchical Softmax, why is it faster?", "aSentId": 58185, "answer": "The speed up comes during training. During training you only need to calculate the probability of one word (Assuming CBOW model). You don't need to probability of every single word in your vocabulary. However, when you use the softmax you will need to calculate the activations for every single word. By using hierarchical softmax the training complexity is reduced from O(V) to O(log(V)) where V is the number of words in your vocabulary.\n\nedit:\n\nIt may be clear if you look at the likelihood.\nThe idea is to minimize the negative likelihood,\n\n`-\\sum_{i=0}^{i=|D|} log(P(Y=y^{i}|x^{i}))`.\n\nHere `P(Y=y^i|x^i)` is the probability of the correct word y for example i. You can see it does not depend on the incorrect words for the ith training example. However, if you use softmax you will need to calculate everything anyways.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58186, "question": "The speed up comes during training. During training you only need to calculate the probability of one word (Assuming CBOW model). You don't need to probability of every single word in your vocabulary. However, when you use the softmax you will need to calculate the activations for every single word. By using hierarchical softmax the training complexity is reduced from O(V) to O(log(V)) where V is the number of words in your vocabulary.\n\nedit:\n\nIt may be clear if you look at the likelihood.\nThe idea is to minimize the negative likelihood,\n\n`-\\sum_{i=0}^{i=|D|} log(P(Y=y^{i}|x^{i}))`.\n\nHere `P(Y=y^i|x^i)` is the probability of the correct word y for example i. You can see it does not depend on the incorrect words for the ith training example. However, if you use softmax you will need to calculate everything anyways.", "aSentId": 58187, "answer": "So my mistake is that you don't need to evaluate the error you make on all the words, only the one you are currently evaluating?\nWhat costfunction and derivative of the costfunction do you use then? And how are the 'decision vectors' (at the nodes in the tree) trained?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58184, "question": "Hierarchical Softmax, why is it faster?", "aSentId": 58189, "answer": "Could I piggyback on this post and ask what the best reference is for hierarchical softmax?  I looked at the Mnih and Hinton paper a while ago and remember not finding it very clear. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58191, "question": "What is the best Machine Learning Textbook out there, which has good directions into Deep Learning?", "aSentId": 58192, "answer": "\"Machine Learning: a Probabilistic Perspective\" by Kevin Murphy is absolutely stellar! I found it to be written as well as Bishop's seminal book, but much more relevant and up-to-date", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58193, "question": "\"Machine Learning: a Probabilistic Perspective\" by Kevin Murphy is absolutely stellar! I found it to be written as well as Bishop's seminal book, but much more relevant and up-to-date", "aSentId": 58194, "answer": "I think Murphy is the only one that actually reaches deep learning. However it's quite out of date (according to the author, no less). Still, I think it, Bishop, or the Hastie et al book would all do decently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58195, "question": "I think Murphy is the only one that actually reaches deep learning. However it's quite out of date (according to the author, no less). Still, I think it, Bishop, or the Hastie et al book would all do decently.", "aSentId": 58196, "answer": "Apparently, he is working on a new edition.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58191, "question": "What is the best Machine Learning Textbook out there, which has good directions into Deep Learning?", "aSentId": 58198, "answer": "Deep Learning flows naturally in my opinion once you understand core ideas behind classical (regular) Machine Learning. I recommend Bishop book, because it nicely explains intuition behind each concept.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58199, "question": "Deep Learning flows naturally in my opinion once you understand core ideas behind classical (regular) Machine Learning. I recommend Bishop book, because it nicely explains intuition behind each concept.", "aSentId": 58200, "answer": "Seconded. Coming from a physics background, I found this book easy to follow and rigorous enough to not seem insulting.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58191, "question": "What is the best Machine Learning Textbook out there, which has good directions into Deep Learning?", "aSentId": 58202, "answer": "Yoshua Bengio has free draft available of a new book he and two others are working on. \n\nHowever, If you find a book that is:\n\nintuitive, sufficiently mathematical (not some ones intellectual joy ride into mathematical abstractions and frameworks), not to wordy or jargon filled, has nice even beautiful informative pictures, has working code examples to illustrate concepts (torch, theano, caffe, matlab, R), covers only what works best instead of stuff no one uses that was part of the history of ML and ...\n\nall this in about 50 to 100 pages. \"Do more with less.\"\n\nFor another 100 to 150 pages, give case-study after case-study of strategies of real-world implementation of these techniques. Including hardware from building your own HPC workstation to a small cluster of 8 to 16 servers. \n\nFinally, finish it off by showing how much we do not know. How unlike the brain these techniques are. How poor is our understanding of unsupervised learning. How the techniques used today are basically 20 to 30 years old. How the rush to use this stuff is because of cheap hardware like gpu's and the availablity of lots of data. Add maybe 20 pages.\n\nSo the book should be about 250 pages max.\n\nFind me that and then i would think it is worth buying.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58203, "question": "Yoshua Bengio has free draft available of a new book he and two others are working on. \n\nHowever, If you find a book that is:\n\nintuitive, sufficiently mathematical (not some ones intellectual joy ride into mathematical abstractions and frameworks), not to wordy or jargon filled, has nice even beautiful informative pictures, has working code examples to illustrate concepts (torch, theano, caffe, matlab, R), covers only what works best instead of stuff no one uses that was part of the history of ML and ...\n\nall this in about 50 to 100 pages. \"Do more with less.\"\n\nFor another 100 to 150 pages, give case-study after case-study of strategies of real-world implementation of these techniques. Including hardware from building your own HPC workstation to a small cluster of 8 to 16 servers. \n\nFinally, finish it off by showing how much we do not know. How unlike the brain these techniques are. How poor is our understanding of unsupervised learning. How the techniques used today are basically 20 to 30 years old. How the rush to use this stuff is because of cheap hardware like gpu's and the availablity of lots of data. Add maybe 20 pages.\n\nSo the book should be about 250 pages max.\n\nFind me that and then i would think it is worth buying.", "aSentId": 58204, "answer": "Neat! Thanks", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58206, "question": "I'd strongly recommend Michael Nielsen's excellent free draft e-book entitled \"Neural Networks and Deep Learning\". He is currently releasing isolated chapters at a rate of more or less one at every 3 months. Check it out online at: http://neuralnetworksanddeeplearning.com/", "aSentId": 58207, "answer": "Neat!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58209, "question": "What do you think of the Simon Haykin's? My uni's library has them and I am about to take one", "aSentId": 58210, "answer": "Not a fan. And I know a lot of people aren't either. \nBishop's Neural Networks for Pattern Recognition is better recommended. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58211, "question": "Not a fan. And I know a lot of people aren't either. \nBishop's Neural Networks for Pattern Recognition is better recommended. ", "aSentId": 58212, "answer": "Why? =(", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58213, "question": "Why? =(", "aSentId": 58214, "answer": "a lot of things in that book are written in a really confusing way", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58213, "question": "Why? =(", "aSentId": 58216, "answer": "Bishop has a bigger name", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58218, "question": "anything on neural networks will do, in fact you can start with matlab neural network toolbox tutorial", "aSentId": 58219, "answer": "I started with a Neural Networks course at uCalgary, and have been using the Matlab NN toolbox very often! Thanks", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58221, "question": "Do you guys think starting to research on ML at the last year of an Electrical Engineering undergrad course is too late if I want to make my career on ML?", "aSentId": 58222, "answer": "It is probably too early, not too late. You want to have solid basic understanding of the underlying math/CS concepts. Then you get another 5-6 years in PhD.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58223, "question": "It is probably too early, not too late. You want to have solid basic understanding of the underlying math/CS concepts. Then you get another 5-6 years in PhD.", "aSentId": 58224, "answer": "Didn't expect that! I already do research applying MLP on medical problems (namely ECG and fMRI), I thought I was too late to be interested on that area and should do something else easier haha", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58230, "question": "Bee Algorithm", "aSentId": 58231, "answer": "I hope this is a joke.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58232, "question": "I hope this is a joke.", "aSentId": 58233, "answer": "It's mind numbing how many of these posts came up after a link to the forum was posted on Coursera.  \n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58234, "question": "It's mind numbing how many of these posts came up after a link to the forum was posted on Coursera.  \n\n", "aSentId": 58235, "answer": "it really makes you wonder about MOOCs when Coursera's audience seems to be dumber than 4chan.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58237, "question": "Are there any historically nontechnical companies doing great work in ML?", "aSentId": 58238, "answer": "The New York Times? https://vimeo.com/117882911", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58239, "question": "The New York Times? https://vimeo.com/117882911", "aSentId": 58240, "answer": "Awesome! This is exactly the sort of thing I was curious about.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58237, "question": "Are there any historically nontechnical companies doing great work in ML?", "aSentId": 58242, "answer": "Target's pregnancy scores. There was a New York times article about it 3 years ago.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58237, "question": "Are there any historically nontechnical companies doing great work in ML?", "aSentId": 58244, "answer": "Depends on what you mean by \"great work in ML\"? I'd say no, if you meant \"actively developing new ML algorithms/statistical techniques\". On the other hand, if you mean \"are gathering/have very cool data sets that they can ask/answer interesting questions with\", then definitely yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58246, "question": "What are the current state-of-the-art approaches for information retrieval from text-based product reviews?", "aSentId": 58247, "answer": "Information retrieval is a very separate field from machine learning. Concepts certainly overlap (like document categorization), but when I hear IR I think search, user profiling, document similarity, etc. \n\nMy point is: what are you trying to do?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58248, "question": "Information retrieval is a very separate field from machine learning. Concepts certainly overlap (like document categorization), but when I hear IR I think search, user profiling, document similarity, etc. \n\nMy point is: what are you trying to do?", "aSentId": 58249, "answer": "ok you are correct, although it does say information retrieval in the sidebar, what i meant was information extraction.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58251, "question": "Computing the Mean and Variance of Non Integrable Functions for Expectation Propagation", "aSentId": 58252, "answer": "A good approximation is the unscented transform. It works very well for the expectations, not so good for the variance in many cases. Murphy's book for a good description.\n\nAlternatively, if they quantities are scalars, you might just use a table or a sophisticated polynomial. This might get you very far.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58251, "question": "Computing the Mean and Variance of Non Integrable Functions for Expectation Propagation", "aSentId": 58254, "answer": "What do you mean by p(x) being \"unintegrable\"? Clearly, exp(||d-x||) grows much faster than any quadratic, so your p(x) should have finite mean and variance, since the normal distribution does.\n\nOr, do you mean intractability?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58251, "question": "Computing the Mean and Variance of Non Integrable Functions for Expectation Propagation", "aSentId": 58256, "answer": "Can you draw samples from it?  If so, calculate mean, variance, etc via Monte Carlo.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 58257, "question": "Can you draw samples from it?  If so, calculate mean, variance, etc via Monte Carlo.", "aSentId": 58258, "answer": "yes I can however, I feel like this would take away from the the advantages of using a deterministic inference technique. I think I have resolved to use a different measure of my likelihood function", "corpus": "reddit"}]