[{"docID": "t5_2r3gv", "qSentId": 15613, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 15614, "answer": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15615, "question": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "aSentId": 15616, "answer": "Thanks - I should! I\u2019ve been thinking about this for years. But it\ntakes time, and there are so many other things in the pipeline \u2026", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15613, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 15618, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15619, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 15620, "answer": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15621, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 15622, "answer": "This is very good to hear.  Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15621, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 15624, "answer": "Wow! Thanks for Sacred.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15625, "question": "Wow! Thanks for Sacred.", "aSentId": 15626, "answer": "You are welcome.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15619, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 15628, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15629, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 15630, "answer": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15631, "question": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "aSentId": 15632, "answer": "RNNLIB is provided as source, which you have to compile yourself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15633, "question": "RNNLIB is provided as source, which you have to compile yourself.", "aSentId": 15634, "answer": "RNNLIB is the exception rather than the rule as far as I can tell.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15629, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 15636, "answer": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15637, "question": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "aSentId": 15638, "answer": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15639, "question": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "aSentId": 15640, "answer": "Fair enough. But it also means that there effectively is no (fast) up-to-date library. At least not with LSTM support out of the box.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15613, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 15642, "answer": "What do you think about learning selective attention with recurrent neural networks?  What do you think are the promising methods in this area?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15646, "question": "Do you have a favorite Theory Of Consciousness (TOC)? \n\nWhat do you think of Guilio Tononi's Integrated Information Theory? \n\nWhat implications - if any - do you think \"TOC\" has for AGI?", "aSentId": 15647, "answer": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15648, "question": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "aSentId": 15649, "answer": "Holy fuck\n\nEDIT: \nI mean, as a ML student researcher, Holy fuck.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15655, "question": "How do you recognize a promising machine learning phd student?", "aSentId": 15656, "answer": "I am privileged because I have been able to attract and\nwork with several truly outstanding students. But how to quickly\nrecognize a promising student when you first meet her? There is no recipe,\nbecause they are all different! In fact, sometimes it takes a while to\nrecognize someone\u2019s brilliance. In hindsight, however, they all have\nsomething in common: successful students are not only smart but also\ntenacious. While trying to solve a challenging problem, they run into\na dead end, and backtrack. Another dead end, another backtrack. But\nthey don\u2019t give up. And suddenly there is this little insight into the\nproblem which changes everything. And suddenly they are world experts\nin a particular aspect of the field, and then find it easy to churn\nout one paper after another, and create a great PhD thesis.\n\nAfter these abstract musings, some more concrete advice.  In\ninterviews with applicants, members of my lab tend to pose a few\nlittle problems, to see how the candidate approaches them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15660, "question": "The LSTM unit is delicately crafted to solve a specific problem in training RNNs. Do you see the need for other similarly \"high-complexity\" units in RNNs or CNNs, like for example Hinton's \"capsules\"? On the topic of CNNs and capsules, do you agree with Hinton's assessment that the efficacy of pooling is actually a disaster? (I do, for what it's worth)", "aSentId": 15661, "answer": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15662, "question": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "aSentId": 15663, "answer": "Thank you!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15670, "question": "Hi Dr. Schmidhuber, Thanks for the AMA!\nHow close are you to building the optimal scientist? ", "aSentId": 15671, "answer": "You are welcome! \n\nAbout a stone's throw away :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15673, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 15674, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15675, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 15676, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15677, "question": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "aSentId": 15678, "answer": "As you see, they may have better personal relationships ... that's it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15680, "question": "In what field do you think machine learning will make the biggest impact in the next ~5 years?", "aSentId": 15681, "answer": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15682, "question": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "aSentId": 15683, "answer": "Well, I guess I meant commerical, although not in terms of money, but in terms of it being actually used my masses of people.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15687, "question": "If marcus hutter was doing an AMA 20 years from now, what scientific question would you ask? Are there any machine learning specific questions you would ask?", "aSentId": 15688, "answer": "(Edited on 3/10/2015:) 20 years from now I'll be 72 and enter my midlife crisis. People will forgive me for asking silly questions. I cannot  predict the most important machine learning-specific question of 2035. If I could, I\u2019d probably ask it right now. However, since Marcus is not only a great computer scientist but also a physicist, I\u2019ll ask him: \u201cGiven the new scientific insights of the past 20 years, how long will it take AIs from our solar system to spread across the galaxy?\u201d Of course, a trivial lower bound is 100,000 years or so, which is nothing compared to the age of the galaxy. But that will work out only if someone else has already installed receivers such that (construction plans of) AIs can travel there by radio. Otherwise one must physically send seeds of self-replicating robot factories to the stars, to build the required infrastructure. How? Current proposals involve light sails pushed by lasers, but how to greatly slow down a seed near its target star? One idea: through even faster reflective sails traveling ahead of the seed. But there must be a better way. Let\u2019s hear what Marcus will have to tell us 20 years from now. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15691, "question": "You have postulated that quantum computers will fail because deterministic universe is a simpler hypothesis than a non-deterministic universe. What do you think about the current state of quantum computation?", "aSentId": 15692, "answer": "If you didn't see it, the professor commented on Quantum computing in another question.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15697, "question": "What is the future of PyBrain? Is your team still working with/on PyBrain? If not, what is your framework of choice? What do you think of Theano? Are you using something better?", "aSentId": 15698, "answer": "My PhD students Klaus and Rupesh are working on a successor of PyBrain with many new features, which hopefully will be released later this year.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15700, "question": "What's something exciting you're working on right now, if it's okay to be specific? ", "aSentId": 15701, "answer": "Among other things, we are working on the \u201cRNNAIssance\u201d - \nthe birth of a Recurrent Neural Network-based Artificial Intelligence (RNNAI).\nThis is about a reinforcement learning, RNN-based, increasingly general problem solver.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15703, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 15704, "answer": "I think I recall Hinton giving an answer to this in his MOOC: we like activations, from which derivatives can be computed easily in terms of the function value itself. For sigmoid the derivative is s(x) * (1 - s(x)) for example.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15703, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 15706, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15703, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 15708, "answer": "I suspect activation functions that grow more quickly are harder to control, and likely lead to exploding or vanishing gradients. Although we've managed to handle piecewise linear activations, I'm not sure if quadratic/exponential would work well. In fact, I'd bet that you could improve on ReLu by making the response become logarithmic after a certain point. RBF activations are common though (and have excellent theoretical properties), they just don't seem to learn as well as ReLu. I once trained a neural net with sin/cosine activations (it went OK, nothing special), but in general you can try out any activation function you want. Throw it into Theano and see what happens.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15710, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 15711, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15712, "question": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "aSentId": 15713, "answer": "An exponential activation would have as its derivative... an exponential. Gradient descent would be pretty messy with such a wild dynamic range.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15715, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 15716, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15717, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 15718, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15721, "question": "Just wanted to say I never get tired of your talks... never.. not once.", "aSentId": 15722, "answer": "Thanks so much - I greatly appreciate it. \n\nYou are in good company. A colleague of mine has Alzheimer, and he said the same thing :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15724, "question": "If ASI is a real threat, what can we do now to prevent a catastrophe later?", "aSentId": 15725, "answer": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15726, "question": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "aSentId": 15727, "answer": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15728, "question": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "aSentId": 15729, "answer": "In my experience ASI almost always means artificial superintelligence, which is a term that's often used when discussing safe/friendly AI. The idea is that while AGI might be human level, ASI would be vastly more intelligent. This is usually supposed to be achieved by an exponential process of recursive self-improvement by an AGI that results in an intelligence explosion.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15733, "question": "Does Alex Graves have the weight of the future on his shoulders?", "aSentId": 15734, "answer": "And vice versa!\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15739, "question": "What music do you like to listen to? any particular bands or composers that you ride for?", "aSentId": 15740, "answer": "I feel that in each music genre, there are a few excellent works, and many others. My taste is pretty standard. For example, my favourite rock &amp; pop music act is also the best-selling one (the Beatles). I love certain songs of the Stones, Led Zeppelin, Elvis, S Wonder,  M Jackson, Prince, U2, Supertramp, Pink Floyd, Gr\u00f6nemeyer, Sting, Kraftwerk, M Bianco, P Williams (and many other artists who had a single great song in their entire carreer). IMO the best songs of Queen are as good as anybody\u2019s, with a rare timeless quality. Some of the works indicated above seem written by true geniuses. Some by my favourite composer (Bach) seem dictated by God himself :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15745, "question": "As a researcher do you care if results of your work find practical application? Or research by itself is more than a rewarding exercise. Immagine computational power was not growing at the same a speed as it did then most of results on RNN would stay on the paper.", "aSentId": 15746, "answer": "Kurt Lewin said: \"There is nothing so practical as a good theory.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15750, "question": "Hello Prof. Schmidhuber, thanks for doing an AMA! I have some questions regarding the G\u00f6del machine. My understanding is that the machine searches for an optimal behavioural strategy in arbitrary environments. It does so by finding a proof that an alternative strategy is better than the current one and by rewriting the actual strategy (which may include the strategy searching mechanism). The G\u00f6del machine finds the optimal strategy for a given utility function. \n\n * Is it guaranteed that the strategy searching mechanism actually finds a proof?\n * It is a current trend to find 'optimal' behaviours or organisation in nature. For example minimal jerk trajectories for reaching and pointing movements,  sparse features in vision or optimal resolution in grid cells. Nature found these strategies by trial-and-error. How can we take a utility function as a starting point and decide that it is a 'good' utility function?\n * Could the G\u00f6del machine and AIXI guide neuroscience and ML research as a theoretical framework? \n * Are there plans to find implementations of self-optimizing agents?", "aSentId": 15751, "answer": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15752, "question": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "aSentId": 15753, "answer": "&gt; G\u00f6del machines are limited by the basic limits of math and computation identified by the founder of modern theoretical computer science himself, Kurt G\u00f6del (1931): some theorems are true but cannot be proven by any computational theorem proving procedure (unless the axiomatic system itself is flawed). That is, in some situations the GM may never find a proof of the benefits of some change to its own code.\n\nApart  from undecidable proofs, is there a constructive way to find the proofs? According to the Curry-Howard theorem proofs can be represented as programs and programs as proofs. So what is gained by searching in proof space in contrast to searching in program space? .. Or maybe I'm missing something. I tried to understand G\u00f6del machines for some time now but I'm still not sure how this should work.\n\n&gt; I think so, because they are optimal in theoretical senses that are not practical, and clarify what remains to be done, e.g.: Given a limited constant number of computational instructions per second (a trillion or so), what is the best way of using them to get as close as possible to a model such as AIXI that is optimal in absence of resource constraints?\n\nI think I saw Konrad K\u00f6rding mentioning AIXI in a talk, but unfortunately I could not find the online presentation any more. Just a wild guess that you knew something about this.. \n\n&gt; Yes.\n\nAny chance you could elaborate on this? :) Is something in this direction published?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15758, "question": "I am starting a CS Bachelor this September at ETH. Primarily because I want to get into AI/ML/NN research and creation. It simply is the most important thing there is:D What should i do to be able to join your group in Lugano, what are you looking for in your research assistants? Thanks and cheers", "aSentId": 15759, "answer": "Thanks a lot for your interest! We\u2019d like to see: mathematical\nskills, programming skills, willingness to work with others,\ncreativity, dedication, enthusiasm (you seem to have enough of that :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15766, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 15767, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15768, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 15769, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15770, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 15771, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15773, "question": "What do you think a small research institute (in Germany) can do to improve changes for funding of their projects?", "aSentId": 15774, "answer": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15775, "question": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "aSentId": 15776, "answer": "Thanks for the answer. Up until now, I always was under the impression that institutes would have to produce papers that are recognized as groundbreaking from the first second on. Guess the importance can increase over time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15778, "question": "What is your take on the threat posed by artificial super intelligence to mankind?\n", "aSentId": 15779, "answer": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15780, "question": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "aSentId": 15781, "answer": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15782, "question": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "aSentId": 15783, "answer": "I do understand your concerns. Note, however, that humankind is already used to huge, indifferent powers. A decent earthquake is a thousand times more powerful than all nuclear weapons combined. The sun is slowly heating up, and will make traditional life impossible within a few hundred million years. Humans evolved just in time to think about this, near the end of the 5-billion-year time window for life on earth.\nYour popular but simplistic nanobot scenario actually sounds like a threat to many AIs in the expected future \"ecology\" of AIs. So they'll be at least motivated to prevent that. Currently I am much more worried about certain humans who are relatively powerful but indifferent to the suffering of others. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15789, "question": "Why does a mirror reverse right amd left, but not up and down?\n\n(I dont want the answer a human gives, but how AI explains it!)\n\n/L", "aSentId": 15790, "answer": "An AI would answer that your perception is reversed. The reason left and right appear to be reversed is because your brain models the mirror-you as part of the same world as the real you, and if you went around behind the mirror and faced yourself, you'd need to reverse your left and right to match the perception of the mirror-you. The reason you don't see the up-down reversal is because you're used to travelling horizontally. If you went over the mirror and faced yourself, you'd then have to reverse up and down instead. So it's all in your non-AI head!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15800, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 15801, "answer": "The models in both US and EU are shaped by Humboldt\u2019s old model\nof the research university. But they come in various flavours.\nFor example, there is huge variance in \"the European models\u201d. \nI see certain advantages of the successful US PhD school model \nwhich I got to know better at the University of Colorado at Boulder in the \nearly 1990s. But I feel that less school-like models also have something \ngoing for them. \n\nUS-inspired PhD schools like those at my present Swiss \nuniversity require students to get credits for certain courses. At TU\nMunich (where I come from), however, the attitude was: a PhD student\nis a grown-up who doesn\u2019t go to school any more; it\u2019s his own job to\nacquire the additional education he needs. This is great for strongly\nself-driven persons but may be suboptimal for others. At TUM, my wonderful\nadvisor, Wilfried Brauer, gave me total freedom in my research. I loved\nit, but it seems kind of out of fashion now in some places. \n\nThe extreme \nvariant is what I like to call the \u201cEinstein model.\u201d Einstein never went to \ngrad school. He worked at the patent office, and at some point he submitted a\nthesis to Univ. Zurich. That was it. Ah, maybe I shouldn\u2019t admit\nthat this is my favorite model. And now I am also realizing that I have not really \nanswered your question in any meaningful way - sorry for that!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15800, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 15803, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15804, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 15805, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15800, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 15807, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15808, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 15809, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15810, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 15811, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15808, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 15813, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15814, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 15815, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15817, "question": "What do you think about using ontologies / semantic information (DBPedia, Wikidata) as a substrate / mould for ANNs to generate more versatile networks?", "aSentId": 15818, "answer": "Sounds like a great idea! Perhaps relevant:  Ilya Sutskever &amp; Oriol Vinyals &amp; Quoc V. Le use LSTM recurrent neural networks to access semantic information for English-to-French translation, with great success: http://arxiv.org/abs/1409.3215. And Oriol Vinyals &amp; Lukasz Kaiser &amp; Terry Koo &amp; Slav Petrov &amp; Ilya Sutskever &amp; Geoffrey Hinton use LSTM to\nread a sentence, and decode it into a flattened tree. They achieve excellent constituency parsing results: http://arxiv.org/abs/1412.7449", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15820, "question": "(in relation to the Atari paper and partly on your statement about it)\n\nWhat do you personally think about using a diverse selection of video games as a learning problem / \"dataset\"?\n\nOne thing I found interesting about the DeepMind Nature paper is that they could not solve Montezuma's Revenge at all (the game, not the travel problem), which is an action-adventure game requiring some kind of real-world knowledge / thinking - and temporal planning, of course. As any Atari game, conceptually it is still rather simple.\n\nI wonder what would happen if we found an AI succeeding over a wide range of complex game concepts like e.g. Alpha Centauri / Civilization, SimCity, Monkey Island II (for humorous puns, such as \"monkey wrench\"), put it into a robot and unleash it on the real world.", "aSentId": 15821, "answer": "&gt; in relation to the Atari paper and partly on your statement about it\n\nCan you point me to his statement about it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15827, "question": "Two questions, if I may:\n\n1. With Moore's law gradually coming to an end, it would seem that we won't be achieving anything even close to General AI on today's hardware, at least not economically. As a researcher at the forefront of the field, are you aware of any hardware \"game changers\" that may simplify training and execution of extremely large neural networks that may be capable of intelligence?\n\n2. What are some of the most exciting papers that you have read (or written) in the past year?", "aSentId": 15828, "answer": "&gt; With Moore's law gradually coming to an end\n\nSource? GPUs have just picked up the Moore torch and is now carrying the field. Ive seen no reason why this won't continue for 1 or 2 more cycles before something new  like graphene will be in production.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15831, "question": "What advice do you have for a BTech computer science student passionate about strong AI hoping to join your team at IDSIA someday?", "aSentId": 15832, "answer": "Read our papers, re-implement one of our systems, perhaps improve it a bit, or better a lot, or do something else that I was not able to think of because it\u2019s too original!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15838, "question": "Where did you get the joke about the three prisoners? ", "aSentId": 15839, "answer": "You mean the one that starts: \"Three prisoners walk into a bar ...\"? :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15845, "question": "What is the algorithm of love?\n", "aSentId": 15846, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15845, "question": "What is the algorithm of love?\n", "aSentId": 15848, "answer": "Great question!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15845, "question": "What is the algorithm of love?\n", "aSentId": 15850, "answer": "In response to the foolish comment: I am not a chinaman, but you are a racist village idiot.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15852, "question": "A long time ago, someone once misattributed '64k ought to be enough for anyone'.\n\nWhat general statement or suggestion about strong generalized a.i. could be looked at in a similar way a decade or two from now?\n\nThanks, I look forward to reading your ama.", "aSentId": 15853, "answer": "\"64 yottabytes ought to be enough for anyone.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15865, "question": "Do you think having a PhD is important if one wants to work in a good research team?", "aSentId": 15866, "answer": "Not at all - my PhD students are doing excellent work, but don't have a PhD :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15868, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 15869, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15871, "question": "i understand that neural networks and deep learning are computationally intensive for non-trivial problems. In addition, many experiments are necessary to see what works and what does not. What sort of equipment do you recommend for doing research in this area without breaking the bank? ", "aSentId": 15872, "answer": "As long as your applications are not too ambitious, a desktop machine with one or more GPUs should do!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15882, "question": "What do you think of Bitcoin. ", "aSentId": 15883, "answer": "I thought more of it when I had more of it.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15885, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 15886, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15891, "question": "Crib notes on decision trees and forests w/ discussion on their efficient implementation.", "aSentId": 15892, "answer": "Mostly just typical notes on trees here -- I thought posting it could be helpful for folks like me who learned machine learning first through Ng's class, which doesn't cover the topic.  One thing included here not in most texts:  discussion on efficient greedy construction implementations, which turned out to actually be pretty challenging/fun/rewarding to think through.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15893, "question": "Mostly just typical notes on trees here -- I thought posting it could be helpful for folks like me who learned machine learning first through Ng's class, which doesn't cover the topic.  One thing included here not in most texts:  discussion on efficient greedy construction implementations, which turned out to actually be pretty challenging/fun/rewarding to think through.", "aSentId": 15894, "answer": "So presorting all of the features actually isn't that necessary and efficient implementations that sort on the fly can actually be much faster in many/most cases especially on highly dimensional data (scikit learn and my [CloudForest](https://github.com/ryanbressler/CloudForest) implementation sort on the fly, I believe R's randomForest package presorts).\n\nThere are a few reasons this is true:\n\n1) The number of features evaluated at each node is usually the square root of the total number of features. Only the root nodes sorts the whole dataset, child nodes always sort a small fraction of it.\n\n2) Impurity (in all of the features) tends to decrease as one travels down the tree and introsort can be really fast (O(n)) sorting things that are mostly constant...fast implementations also track when a feature has become constant to avoid resorting it.\n\n3) Sorting a single feature can be done in a cpu cache friendly way even if the whole data set doesn't fit in cache which makes it much much faster.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15895, "question": "So presorting all of the features actually isn't that necessary and efficient implementations that sort on the fly can actually be much faster in many/most cases especially on highly dimensional data (scikit learn and my [CloudForest](https://github.com/ryanbressler/CloudForest) implementation sort on the fly, I believe R's randomForest package presorts).\n\nThere are a few reasons this is true:\n\n1) The number of features evaluated at each node is usually the square root of the total number of features. Only the root nodes sorts the whole dataset, child nodes always sort a small fraction of it.\n\n2) Impurity (in all of the features) tends to decrease as one travels down the tree and introsort can be really fast (O(n)) sorting things that are mostly constant...fast implementations also track when a feature has become constant to avoid resorting it.\n\n3) Sorting a single feature can be done in a cpu cache friendly way even if the whole data set doesn't fit in cache which makes it much much faster.", "aSentId": 15896, "answer": "Very interesting.  Thank you for the response...  Your point 2 makes a lot of sense in the context of classification.  \n\nBTW, I read in section 1.8.4 [here](http://scikit-learn.org/stable/modules/tree.html) that sklearn does do a presort.  I wonder if this is an old implementation's documentation, or if this is only done for regression.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15897, "question": "Very interesting.  Thank you for the response...  Your point 2 makes a lot of sense in the context of classification.  \n\nBTW, I read in section 1.8.4 [here](http://scikit-learn.org/stable/modules/tree.html) that sklearn does do a presort.  I wonder if this is an old implementation's documentation, or if this is only done for regression.", "aSentId": 15898, "answer": "They don't. That documentation is either old or refers to presorting each feature within the node split search, not the whole data set. One of the authors has an [excellent thesis](https://github.com/glouppe/phd-thesis) that describes lots of the trades offs (search for \"sorting\" or \"presorting\") and has a ton of benchmarks.\n\nI believe the regression and classification code are largely the same, just with different impurities/criteria.\n\nAlso for point 2 it isn't the impurity of the target that decreases or becomes constant, it is the impurity/entropy of the features to be sorted (ie similar cases end up on similar nodes).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15899, "question": "They don't. That documentation is either old or refers to presorting each feature within the node split search, not the whole data set. One of the authors has an [excellent thesis](https://github.com/glouppe/phd-thesis) that describes lots of the trades offs (search for \"sorting\" or \"presorting\") and has a ton of benchmarks.\n\nI believe the regression and classification code are largely the same, just with different impurities/criteria.\n\nAlso for point 2 it isn't the impurity of the target that decreases or becomes constant, it is the impurity/entropy of the features to be sorted (ie similar cases end up on similar nodes).", "aSentId": 15900, "answer": "Thesis looks cool.  Wish I had its chapter five when I was writing this up...\n\n&gt; Also for point 2 it isn't the impurity of the target that decreases or becomes constant, it is the impurity/entropy of the features to be sorted (ie similar cases end up on similar nodes).\n\nyes!  got confused there for a moment.  thanks again!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15902, "question": "Google's Response to Facebooks Deepface", "aSentId": 15903, "answer": "&gt;On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%\n\nThat is both awesome and terrifying.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15902, "question": "Google's Response to Facebooks Deepface", "aSentId": 15905, "answer": "Could this be used as binary classifier? If there is no face in the picture proposed Euclidean embedding will be way off, correct? \n\nNow imagine training similar models for dogs, cats, flamingos etc. At the end we should get a system with close to 100% object classification/detection. And it would be easily extensible(just add new models for new classes) and highly parallel. Or am I wrong?\n\nPS. 99.63% - now that is truly outperforming humans on LFW! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15902, "question": "Google's Response to Facebooks Deepface", "aSentId": 15907, "answer": "&gt; \"A proprietary face detector (similar to Picasa [3]) is run\non the provided LFW thumbnails\"\n\nAnd without that, performance is only half.   Could it be the alignment that is the key to the challenge here, not the actual recognition bit being hard?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15908, "question": "&gt; \"A proprietary face detector (similar to Picasa [3]) is run\non the provided LFW thumbnails\"\n\nAnd without that, performance is only half.   Could it be the alignment that is the key to the challenge here, not the actual recognition bit being hard?", "aSentId": 15909, "answer": "It said that the only alignment is for scale and translation (i.e. picking a bounding box), whereas the usual alignment includes rotating the image.  \n\nI'm not surprised that the performance degraded without running a face detector and doing scale alignment before hand.  Convnets are actually quite invariant with respect to scale (i.e. they basically can only handle scale invariance by reproducing filters at multiple scales at every layer).  \n\nAttentional mechanisms that allow for selecting the scale of the attentive window provide scale invariance.  Deep Symmetry Networks also claim to have this property, but I'm unconvinced by the experimental results in the paper.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15916, "question": "Advice to graduate students interviewing for industry positions (x-post /r/datascience)", "aSentId": 15917, "answer": "Carl is a great data scientist, and this a good advise but I would take it with a grain of salt. However, I would re-frame the blog-post in two scenarios. Most of big firms who interview data scientists or graduates would make the interviews goes on two stages, recruiters who are looking for soft and tranforeabale skills, they are usually making sure that you fit in the culture of their organization, whether you are motivated and eager data scientist or no; Then the technical interviews are done by future colleagues, developers or data scientists, they don't really care about how good you are in selling your self, but it's their job during these 30 mins to analyze the analyzer; I have been interviewed by someone who didn't even say hi. \n\nIt's too risk-y to over-sell yourself, because some developers got exhausted of people who claim to be business-savvies, people who pretend to wear double hats (business and other things .. ). Just to talk like human, explain an idea as you explain it to a child, don't go deep unless you are asked to go that path, don't fake it until you make it, just be yourself ;) \n\nP.S: This is based on my humbled experience, someone who is still failing in his interviews several times. Just take this advise with a grain of salt ;)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15920, "question": "Neural Graphics Engine", "aSentId": 15921, "answer": "Just saw a talk by Dr. Tenenbaum on this work a few weeks ago in Houston. Really interesting stuff!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15924, "question": "Get the intuition behind regularization in ML", "aSentId": 15925, "answer": "If you think \"Bayesian\", regularization is related to the prior on parameters.\n\nNamely, the whole Machine Learning is concerned with inference, that is to come up with distribution `p(w | X)` where `w` is your model's parameter (could be scalar, vector, matrix, etc), and `X` is the data. This is where Bayes' rule is applied:\n\np(w | X) = p (X | w) p (w) / p(X)\n\nOkay, but often we don't need an actual distribution on `w`, all we need is one concrete (preferable the best one, whatever it means) value. We could take mean of that distribution, but that's hard in general (because of denominator). But wait, we have probabilities given data! We can pick the most probable value of `w` given our observations. And, the denominator is not a problem anymore \u2014 it's just a constant w.r.t. `w`.\n\nSo the (pointwise) inference becomes `p(X | w) p(w) \u2192 max`. It's not quite simple to optimize products directly, so we usually take log of product to turn it into sums, and multiply by -1 to change maximization to minimizatio: `-log p(X | w) - log p(w) \u2192 min`. Voila! This is what is called a loss.\n\nIndeed, if you take standard Gaussian distribution as the prior `p(w)`, `-log p(w)` turns exactly into L2 loss (with a multiplicative constant). This prior reflects our prior beliefs about parameters. And usually we believe that parameters are \"sane\" in a sense that they don't vary too much / not so big / etc. Gaussian distribution has most of its probability mass concentrated within 3-4 standard deviations, so big values will be heavily penalized.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15924, "question": "Get the intuition behind regularization in ML", "aSentId": 15927, "answer": "My intuition is that you first assume that your observations are a combination of \"signal\" and \"noise\".  The model which has the best training error will fit both the signal and the noise and will generalize poorly.  \n\nWe use L2 regularization because we assume that the signal and the noise both have properties that make L2 regularized models much worse at fitting the noise and only slightly worse at fitting the signal.  If you assume the noise is independent across instances, then lowering the complexity of the model makes it harder for it to fit the noise.  \n\nL2 is just one way of encouraging the weights to be small, which reduces the complexity of the model.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15924, "question": "Get the intuition behind regularization in ML", "aSentId": 15929, "answer": "L2 regularization is the sum of the square of the components. Consider adding some unit of value to the model. Taking the two extremes you can concentrate that value in one parameter or you can distribute it evenly among all parameters. In an L1 regularization scheme these two approaches result in identical cost to the model. But in L2 the model is penalized more as the value is concentrated in fewer parameters. \n\nThis can be seen as simplifying the model by imagining a polynomial approximation. The more concentrated/lopsided the distribution of the values of the components of the model, more polynomial terms and of higher degree are necessary to approximate that model. Consider the difference between a straight line vs a parabola vs a wildly oscillating function. The latter will need many terms with many different polynomial degree to reproduce it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15933, "question": "LINE: toolkit for embedding large-scale information networks (w/ code and paper)", "aSentId": 15934, "answer": "Paper: http://arxiv.org/abs/1503.03578\n\nThe notion here is very similar to that of DeepWalk, the LINE authors on that topic:\n&gt;  Although empirically effective, the DeepWalk\ndoes not provide a clear objective that articulates what network\nproperties are preserved. Intuitively, DeepWalk expects\nnodes with higher second-order proximity yield similar\nlow-dimensional representations, while the LINE preserves\nboth first-order and second-order proximities. DeepWalk\nuses random walks to expand the neighborhood of a vertex,\nwhich is analogical to a depth-first search. We use a breadth-\nfirst search strategy, which is a more reasonable approach to\nthe second-order proximity. Practically, DeepWalk only applies\nto unweighted networks, while our model is applicable\nfor networks with both weighted and unweighted edges.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15935, "question": "Paper: http://arxiv.org/abs/1503.03578\n\nThe notion here is very similar to that of DeepWalk, the LINE authors on that topic:\n&gt;  Although empirically effective, the DeepWalk\ndoes not provide a clear objective that articulates what network\nproperties are preserved. Intuitively, DeepWalk expects\nnodes with higher second-order proximity yield similar\nlow-dimensional representations, while the LINE preserves\nboth first-order and second-order proximities. DeepWalk\nuses random walks to expand the neighborhood of a vertex,\nwhich is analogical to a depth-first search. We use a breadth-\nfirst search strategy, which is a more reasonable approach to\nthe second-order proximity. Practically, DeepWalk only applies\nto unweighted networks, while our model is applicable\nfor networks with both weighted and unweighted edges.", "aSentId": 15936, "answer": "I don't have any preference for either DeepWalk or LINE but the paper makes some technical claims that seem incorrect.\n\n1. Both DeepWalk and LINE have equally black-box objectives, as they rely on word2vec type minimization. I'm pretty confused why the authors think concatenating two embeddings from the first and second-order embeddings are a reasonable thing to do. At least DeepWalk can be written as a matrix factorization of the random-walk marginal.\n\n2. I was excited to see that the abstract linked embedding to structure preservation, but the objective has very little to do with real network structure preservation such as in structure preserving embedding (shaw / jebara ICML 2009). It's just another word2vec variant which is already ill-understood.\n\n3. DeepWalk should trivially apply to directed networks since you can apply word2vec on the directed simple random walk. The claim that it 'only applies to unweighted networks' seems very disingenuous when the modification to make deepwalk directed is trivial.\n\n4. DeepWalk seems higher order than second-order neighborhoods, as if you use word2vec of size -t- then you have at least t-th order similarity incorporated into the objective.\n\nIt is nice that this algorithm can use weighted edges, and that it also scales. It does seem though that you could modify deepwalk to use weights by doing random-walk according to edge weights.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15937, "question": "I don't have any preference for either DeepWalk or LINE but the paper makes some technical claims that seem incorrect.\n\n1. Both DeepWalk and LINE have equally black-box objectives, as they rely on word2vec type minimization. I'm pretty confused why the authors think concatenating two embeddings from the first and second-order embeddings are a reasonable thing to do. At least DeepWalk can be written as a matrix factorization of the random-walk marginal.\n\n2. I was excited to see that the abstract linked embedding to structure preservation, but the objective has very little to do with real network structure preservation such as in structure preserving embedding (shaw / jebara ICML 2009). It's just another word2vec variant which is already ill-understood.\n\n3. DeepWalk should trivially apply to directed networks since you can apply word2vec on the directed simple random walk. The claim that it 'only applies to unweighted networks' seems very disingenuous when the modification to make deepwalk directed is trivial.\n\n4. DeepWalk seems higher order than second-order neighborhoods, as if you use word2vec of size -t- then you have at least t-th order similarity incorporated into the objective.\n\nIt is nice that this algorithm can use weighted edges, and that it also scales. It does seem though that you could modify deepwalk to use weights by doing random-walk according to edge weights.", "aSentId": 15938, "answer": "Valid points all, but I think there is at least some justification for this stuff however informal. Regarding your points:\n\n1. The concatenation operation seems to be a \"this seems to work\" kind of thing at the moment. Though they do say \"A more principled way to combine the two proximity is to jointly train the objective function (3) and (6), which we leave as future work.\"\n2. I see what you're saying, but I think Levy and Goldberg have clarified word2vec sufficiently that the term \"ill-understood\" may be an overstatement.\n3. I completely agree on this, DeepWalk can support that trivially. In fact, I've implemented it myself and it works well for my use case. Implementing DeepWalk is very simple and you're free to generate random walks however you'd like.\n4. Completely agree.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15939, "question": "Valid points all, but I think there is at least some justification for this stuff however informal. Regarding your points:\n\n1. The concatenation operation seems to be a \"this seems to work\" kind of thing at the moment. Though they do say \"A more principled way to combine the two proximity is to jointly train the objective function (3) and (6), which we leave as future work.\"\n2. I see what you're saying, but I think Levy and Goldberg have clarified word2vec sufficiently that the term \"ill-understood\" may be an overstatement.\n3. I completely agree on this, DeepWalk can support that trivially. In fact, I've implemented it myself and it works well for my use case. Implementing DeepWalk is very simple and you're free to generate random walks however you'd like.\n4. Completely agree.", "aSentId": 15940, "answer": "Levy and Goldberg is a reasonable explanation for word embeddings assuming the ratio of word/context probabilities are approximately equal, but I'm very much skeptical this is true for networks. Applying word2vec to networks and understanding it requires more work.\n\nOverall, it seems like they unfairly put down deepwalk, when theoretically it seems deepwalk is cleaner than this LINE formulation.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15942, "question": "Lecture on Sequence Generation by Alex Graves", "aSentId": 15943, "answer": "One of the most interesting things he talks about (besides the awesome demos) is using neural networks to parameterize probability distributions.\n\nThis has been around a long time, but has recently showed back up in the variational autoencoder. It is also interesting to see the fine-grained control of sampling by adding or removing bias to the mixture distribution's variance.\n\nIf you want to hear neural networks talk, skip to ~38:00. Some really impressive though currently unpublished work.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15942, "question": "Lecture on Sequence Generation by Alex Graves", "aSentId": 15945, "answer": "Thanks for posting!\nI particularly enjoyed the rambling speech generation demo.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15948, "question": "Trying to see the differences between 'nolearn' and 'theano' python packages for DNN.", "aSentId": 15949, "answer": "I hadn't heard of nolearn before you mentioned it.  \n\nhttps://github.com/dnouri/nolearn\n\nApparently it's a wrapper around different neural net libraries, including caffe and lasagna.  Lasagna is a wrapper around Theano.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15950, "question": "I hadn't heard of nolearn before you mentioned it.  \n\nhttps://github.com/dnouri/nolearn\n\nApparently it's a wrapper around different neural net libraries, including caffe and lasagna.  Lasagna is a wrapper around Theano.  ", "aSentId": 15951, "answer": "Thanks", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15948, "question": "Trying to see the differences between 'nolearn' and 'theano' python packages for DNN.", "aSentId": 15953, "answer": "I don't know much about nolearn but I feel like theano is much more flexible in what you can acheive, whereas nolearn comes with all algorithms prepackaged (for theano the equivalent is pylearn2).\n\nSo if you're a newbie _both_ in programming and machine learning, maybe nolearn would be better (but again I never tried it), otherwise I would suggest using theano.\n\ntheano isn't strictly a neural net library, although it's primary usage seems to be just that, in the sense that it lets you define your own architectures at the vector/matrix computation level, rather than at the bit more abstract \"neural net\" level (which in my opinion is an advantage but might make it harder to learn/work with).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15955, "question": "Linear Classifiers for CUDA and OpenCL using ArrayFire", "aSentId": 15956, "answer": "Wow, never heard of arrayfire before! Looks very interesting.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15960, "question": "is this a correct implementation of averaged perceptron?", "aSentId": 15961, "answer": "&gt;Basically after every iteration I save that weight. the algorithm runs until it hits the maximum iterations threshold, and then the final weights that I used is the average of every weight I saw during the course of running the algorithm. is that right?  \n\nYes. It seems to work just fine starting from T=1...N in most settings. Just accumulate the weights you learn over time in an array, then divide by N.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15962, "question": "&gt;Basically after every iteration I save that weight. the algorithm runs until it hits the maximum iterations threshold, and then the final weights that I used is the average of every weight I saw during the course of running the algorithm. is that right?  \n\nYes. It seems to work just fine starting from T=1...N in most settings. Just accumulate the weights you learn over time in an array, then divide by N.", "aSentId": 15963, "answer": "thank you", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15965, "question": "Text2SDR", "aSentId": 15966, "answer": "I'm not following. Could you please ELI5?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15967, "question": "I'm not following. Could you please ELI5?", "aSentId": 15968, "answer": "It's a way of assigning features vectors to words, and then finding a set of sparse features for \"unlimited\" amounts of text by combining these word features using a predictive system.\n\nBasically:\nText -&gt; Features (specifically, sparse distributed representations)\n\nThe system can (and has been) used to predict what people write ahead of time based on previous writings. It can also be used classify sentences.\n\nI'm not very good at explaining :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15969, "question": "It's a way of assigning features vectors to words, and then finding a set of sparse features for \"unlimited\" amounts of text by combining these word features using a predictive system.\n\nBasically:\nText -&gt; Features (specifically, sparse distributed representations)\n\nThe system can (and has been) used to predict what people write ahead of time based on previous writings. It can also be used classify sentences.\n\nI'm not very good at explaining :)", "aSentId": 15970, "answer": "Ah, I think I understand. Similar to the way Swype keyboard tries to predict what word you're going to say next?\n\n&gt;It can also be used classify sentences.\n\nClassify in what way?\n\nInteresting - thanks for sharing.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15971, "question": "Ah, I think I understand. Similar to the way Swype keyboard tries to predict what word you're going to say next?\n\n&gt;It can also be used classify sentences.\n\nClassify in what way?\n\nInteresting - thanks for sharing.", "aSentId": 15972, "answer": "Since the system uses something called temporal pooling to build memories (a HTM term), it forms SDRs that have information not only from the current word but also all necessary contextual information for predicting the next word. So, if you run the system through a sentence, and then get its current SDR, that SDR will represent a feature for the entire sentence. These SDRs can the be fed into standard classifiers to do stuff like spam detection, sentiment analysis, automatic summarization, and subject organization. It can also be used for recommender systems, if you recommend text with a similar SDR to what was just presented.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15969, "question": "It's a way of assigning features vectors to words, and then finding a set of sparse features for \"unlimited\" amounts of text by combining these word features using a predictive system.\n\nBasically:\nText -&gt; Features (specifically, sparse distributed representations)\n\nThe system can (and has been) used to predict what people write ahead of time based on previous writings. It can also be used classify sentences.\n\nI'm not very good at explaining :)", "aSentId": 15974, "answer": "So basically it's a distributed representations language model. Have you compared it to the plethora of benchmarks, like Mnih and Hinton's log-bilinear language model, or RNNs?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15965, "question": "Text2SDR", "aSentId": 15976, "answer": "So you don't update the word vectors after it initially assigns it one? That seems to miss the point of word2vec.\n\nI'm not familiar with HTM. How do you update the parameters of the model? How does it learn long term dependencies between words?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15977, "question": "So you don't update the word vectors after it initially assigns it one? That seems to miss the point of word2vec.\n\nI'm not familiar with HTM. How do you update the parameters of the model? How does it learn long term dependencies between words?", "aSentId": 15978, "answer": "In the current model it doesn't update word vectors, but rather assigns new vectors so that words in similar situations in a sentence are given similar vectors. It is possible to also update the word vectors towards the predictions slowly, but I didn't find this necessary.\n\nI am not actually using HTM itself, but a derivative of it called HTFERL. It is essentially a predictive sparse recurrent autoencoder that can be stacked. It uses recurrent connections to form memories. These connections are used in a SDR bootstrapping scheme (temporal pooling) to group similar events together.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15965, "question": "Text2SDR", "aSentId": 15980, "answer": "The idea of using the hidden layer of a recurrent net as a sentence representation is not new. Recently, Sutskever et al. (NIPS 2014) did this for neural MT, but the idea has been explored before. Using the hidden layer as initial vector for an unknown word at test time is basically Weston et al's heuristic (see Memory Networks paper). Doing it at training time is a weak heuristic, and is unlikely to have an effect on all but the smallest of datasets. You are probably better off doing hapax legomenon smoothing by assigning the words in the long tail of the zipfian distribution to a single vector. Finally why do you even want to use reinforcement learning here? Just use minimising negative log likelihood of the data as your supervised objective.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15981, "question": "The idea of using the hidden layer of a recurrent net as a sentence representation is not new. Recently, Sutskever et al. (NIPS 2014) did this for neural MT, but the idea has been explored before. Using the hidden layer as initial vector for an unknown word at test time is basically Weston et al's heuristic (see Memory Networks paper). Doing it at training time is a weak heuristic, and is unlikely to have an effect on all but the smallest of datasets. You are probably better off doing hapax legomenon smoothing by assigning the words in the long tail of the zipfian distribution to a single vector. Finally why do you even want to use reinforcement learning here? Just use minimising negative log likelihood of the data as your supervised objective.", "aSentId": 15982, "answer": "It isn't using reinforcement learning, it is simply based on the network of the reinforcement learner that I use.\n\n&gt; Using the hidden layer as initial vector for an unknown word at test time is basically Weston et al's heuristic (see Memory Networks paper).\n\nYou misunderstand. The hidden representation isn't used as the word vectors, the prediction is.\n\nThe \"new thing\" is how the system performs temporal pooling (borrowed from my reinforcement learner). Perhaps this was done before, but if so I don't know who did it. It's sort of like an echo state network where SDRs for temporal events are grouped together efficiently. It can remember very large sequences with as little as 2 to 5 iterations (with very high learning rates). I have tested a sequence of 512 numbers, and it remembered it with 90% accuracy after 5 iterations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15983, "question": "It isn't using reinforcement learning, it is simply based on the network of the reinforcement learner that I use.\n\n&gt; Using the hidden layer as initial vector for an unknown word at test time is basically Weston et al's heuristic (see Memory Networks paper).\n\nYou misunderstand. The hidden representation isn't used as the word vectors, the prediction is.\n\nThe \"new thing\" is how the system performs temporal pooling (borrowed from my reinforcement learner). Perhaps this was done before, but if so I don't know who did it. It's sort of like an echo state network where SDRs for temporal events are grouped together efficiently. It can remember very large sequences with as little as 2 to 5 iterations (with very high learning rates). I have tested a sequence of 512 numbers, and it remembered it with 90% accuracy after 5 iterations.", "aSentId": 15984, "answer": "Yeah the output (prediction vector) at t is a transformation of the hidden layer at time t, and where there is an unattested token at test time you take the prediction vector to be the word's representation for future use. See Jason Weston's memory networks paper. If you do this at training time, it's not going to do much more than random initialisation, unless you plan on doing a single pass through the data.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15983, "question": "It isn't using reinforcement learning, it is simply based on the network of the reinforcement learner that I use.\n\n&gt; Using the hidden layer as initial vector for an unknown word at test time is basically Weston et al's heuristic (see Memory Networks paper).\n\nYou misunderstand. The hidden representation isn't used as the word vectors, the prediction is.\n\nThe \"new thing\" is how the system performs temporal pooling (borrowed from my reinforcement learner). Perhaps this was done before, but if so I don't know who did it. It's sort of like an echo state network where SDRs for temporal events are grouped together efficiently. It can remember very large sequences with as little as 2 to 5 iterations (with very high learning rates). I have tested a sequence of 512 numbers, and it remembered it with 90% accuracy after 5 iterations.", "aSentId": 15986, "answer": "Would have to see the maths of your temporal pooling to comment, but there's been work on pooling for shallow (and deep) temporal convolutions for sequences (esp. for language) at several points in the last 15 years. Cf Collobert and Weston, Kalchbrenner et al, etc.\n\nAside from that, most of your work sounds like a slightly over complicated approach to language modelling. It's cool that you're exploring this fascination topic, but I'd recommend that you start with simpler stuff and add on complexity, evaluating against some good standard benchmarks along the way.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15988, "question": "fEMG?", "aSentId": 15989, "answer": "In principle, sure; why not?  This sounds like an empirical question though. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15990, "question": "In principle, sure; why not?  This sounds like an empirical question though. ", "aSentId": 15991, "answer": "Just making sure I'm not on the path to a dead-end because of my lack of expertise. Let the research begin!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15988, "question": "fEMG?", "aSentId": 15993, "answer": "If you strictly mean facial EMG then face movements have been shown to be correlated with the envelope of the speech being produced. Both in terms of the motion signal and in terms of the psychophysical benefit to a listener. But psychophysically there also seems to be a benefit derived in terms of articulatory cues that would extend beyond acoustic envelope information. This information will show up as fast dynamic contractions that /u/Vorsorken mentioned and as he said, will be harder to extract. The envelope is generally pretty robust to extract in an audio signal, so I doubt that will buy you much...however if you try to frame it as robust speech recognition in noise, you might have something from the EMG signal. Good luck.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15995, "question": "Create artificial dataset for binary classification?", "aSentId": 15996, "answer": "Well, you could always make a random matrix X, which would be Dimensions x Examples size, make a random vector W of Dimensions x 1 size, and get labels Y for multiplying them together, possibly adding some kind of noise to Y. Not sure what spark is but it's the classic function fitting f(X) =X*W ~= Y problem, and you can repeat the steps to create however many examples you'd like, at any dimension - with a little trickery.\n\nThe task is to reproduce W, which you already know and so can benchmark easily.\n\nMaybe make f(X) = logsig(X*W) for outputs between 0 and 1.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15995, "question": "Create artificial dataset for binary classification?", "aSentId": 15998, "answer": "You could download lots of random tweets for one keyword and download a random set of tweets for another keyword, and then do classification.  \n\nThe downside is that you'll need to wait a while to download everything, or you'll need to pick an existing source.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 15995, "question": "Create artificial dataset for binary classification?", "aSentId": 16000, "answer": "use the blogger dataset from here: https://github.com/IndicoDataSolutions/Passage/tree/master/examples", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16002, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 16003, "answer": "What area are you in, are you willing to relocate, and what are your specialties? I might be able to provide a real interview depending on answers ;)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16002, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 16005, "answer": "So did you find any takers? How did it go?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16006, "question": "So did you find any takers? How did it go?", "aSentId": 16007, "answer": "I found one taker and it was great! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16006, "question": "So did you find any takers? How did it go?", "aSentId": 16009, "answer": "I haven't found anyone (or exchanged contacts yet) to do an ML interview, but my friend did a fake Comp Sci interview which was pretty good. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16006, "question": "So did you find any takers? How did it go?", "aSentId": 16011, "answer": "If you're allowed, I'd like that contact info so I can find something similar. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16012, "question": "If you're allowed, I'd like that contact info so I can find something similar. ", "aSentId": 16013, "answer": "I can interview you if you like. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16002, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 16015, "answer": "The ML interviews I've had are *all over the place*.  \n\nSome are really obscure questions about MRFs. Some about general ML system building strategies. Some just want me to talk about my work the whole time. Some random ML trivia-esque questions.  \n\nJust try, try again. Eventually you'll trick someone into giving you a job. I've basically stopped studying for interviews because they're so random.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16016, "question": "The ML interviews I've had are *all over the place*.  \n\nSome are really obscure questions about MRFs. Some about general ML system building strategies. Some just want me to talk about my work the whole time. Some random ML trivia-esque questions.  \n\nJust try, try again. Eventually you'll trick someone into giving you a job. I've basically stopped studying for interviews because they're so random.", "aSentId": 16017, "answer": "I just went through the data science interview process myself with a number of companies -- took a number before finally landing a position.  I agree, lots of variation between companies.  However, one common thread through them all: Basic statistics, including AB testing!!! ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16018, "question": "I just went through the data science interview process myself with a number of companies -- took a number before finally landing a position.  I agree, lots of variation between companies.  However, one common thread through them all: Basic statistics, including AB testing!!! ", "aSentId": 16019, "answer": "Good to know!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16016, "question": "The ML interviews I've had are *all over the place*.  \n\nSome are really obscure questions about MRFs. Some about general ML system building strategies. Some just want me to talk about my work the whole time. Some random ML trivia-esque questions.  \n\nJust try, try again. Eventually you'll trick someone into giving you a job. I've basically stopped studying for interviews because they're so random.", "aSentId": 16021, "answer": "I guess they are no more *all over the place* than any computer science interview, but it still helps to get some of the interview anxiety out of the way and actually develop focusing on the problem. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16016, "question": "The ML interviews I've had are *all over the place*.  \n\nSome are really obscure questions about MRFs. Some about general ML system building strategies. Some just want me to talk about my work the whole time. Some random ML trivia-esque questions.  \n\nJust try, try again. Eventually you'll trick someone into giving you a job. I've basically stopped studying for interviews because they're so random.", "aSentId": 16023, "answer": "Correct advice, but more importantly, great username. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 16026, "question": "I am up-voting this thread for you curiosity and commitment to learn and sharpen ur interviewing skills. Best of Luck ;) ", "aSentId": 16027, "answer": "I'll second this. ", "corpus": "reddit"}]
