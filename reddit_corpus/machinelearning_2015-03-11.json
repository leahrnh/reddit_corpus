[{"docID": "t5_2r3gv", "qSentId": 45643, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 45644, "answer": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45645, "question": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "aSentId": 45646, "answer": "Thanks - I should! I\u2019ve been thinking about this for years. But it\ntakes time, and there are so many other things in the pipeline \u2026", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45643, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 45648, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45649, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 45650, "answer": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45651, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 45652, "answer": "This is very good to hear.  Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45651, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/qwlouse/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.", "aSentId": 45654, "answer": "Wow! Thanks for Sacred.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45655, "question": "Wow! Thanks for Sacred.", "aSentId": 45656, "answer": "You are welcome.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45649, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 45658, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45659, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 45660, "answer": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45661, "question": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "aSentId": 45662, "answer": "RNNLIB is provided as source, which you have to compile yourself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45663, "question": "RNNLIB is provided as source, which you have to compile yourself.", "aSentId": 45664, "answer": "RNNLIB is the exception rather than the rule as far as I can tell.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45659, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 45666, "answer": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45667, "question": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "aSentId": 45668, "answer": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45669, "question": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "aSentId": 45670, "answer": "Fair enough. But it also means that there effectively is no (fast) up-to-date library. At least not with LSTM support out of the box.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45643, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 45672, "answer": "What do you think about learning selective attention with recurrent neural networks?  What do you think are the promising methods in this area?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45676, "question": "Do you have a favorite Theory Of Consciousness (TOC)? \n\nWhat do you think of Guilio Tononi's Integrated Information Theory? \n\nWhat implications - if any - do you think \"TOC\" has for AGI?", "aSentId": 45677, "answer": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45683, "question": "How do you recognize a promising machine learning phd student?", "aSentId": 45684, "answer": "I am privileged because I have been able to attract and\nwork with several truly outstanding students. But how to quickly\nrecognize a promising student when you first meet her? There is no recipe,\nbecause they are all different! In fact, sometimes it takes a while to\nrecognize someone\u2019s brilliance. In hindsight, however, they all have\nsomething in common: successful students are not only smart but also\ntenacious. While trying to solve a challenging problem, they run into\na dead end, and backtrack. Another dead end, another backtrack. But\nthey don\u2019t give up. And suddenly there is this little insight into the\nproblem which changes everything. And suddenly they are world experts\nin a particular aspect of the field, and then find it easy to churn\nout one paper after another, and create a great PhD thesis.\n\nAfter these abstract musings, some more concrete advice.  In\ninterviews with applicants, members of my lab tend to pose a few\nlittle problems, to see how the candidate approaches them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45688, "question": "The LSTM unit is delicately crafted to solve a specific problem in training RNNs. Do you see the need for other similarly \"high-complexity\" units in RNNs or CNNs, like for example Hinton's \"capsules\"? On the topic of CNNs and capsules, do you agree with Hinton's assessment that the efficacy of pooling is actually a disaster? (I do, for what it's worth)", "aSentId": 45689, "answer": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45690, "question": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "aSentId": 45691, "answer": "Thank you!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45696, "question": "Hi Dr. Schmidhuber, Thanks for the AMA!\nHow close are you to building the optimal scientist? ", "aSentId": 45697, "answer": "You are welcome! \n\nAbout a stone's throw away :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45700, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 45701, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45702, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 45703, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45704, "question": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "aSentId": 45705, "answer": "As you see, they may have better personal relationships ... that's it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45707, "question": "In what field do you think machine learning will make the biggest impact in the next ~5 years?", "aSentId": 45708, "answer": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45709, "question": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "aSentId": 45710, "answer": "Well, I guess I meant commerical, although not in terms of money, but in terms of it being actually used my masses of people.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45714, "question": "If marcus hutter was doing an AMA 20 years from now, what scientific question would you ask? Are there any machine learning specific questions you would ask?", "aSentId": 45715, "answer": "(Edited on 3/10/2015:) 20 years from now I'll be 72 and enter my midlife crisis. People will forgive me for asking silly questions. I cannot  predict the most important machine learning-specific question of 2035. If I could, I\u2019d probably ask it right now. However, since Marcus is not only a great computer scientist but also a physicist, I\u2019ll ask him: \u201cGiven the new scientific insights of the past 20 years, how long will it take AIs from our solar system to spread across the galaxy?\u201d Of course, a trivial lower bound is 100,000 years or so, which is nothing compared to the age of the galaxy. But that will work out only if someone else has already installed receivers such that (construction plans of) AIs can travel there by radio. Otherwise one must physically send seeds of self-replicating robot factories to the stars, to build the required infrastructure. How? Current proposals involve light sails pushed by lasers, but how to greatly slow down a seed near its target star? One idea: through even faster reflective sails traveling ahead of the seed. But there must be a better way. Let\u2019s hear what Marcus will have to tell us 20 years from now. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45718, "question": "You have postulated that quantum computers will fail because deterministic universe is a simpler hypothesis than a non-deterministic universe. What do you think about the current state of quantum computation?", "aSentId": 45719, "answer": "If you didn't see it, the professor commented on Quantum computing in another question.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45724, "question": "What is the future of PyBrain? Is your team still working with/on PyBrain? If not, what is your framework of choice? What do you think of Theano? Are you using something better?", "aSentId": 45725, "answer": "My PhD students Klaus and Rupesh are working on a successor of PyBrain with many new features, which hopefully will be released later this year.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45727, "question": "What's something exciting you're working on right now, if it's okay to be specific? ", "aSentId": 45728, "answer": "Among other things, we are working on the \u201cRNNAIssance\u201d - \nthe birth of a Recurrent Neural Network-based Artificial Intelligence (RNNAI).\nThis is about a reinforcement learning, RNN-based, increasingly general problem solver.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45730, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 45731, "answer": "I think I recall Hinton giving an answer to this in his MOOC: we like activations, from which derivatives can be computed easily in terms of the function value itself. For sigmoid the derivative is s(x) * (1 - s(x)) for example.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45730, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 45733, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45730, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 45735, "answer": "I suspect activation functions that grow more quickly are harder to control, and likely lead to exploding or vanishing gradients. Although we've managed to handle piecewise linear activations, I'm not sure if quadratic/exponential would work well. In fact, I'd bet that you could improve on ReLu by making the response become logarithmic after a certain point. RBF activations are common though (and have excellent theoretical properties), they just don't seem to learn as well as ReLu. I once trained a neural net with sin/cosine activations (it went OK, nothing special), but in general you can try out any activation function you want. Throw it into Theano and see what happens.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45737, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 45738, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45739, "question": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "aSentId": 45740, "answer": "An exponential activation would have as its derivative... an exponential. Gradient descent would be pretty messy with such a wild dynamic range.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45742, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 45743, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45744, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 45745, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45748, "question": "Just wanted to say I never get tired of your talks... never.. not once.", "aSentId": 45749, "answer": "Thanks so much - I greatly appreciate it. \n\nYou are in good company. A colleague of mine has Alzheimer, and he said the same thing :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45751, "question": "If ASI is a real threat, what can we do now to prevent a catastrophe later?", "aSentId": 45752, "answer": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45753, "question": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "aSentId": 45754, "answer": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45755, "question": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "aSentId": 45756, "answer": "In my experience ASI almost always means artificial superintelligence, which is a term that's often used when discussing safe/friendly AI. The idea is that while AGI might be human level, ASI would be vastly more intelligent. This is usually supposed to be achieved by an exponential process of recursive self-improvement by an AGI that results in an intelligence explosion.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45760, "question": "Does Alex Graves have the weight of the future on his shoulders?", "aSentId": 45761, "answer": "And vice versa!\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45766, "question": "What music do you like to listen to? any particular bands or composers that you ride for?", "aSentId": 45767, "answer": "I feel that in each music genre, there are a few excellent works, and many others. My taste is pretty standard. For example, my favourite rock &amp; pop music act is also the best-selling one (the Beatles). I love certain songs of the Stones, Led Zeppelin, Elvis, S Wonder,  M Jackson, Prince, U2, Supertramp, Pink Floyd, Gr\u00f6nemeyer, Sting, Kraftwerk, M Bianco, P Williams (and many other artists who had a single great song in their entire carreer). IMO the best songs of Queen are as good as anybody\u2019s, with a rare timeless quality. Some of the works indicated above seem written by true geniuses. Some by my favourite composer (Bach) seem dictated by God himself :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45772, "question": "As a researcher do you care if results of your work find practical application? Or research by itself is more than a rewarding exercise. Immagine computational power was not growing at the same a speed as it did then most of results on RNN would stay on the paper.", "aSentId": 45773, "answer": "Kurt Lewin said: \"There is nothing so practical as a good theory.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45775, "question": "Hello Prof. Schmidhuber, thanks for doing an AMA! I have some questions regarding the G\u00f6del machine. My understanding is that the machine searches for an optimal behavioural strategy in arbitrary environments. It does so by finding a proof that an alternative strategy is better than the current one and by rewriting the actual strategy (which may include the strategy searching mechanism). The G\u00f6del machine finds the optimal strategy for a given utility function. \n\n * Is it guaranteed that the strategy searching mechanism actually finds a proof?\n * It is a current trend to find 'optimal' behaviours or organisation in nature. For example minimal jerk trajectories for reaching and pointing movements,  sparse features in vision or optimal resolution in grid cells. Nature found these strategies by trial-and-error. How can we take a utility function as a starting point and decide that it is a 'good' utility function?\n * Could the G\u00f6del machine and AIXI guide neuroscience and ML research as a theoretical framework? \n * Are there plans to find implementations of self-optimizing agents?", "aSentId": 45776, "answer": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45777, "question": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "aSentId": 45778, "answer": "&gt; G\u00f6del machines are limited by the basic limits of math and computation identified by the founder of modern theoretical computer science himself, Kurt G\u00f6del (1931): some theorems are true but cannot be proven by any computational theorem proving procedure (unless the axiomatic system itself is flawed). That is, in some situations the GM may never find a proof of the benefits of some change to its own code.\n\nApart  from undecidable proofs, is there a constructive way to find the proofs? According to the Curry-Howard theorem proofs can be represented as programs and programs as proofs. So what is gained by searching in proof space in contrast to searching in program space? .. Or maybe I'm missing something. I tried to understand G\u00f6del machines for some time now but I'm still not sure how this should work.\n\n&gt; I think so, because they are optimal in theoretical senses that are not practical, and clarify what remains to be done, e.g.: Given a limited constant number of computational instructions per second (a trillion or so), what is the best way of using them to get as close as possible to a model such as AIXI that is optimal in absence of resource constraints?\n\nI think I saw Konrad K\u00f6rding mentioning AIXI in a talk, but unfortunately I could not find the online presentation any more. Just a wild guess that you knew something about this.. \n\n&gt; Yes.\n\nAny chance you could elaborate on this? :) Is something in this direction published?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45783, "question": "I am starting a CS Bachelor this September at ETH. Primarily because I want to get into AI/ML/NN research and creation. It simply is the most important thing there is:D What should i do to be able to join your group in Lugano, what are you looking for in your research assistants? Thanks and cheers", "aSentId": 45784, "answer": "Thanks a lot for your interest! We\u2019d like to see: mathematical\nskills, programming skills, willingness to work with others,\ncreativity, dedication, enthusiasm (you seem to have enough of that :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45790, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 45791, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45792, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 45793, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45794, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 45795, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45797, "question": "What do you think a small research institute (in Germany) can do to improve changes for funding of their projects?", "aSentId": 45798, "answer": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45799, "question": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "aSentId": 45800, "answer": "Thanks for the answer. Up until now, I always was under the impression that institutes would have to produce papers that are recognized as groundbreaking from the first second on. Guess the importance can increase over time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45802, "question": "What is your take on the threat posed by artificial super intelligence to mankind?\n", "aSentId": 45803, "answer": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45804, "question": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "aSentId": 45805, "answer": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45811, "question": "Why does a mirror reverse right amd left, but not up and down?\n\n(I dont want the answer a human gives, but how AI explains it!)\n\n/L", "aSentId": 45812, "answer": "An AI would answer that your perception is reversed. The reason left and right appear to be reversed is because your brain models the mirror-you as part of the same world as the real you, and if you went around behind the mirror and faced yourself, you'd need to reverse your left and right to match the perception of the mirror-you. The reason you don't see the up-down reversal is because you're used to travelling horizontally. If you went over the mirror and faced yourself, you'd then have to reverse up and down instead. So it's all in your non-AI head!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45825, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 45826, "answer": "The models in both US and EU are shaped by Humboldt\u2019s old model\nof the research university. But they come in various flavours.\nFor example, there is huge variance in \"the European models\u201d. \nI see certain advantages of the successful US PhD school model \nwhich I got to know better at the University of Colorado at Boulder in the \nearly 1990s. But I feel that less school-like models also have something \ngoing for them. \n\nUS-inspired PhD schools like those at my present Swiss \nuniversity require students to get credits for certain courses. At TU\nMunich (where I come from), however, the attitude was: a PhD student\nis a grown-up who doesn\u2019t go to school any more; it\u2019s his own job to\nacquire the additional education he needs. This is great for strongly\nself-driven persons but may be suboptimal for others. At TUM, my wonderful\nadvisor, Wilfried Brauer, gave me total freedom in my research. I loved\nit, but it seems kind of out of fashion now in some places. \n\nThe extreme \nvariant is what I like to call the \u201cEinstein model.\u201d Einstein never went to \ngrad school. He worked at the patent office, and at some point he submitted a\nthesis to Univ. Zurich. That was it. Ah, maybe I shouldn\u2019t admit\nthat this is my favorite model. And now I am also realizing that I have not really \nanswered your question in any meaningful way - sorry for that!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45825, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 45828, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45829, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 45830, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45825, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 45832, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45833, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 45834, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45835, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 45836, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45833, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 45838, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45839, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 45840, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45842, "question": "What do you think about using ontologies / semantic information (DBPedia, Wikidata) as a substrate / mould for ANNs to generate more versatile networks?", "aSentId": 45843, "answer": "Sounds like a great idea! Perhaps relevant:  Ilya Sutskever &amp; Oriol Vinyals &amp; Quoc V. Le use LSTM recurrent neural networks to access semantic information for English-to-French translation, with great success: http://arxiv.org/abs/1409.3215. And Oriol Vinyals &amp; Lukasz Kaiser &amp; Terry Koo &amp; Slav Petrov &amp; Ilya Sutskever &amp; Geoffrey Hinton use LSTM to\nread a sentence, and decode it into a flattened tree. They achieve excellent constituency parsing results: http://arxiv.org/abs/1412.7449", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45845, "question": "(in relation to the Atari paper and partly on your statement about it)\n\nWhat do you personally think about using a diverse selection of video games as a learning problem / \"dataset\"?\n\nOne thing I found interesting about the DeepMind Nature paper is that they could not solve Montezuma's Revenge at all (the game, not the travel problem), which is an action-adventure game requiring some kind of real-world knowledge / thinking - and temporal planning, of course. As any Atari game, conceptually it is still rather simple.\n\nI wonder what would happen if we found an AI succeeding over a wide range of complex game concepts like e.g. Alpha Centauri / Civilization, SimCity, Monkey Island II (for humorous puns, such as \"monkey wrench\"), put it into a robot and unleash it on the real world.", "aSentId": 45846, "answer": "&gt; in relation to the Atari paper and partly on your statement about it\n\nCan you point me to his statement about it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45853, "question": "Two questions, if I may:\n\n1. With Moore's law gradually coming to an end, it would seem that we won't be achieving anything even close to General AI on today's hardware, at least not economically. As a researcher at the forefront of the field, are you aware of any hardware \"game changers\" that may simplify training and execution of extremely large neural networks that may be capable of intelligence?\n\n2. What are some of the most exciting papers that you have read (or written) in the past year?", "aSentId": 45854, "answer": "&gt; With Moore's law gradually coming to an end\n\nSource? GPUs have just picked up the Moore torch and is now carrying the field. Ive seen no reason why this won't continue for 1 or 2 more cycles before something new  like graphene will be in production.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45857, "question": "What advice do you have for a BTech computer science student passionate about strong AI hoping to join your team at IDSIA someday?", "aSentId": 45858, "answer": "Read our papers, re-implement one of our systems, perhaps improve it a bit, or better a lot, or do something else that I was not able to think of because it\u2019s too original!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45864, "question": "Where did you get the joke about the three prisoners? ", "aSentId": 45865, "answer": "You mean the one that starts: \"Three prisoners walk into a bar ...\"? :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45871, "question": "What is the algorithm of love?\n", "aSentId": 45872, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45871, "question": "What is the algorithm of love?\n", "aSentId": 45874, "answer": "Great question!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45871, "question": "What is the algorithm of love?\n", "aSentId": 45876, "answer": "In response to the foolish comment: I am not a chinaman, but you are a racist village idiot.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45878, "question": "A long time ago, someone once misattributed '64k ought to be enough for anyone'.\n\nWhat general statement or suggestion about strong generalized a.i. could be looked at in a similar way a decade or two from now?\n\nThanks, I look forward to reading your ama.", "aSentId": 45879, "answer": "\"64 yottabytes ought to be enough for anyone.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45891, "question": "Do you think having a PhD is important if one wants to work in a good research team?", "aSentId": 45892, "answer": "Not at all - my PhD students are doing excellent work, but don't have a PhD :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45894, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 45895, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45897, "question": "i understand that neural networks and deep learning are computationally intensive for non-trivial problems. In addition, many experiments are necessary to see what works and what does not. What sort of equipment do you recommend for doing research in this area without breaking the bank? ", "aSentId": 45898, "answer": "As long as your applications are not too ambitious, a desktop machine with one or more GPUs should do!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45908, "question": "What do you think of Bitcoin. ", "aSentId": 45909, "answer": "I thought more of it when I had more of it.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45911, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 45912, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45916, "question": "A Word is Worth a Thousand Vectors", "aSentId": 45917, "answer": "Very cool idea. Are there any other operations besides addition and subtraction that make any sort of intuitive sense? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45916, "question": "A Word is Worth a Thousand Vectors", "aSentId": 45919, "answer": "This is awesome. I plan to incorporate this into a python bot I wrote. Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45916, "question": "A Word is Worth a Thousand Vectors", "aSentId": 45921, "answer": "leaving the PMI matrix factorization formulation until the final point under Further Reading is kind of a weird choice isn't it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45922, "question": "leaving the PMI matrix factorization formulation until the final point under Further Reading is kind of a weird choice isn't it?", "aSentId": 45923, "answer": "The point was to make it practical for industry &amp; engineers. The footnotes are more academic. The beautiful link between the streaming hierarchical softmax and the matrix-factorization PMI formulation definitely counts as academic :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45927, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 45928, "answer": "So did you find any takers? How did it go?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45927, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 45930, "answer": "What area are you in, are you willing to relocate, and what are your specialties? I might be able to provide a real interview depending on answers ;)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45927, "question": "Would anyone be interested in giving me a fake ML interview over Skype today (in 1-5 hours from when this post was created)?", "aSentId": 45932, "answer": "I am up-voting this thread for you curiosity and commitment to learn and sharpen ur interviewing skills. Best of Luck ;) ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45933, "question": "I am up-voting this thread for you curiosity and commitment to learn and sharpen ur interviewing skills. Best of Luck ;) ", "aSentId": 45934, "answer": "I'll second this. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45936, "question": "Beginner's Guide to Machine Learning: Part 1 of 2", "aSentId": 45937, "answer": ":|", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45936, "question": "Beginner's Guide to Machine Learning: Part 1 of 2", "aSentId": 45939, "answer": "The \"guide\" really didn't touch on much. Though, I suppose it did some prefacing. I would have thought that some talk about how data is usually formatted(from a conceptual p.o.v.), or something to that extent would have at least made it into the first part. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45942, "question": "HIPS/autograd : Computes derivatives of complicated numpy code (used in the hypergradient paper)", "aSentId": 45943, "answer": "The approach they're taking (where they pass in a work-alike object and record operations done on it) is pretty clever, though it seems somewhat limited.\n\nFor example, they mention being able to differentiate through control flow but I don't really see how they'd do that easily for most if-else blocks, since their tape recording of the original function's operation wouldn't only see what happened on the branch that it actually followed (and if the condition the numerical output of computations done on the parameter with respect to which you were doing the differentiation, it seems like this wouldn't work at all).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45944, "question": "The approach they're taking (where they pass in a work-alike object and record operations done on it) is pretty clever, though it seems somewhat limited.\n\nFor example, they mention being able to differentiate through control flow but I don't really see how they'd do that easily for most if-else blocks, since their tape recording of the original function's operation wouldn't only see what happened on the branch that it actually followed (and if the condition the numerical output of computations done on the parameter with respect to which you were doing the differentiation, it seems like this wouldn't work at all).", "aSentId": 45945, "answer": "It looks like they evaluate the function (and record a new tape) for each gradient computation.  If you write \n\n    g = grad(f)\n    dx1 = g(x)\n\nthen they compute `f(x)` and record a new tape each time `g(x)` is called.  Even if `f` has control flow, the gradient of `f(x)` only depends on the path actually taken when evaluating `f` at `x` so their tape (and therefore the gradient) is correct each time.\n\nPresumably this would still be fooled by a function like\n\n    def f(x):\n        if x == 3:\n            return 3\n        else:\n            return x\n\nBut if you're in the fairly common scenario of not caring too much about the precise values of your floats then this is unlikely to be a problem in practice.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45946, "question": "It looks like they evaluate the function (and record a new tape) for each gradient computation.  If you write \n\n    g = grad(f)\n    dx1 = g(x)\n\nthen they compute `f(x)` and record a new tape each time `g(x)` is called.  Even if `f` has control flow, the gradient of `f(x)` only depends on the path actually taken when evaluating `f` at `x` so their tape (and therefore the gradient) is correct each time.\n\nPresumably this would still be fooled by a function like\n\n    def f(x):\n        if x == 3:\n            return 3\n        else:\n            return x\n\nBut if you're in the fairly common scenario of not caring too much about the precise values of your floats then this is unlikely to be a problem in practice.", "aSentId": 45947, "answer": "Aha, I hadn't realized from my original skim that they were running f once per call of grad(f). That makes a lot more sense.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45942, "question": "HIPS/autograd : Computes derivatives of complicated numpy code (used in the hypergradient paper)", "aSentId": 45949, "answer": "What's the difference to calculating ordinary numerical derivatives?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45950, "question": "What's the difference to calculating ordinary numerical derivatives?", "aSentId": 45951, "answer": "Numerical derivatives don't scale well to high dimensional spaces.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45950, "question": "What's the difference to calculating ordinary numerical derivatives?", "aSentId": 45953, "answer": "Its exact to machine precision.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45957, "question": "Are you interested in a Weekly Discussions about ML/DS/Data in this ML-subreddit", "aSentId": 45958, "answer": " &gt; share their knowledge, discuss the trending technologies in the industry of data science, the great papers that they read recently, or the greatest open source that have been created\n\nAhem, isn't it what we're doing here? Like, the whole subreddit seems to be designed for it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45959, "question": " &gt; share their knowledge, discuss the trending technologies in the industry of data science, the great papers that they read recently, or the greatest open source that have been created\n\nAhem, isn't it what we're doing here? Like, the whole subreddit seems to be designed for it.", "aSentId": 45960, "answer": "Yes we do!  But we do that asynchronously :p  don't belittle his point-of-view, there are many people doing the same kind of discussions on twitter ;) I see what he is referring to. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45965, "question": "The Curse of Dimensionality and the Autoencoder", "aSentId": 45966, "answer": "&gt; Autoencoders are an extremely exciting new approach to unsupervised learning\n\nAuto-Encoders are a very old technique that has been known and used in the neural network world for ages. The new thing that Hinton came up with is to stack them. But the idea of Auto-Encoders/Auto-Associators is decades old.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45967, "question": "&gt; Autoencoders are an extremely exciting new approach to unsupervised learning\n\nAuto-Encoders are a very old technique that has been known and used in the neural network world for ages. The new thing that Hinton came up with is to stack them. But the idea of Auto-Encoders/Auto-Associators is decades old.", "aSentId": 45968, "answer": "I'm guessing stacking them wasn't a new idea either, just the method to efficiently find parameters for them.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45969, "question": "I'm guessing stacking them wasn't a new idea either, just the method to efficiently find parameters for them.  ", "aSentId": 45970, "answer": "1) You have an amazing username.\n2) It is your cake day.\n3) You are right.\n\nWish I could give you 3 upvotes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45971, "question": "1) You have an amazing username.\n2) It is your cake day.\n3) You are right.\n\nWish I could give you 3 upvotes.", "aSentId": 45972, "answer": "thank you kind sir", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45967, "question": "&gt; Autoencoders are an extremely exciting new approach to unsupervised learning\n\nAuto-Encoders are a very old technique that has been known and used in the neural network world for ages. The new thing that Hinton came up with is to stack them. But the idea of Auto-Encoders/Auto-Associators is decades old.", "aSentId": 45974, "answer": "Wasn't it Bengio stacking them and Hinton stacking RBMs?\n\nNot that it matters much...", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45965, "question": "The Curse of Dimensionality and the Autoencoder", "aSentId": 45976, "answer": "well written. Kudos ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45978, "question": "Regressors keep converging towards median value", "aSentId": 45979, "answer": "Have you tuned the regularization parameter(s) (for example, usually it is called \"C\" or \"nu\" in SVM)? You may be making the regularization so strong, that the weights are shrunk towards zero (check it) and you end up only fitting the intercept.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45982, "question": "SINGA: A Distributed Deep Learning Platform", "aSentId": 45983, "answer": "Some of the language on the page is admittedly a bit advanced for me. What would I need to provide to the API to use this in a project? Could I just provide inputs and a performance metric and let it loose?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45985, "question": "Neural Responding Machine for Short-Text Conversation", "aSentId": 45986, "answer": "Interesting paper. They combine 2 recently proposed approaches: attention mechanism and encoder-decoder architecture. Since both would not likely to effectively train jointly, they train models separately and then finetune final combined model.\n\nAnd such a nice task, where BLEU/perplexity scores could not be applied. So they had to resort to human evaluation. \n\nAnd net would need to learn a lot to do good on a task, things like time reasoning, deduction/induction and huge part of common knowledge. It really surprising that their model did so well at test time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45987, "question": "Interesting paper. They combine 2 recently proposed approaches: attention mechanism and encoder-decoder architecture. Since both would not likely to effectively train jointly, they train models separately and then finetune final combined model.\n\nAnd such a nice task, where BLEU/perplexity scores could not be applied. So they had to resort to human evaluation. \n\nAnd net would need to learn a lot to do good on a task, things like time reasoning, deduction/induction and huge part of common knowledge. It really surprising that their model did so well at test time.", "aSentId": 45988, "answer": "Why would you expect them not to be able to train jointly? There is a paper \"Jointly Learning To Align and Translate\" by [Bahdanau, Cho, and Bengio](http://arxiv.org/abs/1409.0473) that does exactly this. Also, I disagree that human evaluation is necessary. The whole point of BLEU is that it correlates well with human perception, but I do agree that is a poor metric in general. But it seems fishy to not use any metrics that are common in the literature.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45989, "question": "Why would you expect them not to be able to train jointly? There is a paper \"Jointly Learning To Align and Translate\" by [Bahdanau, Cho, and Bengio](http://arxiv.org/abs/1409.0473) that does exactly this. Also, I disagree that human evaluation is necessary. The whole point of BLEU is that it correlates well with human perception, but I do agree that is a poor metric in general. But it seems fishy to not use any metrics that are common in the literature.", "aSentId": 45990, "answer": "Hmm, have you read the paper? \n\nResponses to Twitter posts(and whatever Chinese equivalent) could be anything. So differently worded responses from different perspectives could make total sense even if they share 0% of words. So BLEU would give 0 while evaluating responses that make 100% sense but give A LOT to retrieval methods responses even if content makes no sense from human perspective.\n\nAs for models not to be able to train jointly, let me quote the paper:\n\n&gt;More specifically, the last hidden state of NRM-glo plays a role different from that of the last state of NRM-loc, since it has the responsibility to encode the entire input sentence. **This role of NRM-glo, however, tends to be not adequately emphasized in training the hybrid encoder when the parameters of the two encoding RNNs are learned jointly from scratch.** For this we use the following trick: we first initialize NRM-hyb with the parameters of NRM-loc and NRM-glo trained separately, then fine tune the parameters in encoder along with training the parameters of decoder\n\n*Bolding is mine emphasizing. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45989, "question": "Why would you expect them not to be able to train jointly? There is a paper \"Jointly Learning To Align and Translate\" by [Bahdanau, Cho, and Bengio](http://arxiv.org/abs/1409.0473) that does exactly this. Also, I disagree that human evaluation is necessary. The whole point of BLEU is that it correlates well with human perception, but I do agree that is a poor metric in general. But it seems fishy to not use any metrics that are common in the literature.", "aSentId": 45992, "answer": "As for Bahdanau, Cho, Bengio paper, I might have worded mine OP poorly. Yes, encoder decoder paradigm was implemented multiple times with different variations of a la Graves 2013 Sequence to sequence paper attention tricks. But it is kinda different to what Huawei proposed. Mine post(OP) was not meant to give totally accurate understanding as to what was actually novel/proposed(paper was written for a reason I guess). I might could have done better job writing OP but combining \n\n1. encoding-decoding model without attention\n\n2. encoding-decoding model with attention\n\nseems to be novel and seems to produce quite a sizable gains. That is on top of quite an interesting choice of task (way more interesting than image to natural language description IMHO).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45996, "question": "correct implementation of Hinge loss minimization for gradient descent", "aSentId": 45997, "answer": "I'd start with writing some really simple test cases especially for your helper functions. Functions don't look crazy but bugs are subtle usually.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 45998, "question": "I'd start with writing some really simple test cases especially for your helper functions. Functions don't look crazy but bugs are subtle usually.", "aSentId": 45999, "answer": "would you please suggest some simple tests? when you say functions don't look crazy, I guess your talking about the ones I have written there, isn't it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46000, "question": "would you please suggest some simple tests? when you say functions don't look crazy, I guess your talking about the ones I have written there, isn't it?", "aSentId": 46001, "answer": "Yeah. What I mean is run these functions through some obvious input/output pairs, see if things look right first before throwing a real dataset at it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46003, "question": "How to learn invariances when the training set doesn't have all possible invariances as examples?", "aSentId": 46004, "answer": "I guess you cannot learn what is not there. In unsupervised learning you would have not enough examples. In supervised learning if you know what an L is you can generate noise on the existing examples up to a certain degree or generate more data by applying the operations you consider invariant to your data.\n\nI guess the main problem is that an algorithm can't make up what your are thinking of when you mean invariant.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46005, "question": "I guess you cannot learn what is not there. In unsupervised learning you would have not enough examples. In supervised learning if you know what an L is you can generate noise on the existing examples up to a certain degree or generate more data by applying the operations you consider invariant to your data.\n\nI guess the main problem is that an algorithm can't make up what your are thinking of when you mean invariant.", "aSentId": 46006, "answer": "&gt; ...or generate more data by applying the operations you consider invariant to your data.\n\nAKA data augmentation, which can work wonderfully in the right situation. The trouble being that the practitioner needs to identify which transformations are acceptable to perform on the data.\n\nAlthough, if you're doing cross validation, you should be able to try augmenting your data set with different transformations, and judge the performance of each augmented data set based on it's CV score. As long as your CV set it large enough, accounting for the additional size of the augmented data.\n\nMore likely, I'm falling into a bad line of reasoning. :)\n\nSo, correct me if I'm wrong (this goes for anyone, I like to be wrong -&gt; update beliefs), but wouldn't this make the space of transformations on the dataset another hyperparameter to optimize? (i.e. if working with images, compare rotations of various distributions to translations of varying (x,y) values, based on their CV performance.)\n\nNevermind the question, how would the choice of CV score influence that result?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46003, "question": "How to learn invariances when the training set doesn't have all possible invariances as examples?", "aSentId": 46008, "answer": "This will be a little more general reply. Invariances are defined by numerical representations of your data. When you say 3x3 grid, and you generate 9-length binary vector, then you have already lost the 1 positions with respect to each other. Therefore you should first talk about the numerical representations (feature extraction process) before classification.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46013, "question": "Distilling knowledge in Neural Nets, by Geoffery Hinton, Vinyals and Jeff Dean", "aSentId": 46014, "answer": "Link to the abstract\n\nhttp://arxiv.org/abs/1503.02531", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46013, "question": "Distilling knowledge in Neural Nets, by Geoffery Hinton, Vinyals and Jeff Dean", "aSentId": 46016, "answer": "In the past Hinton has referred to the knowledge stored in the ratios of very small probabilities as Dark Knowledge. I wonder why he threw away that term.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46017, "question": "In the past Hinton has referred to the knowledge stored in the ratios of very small probabilities as Dark Knowledge. I wonder why he threw away that term.", "aSentId": 46018, "answer": "He didn't want people to realize the source of his power. ;)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46019, "question": "He didn't want people to realize the source of his power. ;)", "aSentId": 46020, "answer": "Being the great-great-grandson of George Boole probably contributes to the source of his power as well. Super interesting guy.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46017, "question": "In the past Hinton has referred to the knowledge stored in the ratios of very small probabilities as Dark Knowledge. I wonder why he threw away that term.", "aSentId": 46022, "answer": "It isn't really the sort of thing you use in an academic manuscript. \"Dark knowledge\" is a term he started using in talks about it; when you're not dealing with double blind review and you're a revered elder god of the field, you can afford to take more liberty with titles.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46023, "question": "It isn't really the sort of thing you use in an academic manuscript. \"Dark knowledge\" is a term he started using in talks about it; when you're not dealing with double blind review and you're a revered elder god of the field, you can afford to take more liberty with titles.", "aSentId": 46024, "answer": "Time to dub doing that \"pulling a Schaul\", as Tom got \"No more pesky learning rates\" into ICML. :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46023, "question": "It isn't really the sort of thing you use in an academic manuscript. \"Dark knowledge\" is a term he started using in talks about it; when you're not dealing with double blind review and you're a revered elder god of the field, you can afford to take more liberty with titles.", "aSentId": 46026, "answer": "Are we talking science here or is this a personality cult?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46027, "question": "Are we talking science here or is this a personality cult?", "aSentId": 46028, "answer": "Is there a difference?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46017, "question": "In the past Hinton has referred to the knowledge stored in the ratios of very small probabilities as Dark Knowledge. I wonder why he threw away that term.", "aSentId": 46030, "answer": "\"Dark Knowledge\" is a typical Hinton-ism - the guy likes colorful names. But in an academic paper (especially in the title/abstract) it's better to use non-ambiguous terms that people already know the meaning of.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 46013, "question": "Distilling knowledge in Neural Nets, by Geoffery Hinton, Vinyals and Jeff Dean", "aSentId": 46032, "answer": "From the paper: \n\n&gt; When we did this work, Google\u2019s baseline model for JFT was a deep convolutional neural network that had been trained for about six months using asynchronous stochastic gradient descent on a large number of cores\n\nI can't even imagine the number of CPU (and GPU) cycles that must've gone into it...  O.O\n", "corpus": "reddit"}]
