[{"docID": "t5_2r3gv", "qSentId": 59192, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 59193, "answer": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59194, "question": "Do you plan on delivering an online course (e.g. on coursera) for RNNs? I for one would be really excited to do the course!!", "aSentId": 59195, "answer": "Thanks - I should! I\u2019ve been thinking about this for years. But it\ntakes time, and there are so many other things in the pipeline \u2026", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59192, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 59197, "answer": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59198, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 59199, "answer": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/IDSIA/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.\n\n**Edit of 16 March 2015:** Sacred link has changed!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59200, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/IDSIA/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.\n\n**Edit of 16 March 2015:** Sacred link has changed!", "aSentId": 59201, "answer": "This is very good to hear.  Thank you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59200, "question": "We did publish lots of open source code. Our\nPyBrain Machine learning library http://pybrain.org/ is public and\nwidely used, thanks to the efforts of Tom Schaul, Justin Bayer, Daan\nWierstra, Sun Yi, Martin Felder, Frank Sehnke, Thomas R\u00fcckstiess.\n\nHere is the already mentioned code\nhttp://sourceforge.net/projects/rnnl/ of the first competition-winning\nRNNs (2009) by my former PhD student and then postdoc Alex\nGraves. Many are using that.\n\nIt is true though that we don\u2019t publish all our code right away.  In\nfact, some of our code gets tied up in industrial projects which make\nit hard to release. \n\nNevertheless, especially recently, we published less code than we\ncould have. I am a big fan of the open source movement, and we've\nalready concluded internally to contribute more to it. Not long ago,\nthanks to the work of Klaus Greff, we open-sourced Python-based\n[Sacred](https://github.com/IDSIA/sacred): an infrastructure\nframework to organize our experiments and to keep the results\nreproducible. Unfortunately, it\u2019s a bit hard to find,\nbecause it turns out there already exists a famous \u201csacred python.\u201d\n\nThere are also plans to release more of our recent\nrecurrent network code soon.  In particular, there are plans for a new\nopen source library, a successor of PyBrain.\n\n**Edit of 16 March 2015:** Sacred link has changed!", "aSentId": 59203, "answer": "Wow! Thanks for Sacred.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59204, "question": "Wow! Thanks for Sacred.", "aSentId": 59205, "answer": "You are welcome.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59198, "question": "Why doesn't your group post its code online for reproducing the results of competitions you've won, such as the ISBI Brain Segmentation Contest?  Your results are impressive, but almost always not helpful for pushing the research forward.", "aSentId": 59207, "answer": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59208, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 59209, "answer": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59210, "question": "yeah, but what if somebody wants to see under the hood and improve it? providing code is the only way to enable the world to learn/help/improve.", "aSentId": 59211, "answer": "RNNLIB is provided as source, which you have to compile yourself.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59212, "question": "RNNLIB is provided as source, which you have to compile yourself.", "aSentId": 59213, "answer": "RNNLIB is the exception rather than the rule as far as I can tell.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59208, "question": "That is not entirely true. Alex Graves released a toolbox(RNNLIB) thus helping in pushing research forward.  ", "aSentId": 59215, "answer": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59216, "question": "Isn't that the one that is incredibly hard to compile on newer systems because its dependencies are completely outdated (e.g. GCC 3.0)?\n\nAnd correct me if I am wrong, but it also doesn't feature many of the \"newer\" developments, e.g. peepholes or layer generalization (see Monner's \"A generalized LSTM-like training algorithm for second-order recurrent neural networks\")", "aSentId": 59217, "answer": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59218, "question": "It's fair to ask that authors release the code used in preparing their publications, but you can't expect them to perform maintenance and feature updates afterwards.", "aSentId": 59219, "answer": "Fair enough. But it also means that there effectively is no (fast) up-to-date library. At least not with LSTM support out of the box.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59192, "question": "I am J\u00fcrgen Schmidhuber, AMA!", "aSentId": 59221, "answer": "What do you think about learning selective attention with recurrent neural networks?  What do you think are the promising methods in this area?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59225, "question": "Do you have a favorite Theory Of Consciousness (TOC)? \n\nWhat do you think of Guilio Tononi's Integrated Information Theory? \n\nWhat implications - if any - do you think \"TOC\" has for AGI?", "aSentId": 59226, "answer": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59227, "question": "Karl Popper famously said: \u201cAll life is problem solving.\u201d No theory of\nconsciousness is necessary to define the objectives of a general\nproblem solver. From an AGI point of view, consciousness is at best a\nby-product of a general problem solving procedure.\n\nI must admit that I am not a big fan of Tononi's theory.  The\nfollowing may represent a simpler and more general view of\nconsciousness.  Where do the symbols and self-symbols underlying\nconsciousness and sentience come from?  I think they come from data\ncompression during problem solving.  Let me plagiarize what I wrote\nearlier [1,2]:\n\nWhile a problem solver is interacting with the world, it should store\nthe entire raw history of actions and sensory observations including\nreward signals.  The data is \u2018holy\u2019 as it is the only basis of all\nthat can be known about the world. If you can store the data, do not\nthrow it away! Brains may have enough storage capacity to store 100\nyears of lifetime at reasonable resolution [1].\n\nAs we interact with the world to achieve goals, we are constructing\ninternal models of the world, predicting and thus partially\ncompressing the data history we are observing. If the\npredictor/compressor is a biological or artificial recurrent neural\nnetwork (RNN), it will automatically create feature hierarchies, lower\nlevel neurons corresponding to simple feature detectors similar to\nthose found in human brains, higher layer neurons typically\ncorresponding to more abstract features, but fine-grained where\nnecessary. Like any good compressor, the RNN will learn to identify\nshared regularities among different already existing internal data\nstructures, and generate prototype encodings (across neuron\npopulations) or symbols for frequently occurring observation\nsub-sequences, to shrink the storage space needed for the whole (we\nsee this in our artificial RNNs all the time).  Self-symbols may be\nviewed as a by-product of this, since there is one thing that is\ninvolved in all actions and sensory inputs of the agent, namely, the\nagent itself. To efficiently encode the entire data history through\npredictive coding, it will\nprofit from creating some sort of internal prototype symbol or code\n(e. g. a neural activity pattern) representing itself [1,2].  Whenever\nthis representation becomes activated above a certain threshold, say,\nby activating the corresponding neurons through new incoming sensory\ninputs or an internal \u2018search light\u2019 or otherwise, the agent could be\ncalled self-aware.  No need to see this as a mysterious process \u2014 it\nis just a natural by-product of partially compressing the observation\nhistory by efficiently encoding frequent observations.\n\n[1] Schmidhuber, J. (2009a) Simple algorithmic theory of subjective beauty, novelty,\nsurprise, interestingness, attention, curiosity, creativity, art, science, music,\njokes.  SICE Journal of the Society of Instrument and Control Engineers, 48 (1), pp. 21\u201332.\n\n[2] J. Schmidhuber. Philosophers &amp; Futurists, Catch Up! Response to The Singularity. \nJournal of Consciousness Studies, Volume 19, Numbers 1-2, pp. 173-182(10), 2012.\n", "aSentId": 59228, "answer": "Holy fuck\n\nEDIT: \nI mean, as a ML student researcher, Holy fuck.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59234, "question": "How do you recognize a promising machine learning phd student?", "aSentId": 59235, "answer": "I am privileged because I have been able to attract and\nwork with several truly outstanding students. But how to quickly\nrecognize a promising student when you first meet her? There is no recipe,\nbecause they are all different! In fact, sometimes it takes a while to\nrecognize someone\u2019s brilliance. In hindsight, however, they all have\nsomething in common: successful students are not only smart but also\ntenacious. While trying to solve a challenging problem, they run into\na dead end, and backtrack. Another dead end, another backtrack. But\nthey don\u2019t give up. And suddenly there is this little insight into the\nproblem which changes everything. And suddenly they are world experts\nin a particular aspect of the field, and then find it easy to churn\nout one paper after another, and create a great PhD thesis.\n\nAfter these abstract musings, some more concrete advice.  In\ninterviews with applicants, members of my lab tend to pose a few\nlittle problems, to see how the candidate approaches them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59239, "question": "The LSTM unit is delicately crafted to solve a specific problem in training RNNs. Do you see the need for other similarly \"high-complexity\" units in RNNs or CNNs, like for example Hinton's \"capsules\"? On the topic of CNNs and capsules, do you agree with Hinton's assessment that the efficacy of pooling is actually a disaster? (I do, for what it's worth)", "aSentId": 59240, "answer": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59241, "question": "I am not Dr. Schmidhuber, but I would like to weigh in on this since I talked to Hinton in person about his capsules.\n\nNow please take this with a grain of salt, since it is quite possible that I misinterpreted him :)\n\nDr. Hinton seems to believe that all information must somehow still be somewhat visible at the highest level of a hierarchy. With stuff like maxout units, yes, information is lost at higher layers. But the information isn't gone! It's still stored in the activations of the lower layers. So really, we could just grab that information again. Now this is probably very difficult for classifiers, but in HTM-style architectures (where information flows in both the up and down directions), it is perfectly possible to use both higher-layer abstracted information as well as lower layer \"fine-grained\" information simultaneously. For MPFs (memory prediction frameworks, a generalization of HTM) this works quite well since they only try to predict their next input (which in turn can be used for reinforcement learning).\n\nAlso, capsules are basically columns in HTM (he said that himself IIRC), except in HTM they are used for storing contextual (temporal) information, which to me seems far more realistic than storing additional feature-oriented spatial information like Dr. Hinton seems to be using them for.\n\n", "aSentId": 59242, "answer": "Thank you!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59249, "question": "Hi Dr. Schmidhuber, Thanks for the AMA!\nHow close are you to building the optimal scientist? ", "aSentId": 59250, "answer": "You are welcome! \n\nAbout a stone's throw away :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59252, "question": "Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?", "aSentId": 59253, "answer": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59254, "question": "&gt; Why is there not much interaction and collaboration between the researchers of Recurrent NNs and the rest of the NN community, particularly Convolutional NNs (e.g. Hinton, LeCun, Bengio)?\n\nIncorrect premise, IMO: At least 2/3 of your \"CNN people\" published notable work on RNNs.", "aSentId": 59255, "answer": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59256, "question": "Yes of course, but that is not what I meant.  I always see Hinton, LeCun, and Bengio interacting at conferences, panels, and google plus, but never Schmidhuber.   They also cite each others papers more.", "aSentId": 59257, "answer": "As you see, they may have better personal relationships ... that's it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59259, "question": "In what field do you think machine learning will make the biggest impact in the next ~5 years?", "aSentId": 59260, "answer": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59261, "question": "I think it depends a bit on what you mean by \"impact\". Commercial\nimpact? If so, in a related answer I write: Both supervised learning\nrecurrent neural networks (RNNs) and reinforcement learning RNNs will\nbe greatly scaled up.  In the commercially relevant supervised\ndepartment, many tasks such as natural language processing, speech\nrecognition, automatic video analysis and combinations of all three\nwill perhaps soon become trivial through large RNNs (the vision part\naugmented by CNN front-ends).\n\n\u201cSymbol grounding\u201d will be a natural by-product of this. For example,\nthe speech or text-processing units of the RNN will be connected to\nits video-processing units, and the RNN will learn the visual meaning\nof sentences such as \u201cthe cat in the video fell from the tree\u201d. Such\nRNNs should have many commercial applications.\n\nI am not so sure when we will see the first serious applications of\nreinforcement learning RNNs to real world robots, but it might also\nhappen within the next 5 years.\n\n", "aSentId": 59262, "answer": "Well, I guess I meant commerical, although not in terms of money, but in terms of it being actually used my masses of people.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59267, "question": "If marcus hutter was doing an AMA 20 years from now, what scientific question would you ask? Are there any machine learning specific questions you would ask?", "aSentId": 59268, "answer": "(Edited on 3/10/2015:) 20 years from now I'll be 72 and enter my midlife crisis. People will forgive me for asking silly questions. I cannot  predict the most important machine learning-specific question of 2035. If I could, I\u2019d probably ask it right now. However, since Marcus is not only a great computer scientist but also a physicist, I\u2019ll ask him: \u201cGiven the new scientific insights of the past 20 years, how long will it take AIs from our solar system to spread across the galaxy?\u201d Of course, a trivial lower bound is 100,000 years or so, which is nothing compared to the age of the galaxy. But that will work out only if someone else has already installed receivers such that (construction plans of) AIs can travel there by radio. Otherwise one must physically send seeds of self-replicating robot factories to the stars, to build the required infrastructure. How? Current proposals involve light sails pushed by lasers, but how to greatly slow down a seed near its target star? One idea: through even faster reflective sails traveling ahead of the seed. But there must be a better way. Let\u2019s hear what Marcus will have to tell us 20 years from now. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59271, "question": "You have postulated that quantum computers will fail because deterministic universe is a simpler hypothesis than a non-deterministic universe. What do you think about the current state of quantum computation?", "aSentId": 59272, "answer": "If you didn't see it, the professor commented on Quantum computing in another question.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59279, "question": "What is the future of PyBrain? Is your team still working with/on PyBrain? If not, what is your framework of choice? What do you think of Theano? Are you using something better?", "aSentId": 59280, "answer": "My PhD students Klaus and Rupesh are working on a successor of PyBrain with many new features, which hopefully will be released later this year.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59282, "question": "What's something exciting you're working on right now, if it's okay to be specific? ", "aSentId": 59283, "answer": "Among other things, we are working on the \u201cRNNAIssance\u201d - \nthe birth of a Recurrent Neural Network-based Artificial Intelligence (RNNAI).\nThis is about a reinforcement learning, RNN-based, increasingly general problem solver.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59285, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 59286, "answer": "I think I recall Hinton giving an answer to this in his MOOC: we like activations, from which derivatives can be computed easily in terms of the function value itself. For sigmoid the derivative is s(x) * (1 - s(x)) for example.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59285, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 59288, "answer": "There are Compositional Pattern Producing Networks which are used in HyperNEAT. They use many different mathematical functions as activations.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59285, "question": "Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing). Is the training too difficult or are those types of functions generally not that useful?", "aSentId": 59290, "answer": "I suspect activation functions that grow more quickly are harder to control, and likely lead to exploding or vanishing gradients. Although we've managed to handle piecewise linear activations, I'm not sure if quadratic/exponential would work well. In fact, I'd bet that you could improve on ReLu by making the response become logarithmic after a certain point. RBF activations are common though (and have excellent theoretical properties), they just don't seem to learn as well as ReLu. I once trained a neural net with sin/cosine activations (it went OK, nothing special), but in general you can try out any activation function you want. Throw it into Theano and see what happens.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59292, "question": "&gt; Why has there been such little work on more complicated activation functions like polynomials, exponentials, etc. (the only paper I saw was a cubic activation for NN for dependency parsing)\n\nGoogle these:\n\n* learning activation functions\n* network in network\n* parametric RELU", "aSentId": 59293, "answer": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59294, "question": "Thanks, I'm aware of those approaches. I was just wondering why obvious activation possible activation functions like the ones I mentioned hadn't been tried extensively also.", "aSentId": 59295, "answer": "An exponential activation would have as its derivative... an exponential. Gradient descent would be pretty messy with such a wild dynamic range.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59297, "question": "I might well be mistaken, but isn't one of the primary ideas behind neural networks to use a low-complexity function at each node, which effectively becomes a higher-order transformation through all the nodes and layers? I mean, aren't multiple layers and multiple nodes in each layer with less complex activations expected to approximate higher-order functions?", "aSentId": 59298, "answer": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59299, "question": "Multiplication between two inputs cannot be easily approximated I believe for ex. using just sigmoids/relu/arctan activation functions.", "aSentId": 59300, "answer": "I see, interesting!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59303, "question": "What do you think a small research institute (in Germany) can do to improve changes for funding of their projects?", "aSentId": 59304, "answer": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59305, "question": "I only have a trivial suggestion: publish some promising results! When my co-director Luca Maria Gambardella and myself took over IDSIA in 1995, it was just a small outfit with a handful of researchers. With Marco Dorigo and others, Luca started publishing papers on Swarm Intelligence and Ant Colony Optimization. Today this stuff is famous, but back then it was not immediately obvious that this would become such an important field. Nevertheless, the early work helped to acquire grants and grow the institute. Similarly for the neural network research done in my group. Back then computers were 10,000 times slower than today, and we had to resort to toy experiments to show the advantages of our (recurrent) neural networks over previous methods. It certainly was not obvious to all reviewers that this would result in huge commercial hits two decades later. But the early work was promising enough to acquire grants and push this research further. ", "aSentId": 59306, "answer": "Thanks for the answer. Up until now, I always was under the impression that institutes would have to produce papers that are recognized as groundbreaking from the first second on. Guess the importance can increase over time.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59308, "question": "Just wanted to say I never get tired of your talks... never.. not once.", "aSentId": 59309, "answer": "Thanks so much - I greatly appreciate it. \n\nYou are in good company. A colleague of mine has Alzheimer, and he said the same thing :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59311, "question": "If ASI is a real threat, what can we do now to prevent a catastrophe later?", "aSentId": 59312, "answer": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59313, "question": "ASI? You mean the Adam Smith Institute, a libertarian think tank in the UK? I don\u2019t feel they are a real threat.\n\n", "aSentId": 59314, "answer": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59315, "question": "I'm interested in how you'd answer it if it had been \"AGI\"? Also, maybe in contrast to that, \"artificial specific intelligence\" might have been what stevebrt was going for. Just a guess though.", "aSentId": 59316, "answer": "In my experience ASI almost always means artificial superintelligence, which is a term that's often used when discussing safe/friendly AI. The idea is that while AGI might be human level, ASI would be vastly more intelligent. This is usually supposed to be achieved by an exponential process of recursive self-improvement by an AGI that results in an intelligence explosion.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59320, "question": "Does Alex Graves have the weight of the future on his shoulders?", "aSentId": 59321, "answer": "And vice versa!\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59325, "question": "What music do you like to listen to? any particular bands or composers that you ride for?", "aSentId": 59326, "answer": "I feel that in each music genre, there are a few excellent works, and many others. My taste is pretty standard. For example, my favourite rock &amp; pop music act is also the best-selling one (the Beatles). I love certain songs of the Stones, Led Zeppelin, Elvis, S Wonder,  M Jackson, Prince, U2, Supertramp, Pink Floyd, Gr\u00f6nemeyer, Sting, Kraftwerk, M Bianco, P Williams (and many other artists who had a single great song in their entire carreer). IMO the best songs of Queen are as good as anybody\u2019s, with a rare timeless quality. Some of the works indicated above seem written by true geniuses. Some by my favourite composer (Bach) seem dictated by God himself :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59331, "question": "As a researcher do you care if results of your work find practical application? Or research by itself is more than a rewarding exercise. Immagine computational power was not growing at the same a speed as it did then most of results on RNN would stay on the paper.", "aSentId": 59332, "answer": "Kurt Lewin said: \"There is nothing so practical as a good theory.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59334, "question": "Hello Prof. Schmidhuber, thanks for doing an AMA! I have some questions regarding the G\u00f6del machine. My understanding is that the machine searches for an optimal behavioural strategy in arbitrary environments. It does so by finding a proof that an alternative strategy is better than the current one and by rewriting the actual strategy (which may include the strategy searching mechanism). The G\u00f6del machine finds the optimal strategy for a given utility function. \n\n * Is it guaranteed that the strategy searching mechanism actually finds a proof?\n * It is a current trend to find 'optimal' behaviours or organisation in nature. For example minimal jerk trajectories for reaching and pointing movements,  sparse features in vision or optimal resolution in grid cells. Nature found these strategies by trial-and-error. How can we take a utility function as a starting point and decide that it is a 'good' utility function?\n * Could the G\u00f6del machine and AIXI guide neuroscience and ML research as a theoretical framework? \n * Are there plans to find implementations of self-optimizing agents?", "aSentId": 59335, "answer": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59336, "question": "Hello quiteamess, you are welcome!\n\n1. G\u00f6del machines are limited by the basic limits of math and\ncomputation identified by the founder of modern theoretical computer\nscience himself, Kurt G\u00f6del (1931): some theorems are true but cannot\nbe proven by any computational theorem proving procedure (unless the\naxiomatic system itself is flawed). That is, in some situations the GM\nmay never find a proof of the benefits of some change to its own code.\n\n2. We can imitate nature, which approached this issue through\nevolution. It generated many utility function-optimizing organisms with\ndifferent utility functions. Those with the \u201cgood\u201d utility functions\nfound their niches and survived. \n\n3. I think so, because they are optimal in theoretical senses that are\nnot practical, and clarify what remains to be done, e.g.: Given a\nlimited constant number of computational instructions per second (a\ntrillion or so), what is the best way of using them to get as close as\npossible to a model such as AIXI that is optimal in absence of\nresource constraints?\n\n4. Yes.", "aSentId": 59337, "answer": "&gt; G\u00f6del machines are limited by the basic limits of math and computation identified by the founder of modern theoretical computer science himself, Kurt G\u00f6del (1931): some theorems are true but cannot be proven by any computational theorem proving procedure (unless the axiomatic system itself is flawed). That is, in some situations the GM may never find a proof of the benefits of some change to its own code.\n\nApart  from undecidable proofs, is there a constructive way to find the proofs? According to the Curry-Howard theorem proofs can be represented as programs and programs as proofs. So what is gained by searching in proof space in contrast to searching in program space? .. Or maybe I'm missing something. I tried to understand G\u00f6del machines for some time now but I'm still not sure how this should work.\n\n&gt; I think so, because they are optimal in theoretical senses that are not practical, and clarify what remains to be done, e.g.: Given a limited constant number of computational instructions per second (a trillion or so), what is the best way of using them to get as close as possible to a model such as AIXI that is optimal in absence of resource constraints?\n\nI think I saw Konrad K\u00f6rding mentioning AIXI in a talk, but unfortunately I could not find the online presentation any more. Just a wild guess that you knew something about this.. \n\n&gt; Yes.\n\nAny chance you could elaborate on this? :) Is something in this direction published?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59342, "question": "I am starting a CS Bachelor this September at ETH. Primarily because I want to get into AI/ML/NN research and creation. It simply is the most important thing there is:D What should i do to be able to join your group in Lugano, what are you looking for in your research assistants? Thanks and cheers", "aSentId": 59343, "answer": "Thanks a lot for your interest! We\u2019d like to see: mathematical\nskills, programming skills, willingness to work with others,\ncreativity, dedication, enthusiasm (you seem to have enough of that :-)\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59350, "question": "Hello! I just started doing my PhD at a German University and am interested in ML/NN. Would you recommend working on specific algorithms and trying to improve them or focus more on a specific use case? People are recommending doint the latter because working on algorithms takes a lot of time and my *opponents* are companies like Google.", "aSentId": 59351, "answer": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59352, "question": "But not working on algorithms/models and focusing only on an application is risky. Unless you love the application and then maybe you discover that the most sensible way to solve it in terms of performance/simplicity/robustness/computation time is not with a neural network.\n\n", "aSentId": 59353, "answer": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59354, "question": "What I mean by not working on algorithms is that I don't think I should create something like RMSProb or AdaGrad or create my own type of neural network. What I mean by concentrating on application is that I should look for a quite complex use case that is only solvable by deep knowledge of deep learning (no pun intended).", "aSentId": 59355, "answer": "&gt; a quite complex use case that is only solvable by deep knowledge of deep learning\n\nRelated to this, I would like to ask a question to Juergen. The history of machine learning seems to be quite cyclic. Is deep learning the final frontier? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59357, "question": "What is your take on the threat posed by artificial super intelligence to mankind?\n", "aSentId": 59358, "answer": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59359, "question": "I guess there is no lasting way of controlling systems much smarter\nthan humans, pursuing their own goals, being curious and creative, in\na way similar to the way humans and other mammals are creative, but on\na much grander scale.\n\nBut I think we may hope there won't be too many goal conflicts between\n\"us\" and \"them.\u201d Let me elaborate on this.\n\nHumans and others are interested in those they can compete and\ncollaborate with. Politicians are interested in other\npoliticians. Business people are interested in other business\npeople. Scientists are interested in other scientists. Kids are\ninterested in other kids of the same age. Goats are interested in\nother goats.\n\nSupersmart AIs will be mostly interested in other supersmart AIs, not\nin humans. Just like humans are mostly interested in other humans, not\nin ants. Aren't we much smarter than ants? But we don\u2019t extinguish\nthem, except for the few that invade our homes. The weight of all ants\nis still comparable to the weight of all humans.\n\n\nHuman interests are mainly limited to a very thin film of biosphere\naround the third planet, full of poisonous oxygen that makes many\nrobots rust. The rest of the solar system, however, is not made for\nhumans, but for appropriately designed robots. Some of the most\nimportant explorers of the 20th century already were (rather stupid)\nrobotic spacecraft. And they are getting smarter rapidly. Let\u2019s go\ncrazy. Imagine an advanced robot civilization in the asteroid belt,\nquite different from ours in the biosphere, with access to many more\nresources (e.g., the earth gets less than a billionth of the sun's\nlight). The belt contains lots of material for innumerable\nself-replicating robot factories. Robot minds or parts thereof will\ntravel in the most elegant and fastest way (namely by radio from\nsenders to receivers) across the solar system and beyond. There are\nincredible new opportunities for robots and software life in places\nhostile to biological beings. Why should advanced robots care much for\nour puny territory on the surface of planet number 3?\n\nYou see, I am an optimist :-)", "aSentId": 59360, "answer": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59361, "question": "I'm very concerned that there are numerous ways that scenario could fail. E.g. the superintelligent AI invents superior nanotech after being built, and self-replicating nanobots rapidly consume the Earth's surface. Sure it doesn't *need* the Earth's resources, but after you have the first nanobots, why make them stop?\n\nSecond it could come back to Earth later when it material to build dyson swarms, and our planet has a significant amount of mass close to the sun.\n\nThe idea of all powerful beings that are *totally indifferent* to us is utterly terrifying.\n\n*\"The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else.\"*", "aSentId": 59362, "answer": "I do understand your concerns. Note, however, that humankind is already used to huge, indifferent powers. A decent earthquake is a thousand times more powerful than all nuclear weapons combined. The sun is slowly heating up, and will make traditional life impossible within a few hundred million years. Humans evolved just in time to think about this, near the end of the 5-billion-year time window for life on earth.\nYour popular but simplistic nanobot scenario actually sounds like a threat to many AIs in the expected future \"ecology\" of AIs. So they'll be at least motivated to prevent that. Currently I am much more worried about certain humans who are relatively powerful but indifferent to the suffering of others. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59364, "question": "A long time ago, someone once misattributed '64k ought to be enough for anyone'.\n\nWhat general statement or suggestion about strong generalized a.i. could be looked at in a similar way a decade or two from now?\n\nThanks, I look forward to reading your ama.", "aSentId": 59365, "answer": "\"64 yottabytes ought to be enough for anyone.\"", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59371, "question": "Why does a mirror reverse right amd left, but not up and down?\n\n(I dont want the answer a human gives, but how AI explains it!)\n\n/L", "aSentId": 59372, "answer": "An AI would answer that your perception is reversed. The reason left and right appear to be reversed is because your brain models the mirror-you as part of the same world as the real you, and if you went around behind the mirror and faced yourself, you'd need to reverse your left and right to match the perception of the mirror-you. The reason you don't see the up-down reversal is because you're used to travelling horizontally. If you went over the mirror and faced yourself, you'd then have to reverse up and down instead. So it's all in your non-AI head!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59381, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 59382, "answer": "The models in both US and EU are shaped by Humboldt\u2019s old model\nof the research university. But they come in various flavours.\nFor example, there is huge variance in \"the European models\u201d. \nI see certain advantages of the successful US PhD school model \nwhich I got to know better at the University of Colorado at Boulder in the \nearly 1990s. But I feel that less school-like models also have something \ngoing for them. \n\nUS-inspired PhD schools like those at my present Swiss \nuniversity require students to get credits for certain courses. At TU\nMunich (where I come from), however, the attitude was: a PhD student\nis a grown-up who doesn\u2019t go to school any more; it\u2019s his own job to\nacquire the additional education he needs. This is great for strongly\nself-driven persons but may be suboptimal for others. At TUM, my wonderful\nadvisor, Wilfried Brauer, gave me total freedom in my research. I loved\nit, but it seems kind of out of fashion now in some places. \n\nThe extreme \nvariant is what I like to call the \u201cEinstein model.\u201d Einstein never went to \ngrad school. He worked at the patent office, and at some point he submitted a\nthesis to Univ. Zurich. That was it. Ah, maybe I shouldn\u2019t admit\nthat this is my favorite model. And now I am also realizing that I have not really \nanswered your question in any meaningful way - sorry for that!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59381, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 59384, "answer": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59385, "question": "I wonder if you are oversimplifying the so-called \"European model\" to suit your question.\n\nThe main source of funding for science PhD students in the UK is the EPSRC, which is 3.5 years funding. You are not tied to a project so you can pursue whatever you please, providing your supervisor is willing to go along with you.", "aSentId": 59386, "answer": "I probably am. I don't know much about grad school in Europe apart from what i hear from a few friends here and there. My impression tells me it is kind of different from grad school in America. I'd like to hear from someone with more insight. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59381, "question": "What do you think about the american model of grad school (5 years on average, teaching duties, industry internships, freedom to explore and zero in on a research problem) versus the european model (3 years, contracted for a specific project, no teaching duties, limited industry internships)? ", "aSentId": 59388, "answer": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59389, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 59390, "answer": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59391, "question": "i guess we might be looking at different programs.... i see a lot of emails on ML mailing lists about phd positions to work on a certain problem, on a contract of three years. i also know people doing phd at a max planck-affiliated program, where they don't teach, but work on research. the contracts are for three years from what i've seen and some people might take a couple of years more. ", "aSentId": 59392, "answer": "That could be, because Max Planck is a research center, not a university. Then I can imagine that the time period is shorter. I guess the same applies to a few other research centers in Europe. Is there no such thing in the USA?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59389, "question": "Grad school is PhD? I've never heard of a 3 year PhD in Europe, or one without teaching duties... Typical is 4 years minimal (can be longer) and definitely teaching duties", "aSentId": 59394, "answer": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59395, "question": "In Denmark, and by extension most of Europe by way of Bologna I believe (not counting UK), we follow a rather strict 3-2-3 year program (undergraduate, followed by graduate, followed by PhD). In Denmark the PhD is not extendable beyond 3 years, but there are some teaching duties.", "aSentId": 59396, "answer": "I have heard that about Denmark before. However phd time is not in any bologna agreement AFAIK.\n\nAt least UK, Netherlands and Belgium all have 4 years PhD, and I'm fairly certain Sweden, France and German universities as well... (All based on lab member phd duration)\n\nI tried googling what the typical length of a PhD is in Europe, but found no definitive answer. It seems it is not strictly defined, some countries have 3, most have 4, some can be extended to 5. I found no statistics on how often those lengths apply in reality, so it is difficult to say what happens most frequently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59398, "question": "What do you think about using ontologies / semantic information (DBPedia, Wikidata) as a substrate / mould for ANNs to generate more versatile networks?", "aSentId": 59399, "answer": "Sounds like a great idea! Perhaps relevant:  Ilya Sutskever &amp; Oriol Vinyals &amp; Quoc V. Le use LSTM recurrent neural networks to access semantic information for English-to-French translation, with great success: http://arxiv.org/abs/1409.3215. And Oriol Vinyals &amp; Lukasz Kaiser &amp; Terry Koo &amp; Slav Petrov &amp; Ilya Sutskever &amp; Geoffrey Hinton use LSTM to\nread a sentence, and decode it into a flattened tree. They achieve excellent constituency parsing results: http://arxiv.org/abs/1412.7449", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59401, "question": "(in relation to the Atari paper and partly on your statement about it)\n\nWhat do you personally think about using a diverse selection of video games as a learning problem / \"dataset\"?\n\nOne thing I found interesting about the DeepMind Nature paper is that they could not solve Montezuma's Revenge at all (the game, not the travel problem), which is an action-adventure game requiring some kind of real-world knowledge / thinking - and temporal planning, of course. As any Atari game, conceptually it is still rather simple.\n\nI wonder what would happen if we found an AI succeeding over a wide range of complex game concepts like e.g. Alpha Centauri / Civilization, SimCity, Monkey Island II (for humorous puns, such as \"monkey wrench\"), put it into a robot and unleash it on the real world.", "aSentId": 59402, "answer": "&gt; in relation to the Atari paper and partly on your statement about it\n\nCan you point me to his statement about it?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59409, "question": "Two questions, if I may:\n\n1. With Moore's law gradually coming to an end, it would seem that we won't be achieving anything even close to General AI on today's hardware, at least not economically. As a researcher at the forefront of the field, are you aware of any hardware \"game changers\" that may simplify training and execution of extremely large neural networks that may be capable of intelligence?\n\n2. What are some of the most exciting papers that you have read (or written) in the past year?", "aSentId": 59410, "answer": "&gt; With Moore's law gradually coming to an end\n\nSource? GPUs have just picked up the Moore torch and is now carrying the field. Ive seen no reason why this won't continue for 1 or 2 more cycles before something new  like graphene will be in production.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59413, "question": "What advice do you have for a BTech computer science student passionate about strong AI hoping to join your team at IDSIA someday?", "aSentId": 59414, "answer": "Read our papers, re-implement one of our systems, perhaps improve it a bit, or better a lot, or do something else that I was not able to think of because it\u2019s too original!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59419, "question": "Where did you get the joke about the three prisoners? ", "aSentId": 59420, "answer": "You mean the one that starts: \"Three prisoners walk into a bar ...\"? :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59426, "question": "What is the algorithm of love?\n", "aSentId": 59427, "answer": "For those who did not grok: Schmidhuber works on the formal theory of curiosity and epistemic value. What is the best formal account of co-operation / affection / attachment, a.k.a. \"love\"? For instance, Minsky refers to \"attachment learning\", albeit without formalization.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59426, "question": "What is the algorithm of love?\n", "aSentId": 59429, "answer": "Great question!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59443, "question": "Do you think having a PhD is important if one wants to work in a good research team?", "aSentId": 59444, "answer": "Not at all - my PhD students are doing excellent work, but don't have a PhD :-)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59446, "question": "How feasible is it for a non-expert to successfully run RNN code on a new dataset? Is there any high-quality open source code to do it?", "aSentId": 59447, "answer": "alex graves has a toolbox called RNNLIB. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59449, "question": "i understand that neural networks and deep learning are computationally intensive for non-trivial problems. In addition, many experiments are necessary to see what works and what does not. What sort of equipment do you recommend for doing research in this area without breaking the bank? ", "aSentId": 59450, "answer": "As long as your applications are not too ambitious, a desktop machine with one or more GPUs should do!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59459, "question": "What do you think of Bitcoin. ", "aSentId": 59460, "answer": "I thought more of it when I had more of it.\n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59462, "question": "Why do so many chinamen flood the ML community with rubbish?", "aSentId": 59463, "answer": "Whoops, looks like Grandma found Reddit", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59466, "question": "Google DeepMind publications all in one place", "aSentId": 59467, "answer": "Well, some papers do include authors with Google DeepMind affiliation, yet not on the list. Example: http://arxiv.org/abs/1502.03509", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59466, "question": "Google DeepMind publications all in one place", "aSentId": 59469, "answer": "Wow this is more resources than I could read in any reasonable amount of time without an unreasonable amount of determination.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59471, "question": "My Attempt at Outperforming DeepMind's Atari Results - UPDATE 13", "aSentId": 59472, "answer": "&gt;I would have made a video, but since the ALE uses..\n\nshoot it using your smartphone!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59471, "question": "My Attempt at Outperforming DeepMind's Atari Results - UPDATE 13", "aSentId": 59474, "answer": "This looks very promising. No one can doubt your ambition. Have you tried competing with the DeepMind system on a composite game (e.g. a game that switches between breakout and something else every 10 seconds)? Intuitively, it seems that your system should be better at that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59475, "question": "This looks very promising. No one can doubt your ambition. Have you tried competing with the DeepMind system on a composite game (e.g. a game that switches between breakout and something else every 10 seconds)? Intuitively, it seems that your system should be better at that.", "aSentId": 59476, "answer": "That would be an interesting test. The ALE right now is not set up for switching between games as far as I know, but perhaps there is a way of doing that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59471, "question": "My Attempt at Outperforming DeepMind's Atari Results - UPDATE 13", "aSentId": 59478, "answer": "I guess a key metric of success should be how proficient the system gets with a fixed amount of training data (ie. game time).\n\nThe deepmind guys seem to talk in the realm of hundreds of games to get decent results, which would presumably equate to hours of play time.\n\nYour results for 15 minutes of playtime seem competitive for that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59483, "question": "You definitely are optimistic! I like it...keep going, hopefully you get to something really cool. BTW I am looking at your code and I really can't figure out how you interface with ALE, you seem to have your own rendered inside Main.cpp but you said you are using ALE rendering SDL...   Also, how many regions has your network? I mean what is the hierarchy?", "aSentId": 59484, "answer": "I didn't do any of the rendering, the ALE handles all of that. I only inserted my agent into the CustomAgent class.\n\nRight now I am using 6 layers in the hierarchy, each higher layer is a bit smaller than the previous. The first layer is 168x192 (the resolution of the Atari 2600 plus a region where the action and Q inputs go).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59485, "question": "I didn't do any of the rendering, the ALE handles all of that. I only inserted my agent into the CustomAgent class.\n\nRight now I am using 6 layers in the hierarchy, each higher layer is a bit smaller than the previous. The first layer is 168x192 (the resolution of the Atari 2600 plus a region where the action and Q inputs go).", "aSentId": 59486, "answer": "I see, so basically you are embedding your code inside ALE in a CustomAgent that also instantiate the network layers and topology of your HTFERL network (as well as compiling everything within ALE). It would be great if you could share that code as well. \n\nAlso (for educational purposes and not performance) have you considered in the future a simpler C/C++ implementation without OpenCL? \nI think a big selling point of your approach is that the algorithm should be relatively compact/elegant and OpenCL takes away a little bit of that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59491, "question": "Knowm is a nascent company utilizing a new computational primitive (kt-RAM) to eliminate the Von Neumann bottleneck from cortical learning software. Here's their research paper. Also check out /r/knowm. What are your thoughts?", "aSentId": 59492, "answer": "sounds like a steaming pile of bullshit.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59491, "question": "Knowm is a nascent company utilizing a new computational primitive (kt-RAM) to eliminate the Von Neumann bottleneck from cortical learning software. Here's their research paper. Also check out /r/knowm. What are your thoughts?", "aSentId": 59494, "answer": "Sounds like they're trying to make a specialized hardware solution before anyone even knows what the right software model is. Which is a very, very dumb idea and a recipe for wasting a lot of effort on hard-coding a bad algorithm.\n\nThere's a reason why coders say premature optimization is the root of all evil.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59496, "question": "Libdeep: A deep learning library for C/C++/Python", "aSentId": 59497, "answer": "I think something bad happened when they trained the cancer detection model.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59496, "question": "Libdeep: A deep learning library for C/C++/Python", "aSentId": 59499, "answer": "Thanks for the announcement. \n\nSorry but I really have to ask: Why write another C-based library when caffe is available and is being widely used? I'm trying to understand your use case and figuring out if your library would be useful for what I'm working on. Thank you!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59500, "question": "Thanks for the announcement. \n\nSorry but I really have to ask: Why write another C-based library when caffe is available and is being widely used? I'm trying to understand your use case and figuring out if your library would be useful for what I'm working on. Thank you!", "aSentId": 59501, "answer": "This library doesn't do very much, and it makes some very questionable architectural decisions.  You probably do not want to use it at all.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59500, "question": "Thanks for the announcement. \n\nSorry but I really have to ask: Why write another C-based library when caffe is available and is being widely used? I'm trying to understand your use case and figuring out if your library would be useful for what I'm working on. Thank you!", "aSentId": 59503, "answer": "I am not the author, just happened to find this on Github.\nSo I have the same question to be honest.\n\nThough in defense of libdeep, the Python bindings do provide some pretty tidy examples and I like the idea of writing the net out to a .c source file to be compiled and used however you see fit.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59496, "question": "Libdeep: A deep learning library for C/C++/Python", "aSentId": 59505, "answer": "Python bindings: https://github.com/bashrc/libdeep-python", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59508, "question": "Data sets far too large for current hardware, need some recommendations.", "aSentId": 59509, "answer": "I think theano supports assignment to multiple GPUs, but not multi-gpu for the same function.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59510, "question": "I think theano supports assignment to multiple GPUs, but not multi-gpu for the same function.", "aSentId": 59511, "answer": "o.O\nI am quite confused then. Both of my titans are constantly at 100% when using Theano.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59512, "question": "o.O\nI am quite confused then. Both of my titans are constantly at 100% when using Theano.", "aSentId": 59513, "answer": "Really? that would not be my expectation, but I don't have 2 gpus so I haven't done it myself. What kind of model are you running?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59512, "question": "o.O\nI am quite confused then. Both of my titans are constantly at 100% when using Theano.", "aSentId": 59515, "answer": "That's odd, because Theano definitely does not support using multiple GPUs yet, except when you explicitly run functions on one or the other and manually transfer data between GPUs using PyCUDA, as they do in the paper siblbombs linked.\n\nThe new backend will support using multiple GPUs, but that is still under heavy development.\n\nI usually just run multiple experiments concurrently (one per GPU), there are always plenty of hyperparameters that need tuning anyway :)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59517, "question": "How do I get into AI, machine learning, planning, etc.?", "aSentId": 59518, "answer": "Try one of the popular moocs . udacity and coursera has some useful ones", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59517, "question": "How do I get into AI, machine learning, planning, etc.?", "aSentId": 59520, "answer": "There is an MIT Open Courseware course on Artificial Intelligance.  It went over my head midway through the first lecture so I have no idea how good it is.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59522, "question": "Probabilistic Binary-Mask Cocktail-Party Source Separation in a Convolutional Deep Neural Network", "aSentId": 59523, "answer": "From the abstract:\n\n&gt;Our results approach ideal binary mask performance, illustrating that relatively simple deep neural networks are capable of robust binary mask prediction.\n\nThis guy is essentially saying that he solved the cocktail party problem, one of the hardest problems in computer science. If true, it would be the greatest news in the business since the invention of multitasking. Am I the only one who is skeptical?\n\nEdit: Never mind. He's cheating. I had to make sure:\n\n&gt;In this paper, we employed a convolutional deep neural\nnetwork (DNN) to learn the ideal binary mask for a two-speaker\nspeech separation problem where speech from the two\nspeakers is used as training data and where the model is then\ntested on new speech from the same speakers.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59525, "question": "Introduction to Statistics using Python", "aSentId": 59526, "answer": "Thanks for sharing this, there's a lot of useful stuff here.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59527, "question": "Thanks for sharing this, there's a lot of useful stuff here.", "aSentId": 59528, "answer": "\nO, teach me how I should forget to think.\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59529, "question": "\nO, teach me how I should forget to think.\n", "aSentId": 59530, "answer": "I... don't get it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59533, "question": "Blogs about predictive analytics", "aSentId": 59534, "answer": "I'd also be interested if there are technical focused blogs on this.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59537, "question": "Does momentum make sense only for SGD or batch-GD, and not for GD?", "aSentId": 59538, "answer": "The noisy gradient isn't the only thing momentum helps. It can also help with stabilizing the descent direction even in a perfectly noiseless gradient regime (if you happen to be darting from one side of a trough/half-pipe to another, momentum will tend to push you perpendicular to the curvature of the pipe).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59539, "question": "The noisy gradient isn't the only thing momentum helps. It can also help with stabilizing the descent direction even in a perfectly noiseless gradient regime (if you happen to be darting from one side of a trough/half-pipe to another, momentum will tend to push you perpendicular to the curvature of the pipe).", "aSentId": 59540, "answer": "Is momentum, theoretically, an alternative to or complementary to learning rate adaptation methods like using the Hessian matrix, or Adagrad/delta etc. ? meaning, do you expect that using momentum with these will generally be helpful, or its more of a try it and find out kind of situation?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59537, "question": "Does momentum make sense only for SGD or batch-GD, and not for GD?", "aSentId": 59542, "answer": "Even conventional GD can be improved, most notably by introducing the Hessian matrix (the matrix of the second derivatives). You then have Newton's method, which has fast convergence once its near modes, and needs to be complemented with a line search part when too far from a mode\n\nSome momentum techniques can be viewed as trying to approximate the Hessian, I believe ?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59537, "question": "Does momentum make sense only for SGD or batch-GD, and not for GD?", "aSentId": 59544, "answer": "Can you link to any articles that talks about this \"momentum\"? How do you define and make use of momentum. I have never heard of this. I would imagine that every next gradient at iteration t+1 is a linear combination of true gradients at iteration t and t+1. For example, you could start with gradient v_{t}, use it to find the next point by moving some learning rate \\alpha along v_{t}, then compute the gradient v_{t+1} at the new point, but before moving \\alpha at this point, redefine v_{t+1} = (1/2)v_{t} + (1/2)v_{t+1}. That way you aren't changing direction as abruptly. I am not sure how to answer your question, but you may want to think about how the learning rate \\alpha (or the step size if you will) affects your \"momentum.\" ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59546, "question": "Text data classification", "aSentId": 59547, "answer": "Try using n grams tf+IDF combined with senti wordnet", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59548, "question": "Try using n grams tf+IDF combined with senti wordnet", "aSentId": 59549, "answer": "Hadn't considered that, i'll try that out. Thanks.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59546, "question": "Text data classification", "aSentId": 59551, "answer": "Deep learning is the state of the art right now in text classification. I'd check out passage, which makes it pretty easy to get started: https://github.com/IndicoDataSolutions/Passage\n\nPast that, is this unsupervised or supervised? (i.e. Do you have a training and testing set with labels of reasonable size?) If not, some kind of clustering method would work quite nicely. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59552, "question": "Deep learning is the state of the art right now in text classification. I'd check out passage, which makes it pretty easy to get started: https://github.com/IndicoDataSolutions/Passage\n\nPast that, is this unsupervised or supervised? (i.e. Do you have a training and testing set with labels of reasonable size?) If not, some kind of clustering method would work quite nicely. ", "aSentId": 59553, "answer": "I tried a clustering method to identify the classes but it gave me some strange results, I am in the process of building a training dataset right now. \n\nThank you for the article, I think it should work pretty well for me. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59555, "question": "Hacker's guide to Neural Networks", "aSentId": 59556, "answer": "This is great! It could be just that I'm new to the area, but this guide is the first NN/deep-learning resource that doesn't dedicate the introduction to regurgitating the whole \"neurons in our brains are like NN but not really lulz\". \n\n", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59555, "question": "Hacker's guide to Neural Networks", "aSentId": 59558, "answer": "Andrej posts here, he's done informal AMAs before.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59555, "question": "Hacker's guide to Neural Networks", "aSentId": 59560, "answer": "fantastic", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59563, "question": "Ask ML: Deep Learning - Where to start? What to implement? RNN's? RBM?", "aSentId": 59564, "answer": "Have you ever implemented a regular MLP (neural network) before? It might be best to start with that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59565, "question": "Have you ever implemented a regular MLP (neural network) before? It might be best to start with that.", "aSentId": 59566, "answer": "Agreed. Start simple! Definitely don't waste your time with RBMs, they're still useful in some special cases, but most of the time you won't need them.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59567, "question": "Agreed. Start simple! Definitely don't waste your time with RBMs, they're still useful in some special cases, but most of the time you won't need them.", "aSentId": 59568, "answer": "I think the theory of RBM's is quite appealing. The notion of ENERGY seems to be a very interesting study.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59565, "question": "Have you ever implemented a regular MLP (neural network) before? It might be best to start with that.", "aSentId": 59570, "answer": "Yes I did. I actually implemented a whole bunch of the standard Machine Learning algorithms already (Decision Trees, LinReg, LogRec, FeedForwards with BackProp). Now I want to go more into Deep Learning and I started with the paper \"Learning Deep Architectures for AI\". There it is written that Deep Belief Networks are coming from RBM's which come from Hopfield Nets. So I thought that it would be a good idea to study them a bit , henceforth implementing them ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59571, "question": "Yes I did. I actually implemented a whole bunch of the standard Machine Learning algorithms already (Decision Trees, LinReg, LogRec, FeedForwards with BackProp). Now I want to go more into Deep Learning and I started with the paper \"Learning Deep Architectures for AI\". There it is written that Deep Belief Networks are coming from RBM's which come from Hopfield Nets. So I thought that it would be a good idea to study them a bit , henceforth implementing them ", "aSentId": 59572, "answer": "Take Hinton's course on Coursera. That explains Hopfield nets, Stochastic Belief Nets, Boltzmann Machines, etc. He takes you through the progression. And it is from 2012, before DNN really overwhelmed everything else.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59571, "question": "Yes I did. I actually implemented a whole bunch of the standard Machine Learning algorithms already (Decision Trees, LinReg, LogRec, FeedForwards with BackProp). Now I want to go more into Deep Learning and I started with the paper \"Learning Deep Architectures for AI\". There it is written that Deep Belief Networks are coming from RBM's which come from Hopfield Nets. So I thought that it would be a good idea to study them a bit , henceforth implementing them ", "aSentId": 59574, "answer": "That paper is now 6 years old. I can tell you with confidence that almost nobody in the author's research group is working on RBMs or DBNs, at least as their primary direction of research.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59576, "question": "What are the pros an cons of Variational Autoencoders in relation to normal Autoencoders?", "aSentId": 59577, "answer": "From what I have read, Variational AE is a generative model compared to vanilla AE. \n\nI guess if you want to learn hidden representations of data (like AE) and generate data from it you should use Variational AE", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59576, "question": "What are the pros an cons of Variational Autoencoders in relation to normal Autoencoders?", "aSentId": 59579, "answer": "It has a probabilistic semantics that let's you sample from the joint distribution over the pixels, p(y).  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59580, "question": "It has a probabilistic semantics that let's you sample from the joint distribution over the pixels, p(y).  ", "aSentId": 59581, "answer": "Not only that. This is sth that denoising auto encoders also have, as their reconstruction is the transition operator of a Markov chain which produces samples from the data distribution.\n\nThe important difference is that sampling is efficient, because it only needs a single pass through the network.\n\nFurther niceties:\n\n- you can estimate the log likelihood very efficiently via importance sampling (see Rezende's \"sister\"-paper),\n- you can impute missing values via a Markov chain method (same paper).\n- you don't have to set hyper parameters such as regularization constants or of the noise distribution.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59582, "question": "Not only that. This is sth that denoising auto encoders also have, as their reconstruction is the transition operator of a Markov chain which produces samples from the data distribution.\n\nThe important difference is that sampling is efficient, because it only needs a single pass through the network.\n\nFurther niceties:\n\n- you can estimate the log likelihood very efficiently via importance sampling (see Rezende's \"sister\"-paper),\n- you can impute missing values via a Markov chain method (same paper).\n- you don't have to set hyper parameters such as regularization constants or of the noise distribution.", "aSentId": 59583, "answer": "Just curious, which regularization constants are you referring to?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59584, "question": "Just curious, which regularization constants are you referring to?", "aSentId": 59585, "answer": "sparsity penalty, contraction penalty.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59586, "question": "sparsity penalty, contraction penalty.", "aSentId": 59587, "answer": "Ah, I thought you were referring to a framework where you would never have to tune hyperparameters even if you decided to include other penalties in the VAE framework (like weight decay).", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59588, "question": "Ah, I thought you were referring to a framework where you would never have to tune hyperparameters even if you decided to include other penalties in the VAE framework (like weight decay).", "aSentId": 59589, "answer": "Well, no. :) There a plenty of hps involved.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59576, "question": "What are the pros an cons of Variational Autoencoders in relation to normal Autoencoders?", "aSentId": 59591, "answer": "The downside is that it is harder to implement.\n\nI don't know of any reason to use a DAE instead of a VAE.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59592, "question": "The downside is that it is harder to implement.\n\nI don't know of any reason to use a DAE instead of a VAE.", "aSentId": 59593, "answer": "Hi\n\nDidn't you write previously that VAE are harder to optimize, or did you change your mind about that?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59594, "question": "Hi\n\nDidn't you write previously that VAE are harder to optimize, or did you change your mind about that?", "aSentId": 59595, "answer": "Since Adam I did.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59596, "question": "Since Adam I did.", "aSentId": 59597, "answer": "Were you using RMSProp before?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59598, "question": "Were you using RMSProp before?", "aSentId": 59599, "answer": "Or adadelta.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59600, "question": "Or adadelta.", "aSentId": 59601, "answer": "So Adam/ADADELTA helped fix the convergence issues with VAEs?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59602, "question": "So Adam/ADADELTA helped fix the convergence issues with VAEs?", "aSentId": 59603, "answer": "While the final training is still noisy, Adam made it possible to learn some distributions that Adadelta/rmsprop had troubles with.\n\nE.g. a uniform box is incredibly hard for the VAE unless you use adam. (If someone is able to do it with adadelta/rmsprop, let me know!)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59604, "question": "While the final training is still noisy, Adam made it possible to learn some distributions that Adadelta/rmsprop had troubles with.\n\nE.g. a uniform box is incredibly hard for the VAE unless you use adam. (If someone is able to do it with adadelta/rmsprop, let me know!)", "aSentId": 59605, "answer": "Do you mean converting a uniform distribution x into a gaussian distributed variable q(z|x)? That's surprising considering an inverse CDF does just that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59606, "question": "Do you mean converting a uniform distribution x into a gaussian distributed variable q(z|x)? That's surprising considering an inverse CDF does just that.", "aSentId": 59607, "answer": "Yes, but the sampling noise in combination with the asymptotes makes it difficult, it seems.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59592, "question": "The downside is that it is harder to implement.\n\nI don't know of any reason to use a DAE instead of a VAE.", "aSentId": 59609, "answer": "&gt; DAE\n\nSorry What is this?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59610, "question": "&gt; DAE\n\nSorry What is this?", "aSentId": 59611, "answer": "denoising auto encoder", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59612, "question": "denoising auto encoder", "aSentId": 59613, "answer": "ah thanks", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59615, "question": "Unrelated question: \n\nHas anyone tried making the bottom part of the variational autoencoder a convnet, and making the top part of the network fully connected?  \n\nI'm pretty sure this would work.  ", "aSentId": 59616, "answer": "Yes, it's been done: http://arxiv.org/abs/1503.03167", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59618, "question": "On April 1st a Livestream event is taking place on how #watson artificial intelligence will impact you", "aSentId": 59619, "answer": "April Fools!!!!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59621, "question": "Bayesian Networks and ML. Not sure how they work together.", "aSentId": 59622, "answer": "BN and random Forest are different techniques. I.e random forest is a separate classification technique and BN is a graphical model. Try the package Bnlearn in R. It tells you how to design bn and apply it. ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59624, "question": "Images that fool computer vision raise security concerns", "aSentId": 59625, "answer": "What I don't understand is the following: Doesn't that happen to all learning algorithms?", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59626, "question": "What I don't understand is the following: Doesn't that happen to all learning algorithms?", "aSentId": 59627, "answer": "shh... deep learning is the buzz, so they are supposed to get their personal buzz out of it", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59626, "question": "What I don't understand is the following: Doesn't that happen to all learning algorithms?", "aSentId": 59629, "answer": "It's impossible to avoid bad classifications, unless you want to have a complete dictionary of every image.\n\nYour models have to make assumptions about the data in order to generalize past the training data.  Image classification is not exactly a function of the input space, so there are always going to be \"bad\" classifications.\n\nThe idea behind this particular method of finding the bad images is probably the first guess you'd get from a lot of mathematicians.  You'd expect to get some weird classification by starting at a point (image), randomly checking a few nearby points (variants on the image), going in the \"worst\" direction, and repeating the process.\n\nYou could try to design your model to defeat that kind of thing, and there's some obvious ideas (apply transformations or random perturbations to training data and keep training).  That might make it harder, but there's always going to be something weird going on, unless you've built a model that \"correctly\" classifies the entire input space.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59624, "question": "Images that fool computer vision raise security concerns", "aSentId": 59631, "answer": "How much knowledge about the system do you need to craft these kinds of images? Don't you need to have the system itself generate them in the first place? ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59632, "question": "How much knowledge about the system do you need to craft these kinds of images? Don't you need to have the system itself generate them in the first place? ", "aSentId": 59633, "answer": "In the cases that I've seen you need the gradient of the output with respect to the input, which usually requires having the parameters of the model.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59634, "question": "In the cases that I've seen you need the gradient of the output with respect to the input, which usually requires having the parameters of the model.  ", "aSentId": 59635, "answer": "IIRC in [Nguyen, Yosinski, and Clune, \u201cDeep Neural Networks Are Easily Fooled.\u201d](http://arxiv.org/abs/1412.1897), they used a genetic algorithm to generate the fooling images -- so all you would need is unlimited queries and their results.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59634, "question": "In the cases that I've seen you need the gradient of the output with respect to the input, which usually requires having the parameters of the model.  ", "aSentId": 59637, "answer": "or just estimates of the gradient from input/output examples", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59638, "question": "or just estimates of the gradient from input/output examples", "aSentId": 59639, "answer": "How would you get the gradient estimate? I've thought about this and tried to use finite differences to get the gradient on an ImageNet trained network. But then it took a ridiculous long time and I realized I had to do more than 100 million forward passes (the number of network parameters)! Perhaps a stochastic algorithm would've worked better, but it'd be less exact.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59634, "question": "In the cases that I've seen you need the gradient of the output with respect to the input, which usually requires having the parameters of the model.  ", "aSentId": 59641, "answer": "So similar to a backdoor.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59624, "question": "Images that fool computer vision raise security concerns", "aSentId": 59643, "answer": "Oh my god, it's a reverse CAPTCHA.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59645, "question": "Why don't we train our neural nets to outsmart the evolutionary algorithm? Just generate those fooling images, and label them as rubbish, put them in the neural net and it can now discern between real and fake images.", "aSentId": 59646, "answer": "that was mentioned in the article but since there's so many bad images relative to good it would take forever.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59647, "question": "that was mentioned in the article but since there's so many bad images relative to good it would take forever.", "aSentId": 59648, "answer": "Ah, that makes sense. Thanks for the reply!", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59652, "question": "\"This potentially has the basis for malfeasants to cause automated systems to give carefully crafted wrong answers to certain questions\"\n\nI don't see where this could be a security concern.  ", "aSentId": 59653, "answer": "Imagine a robot that guards the declaration of independence. The only person allowed in the room with the DoI is the caretaker. The robot allows her in based on a model from deep learning, and shoots anyone else who tried.\n\nNow let's say that Nick Cage wants to steal the declaration of independence. Using his knowledge of neural networks, Nick engineers a mask that takes advantage of the flaws in these deep nets.\n\nWhen the robots sees Nick wearing the mask, from most angles, it interprets it as the face of the caretaker.\n\nSorry for the ridiculous example.\n\nOh, maybe a better one would be a self-driving car that uses CV to avoid objects. Imagine a protest by truck drivers who are losing their jobs, where they cover their trucks in these \"adversarial\" images that causes the self-driving trucks to crash when driven alongside them. Same deal for taxi drivers.\n\nIn all cases I can think of, the security concern comes from people relying on these systems, rather than the systems themselves. Which is kind of obvious, in retrospect.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59654, "question": "Imagine a robot that guards the declaration of independence. The only person allowed in the room with the DoI is the caretaker. The robot allows her in based on a model from deep learning, and shoots anyone else who tried.\n\nNow let's say that Nick Cage wants to steal the declaration of independence. Using his knowledge of neural networks, Nick engineers a mask that takes advantage of the flaws in these deep nets.\n\nWhen the robots sees Nick wearing the mask, from most angles, it interprets it as the face of the caretaker.\n\nSorry for the ridiculous example.\n\nOh, maybe a better one would be a self-driving car that uses CV to avoid objects. Imagine a protest by truck drivers who are losing their jobs, where they cover their trucks in these \"adversarial\" images that causes the self-driving trucks to crash when driven alongside them. Same deal for taxi drivers.\n\nIn all cases I can think of, the security concern comes from people relying on these systems, rather than the systems themselves. Which is kind of obvious, in retrospect.", "aSentId": 59655, "answer": "Well, the unique thing about the adversarial examples is that humans can't perceive how they differ from normal examples.  If you just want to fool a computer system, you could just feed it fake data.  \n\nMaybe adversarial examples could fool a DRM detector or a spam detector?  Nonetheless, generating the adversarial examples would require having access to the parameters of the model.  It also might not be the easiest way to create examples that fool the model.  \n\nIt might be interesting to study ways of generating adversarial examples without having access to the model.  I guess it would be a search problem?  Genetic algorithms?  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59654, "question": "Imagine a robot that guards the declaration of independence. The only person allowed in the room with the DoI is the caretaker. The robot allows her in based on a model from deep learning, and shoots anyone else who tried.\n\nNow let's say that Nick Cage wants to steal the declaration of independence. Using his knowledge of neural networks, Nick engineers a mask that takes advantage of the flaws in these deep nets.\n\nWhen the robots sees Nick wearing the mask, from most angles, it interprets it as the face of the caretaker.\n\nSorry for the ridiculous example.\n\nOh, maybe a better one would be a self-driving car that uses CV to avoid objects. Imagine a protest by truck drivers who are losing their jobs, where they cover their trucks in these \"adversarial\" images that causes the self-driving trucks to crash when driven alongside them. Same deal for taxi drivers.\n\nIn all cases I can think of, the security concern comes from people relying on these systems, rather than the systems themselves. Which is kind of obvious, in retrospect.", "aSentId": 59657, "answer": "I personally think that the security concern is overblown when it comes to dynamic, real-time environments. Human beings can make wildly incorrect guesses about what an object is that is in the distance, at the periphery of their vision, or when their vision is impaired or impeded. \n\nIf all I got was a momentary glimpse of \"array of roughly square shapes\" my first guess would be computer keyboard as well. But usually I get a sequence of observations at slightly different angles over the course of several seconds in order to confirm that it was in fact a keyboard and not a predator in disguise.\n\nFor static images, I can definitely see this being a concern. But for a computer vision system deployed in a dynamic, real-time setting, it seems far less likely for such attacks to succeed.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59652, "question": "\"This potentially has the basis for malfeasants to cause automated systems to give carefully crafted wrong answers to certain questions\"\n\nI don't see where this could be a security concern.  ", "aSentId": 59659, "answer": "&gt;DNN might be used by a Web advertiser to decide what ad to show you on Facebook or by an intelligence agency to decide if a particular activity is suspicious\n\nthis might be a security concern for your asshole when the CIA decides to enhanced interrogate you by breaking off fluroescent lights in your ass and start pouring lye into it based on a false positive by a machine learning system. It's either that or water boarding or naked human pyramids. \n\nI don't think it will be easy to explain to jarheads that these systems can be fooled, the military really believes in systems like this being more effective that human beings. Countries like Israel are already using systems like this to identify \"bad people\" at airports based on facial expressions and are trying to sell the TSA on it in the US\n\nthink about it.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59661, "question": "From my extremely limited understanding, adding a little noise before processing would prevent this attack.", "aSentId": 59662, "answer": "Or, like in real life, process multiple frames on a suspect and the natural noise does it for you.  ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59663, "question": "Or, like in real life, process multiple frames on a suspect and the natural noise does it for you.  ", "aSentId": 59664, "answer": "Yeah, I was thinking of processing a digital image supplied by the attacker. The probability of one of these pathological inputs showing up after any analog stages is astronomically low.\n\n(again, I'm completely ignorant on this subject)", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59666, "question": "Those are some really fascinating images. I feel like, on some level, that's how our own brains are breaking up the images we see before it all get weaved together.", "aSentId": 59667, "answer": "the difference is these are the input images, not some intermediate processing.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59669, "question": "This is the sort of thing I mean when I say the singularity is a long way off. People think ai is complex or dangerous, but its incredibly simple and stupid. Self awareness is miles away.", "aSentId": 59670, "answer": "You're acting like humans never mislabel visual stimuli (and for example, would never mistake a jackdaw for a crow). ", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59671, "question": "You're acting like humans never mislabel visual stimuli (and for example, would never mistake a jackdaw for a crow). ", "aSentId": 59672, "answer": "But thats the point: the computers are no where near being able to tell that that definitely is a bird and not some other pattern designed to fool them. We're not perfect, but we are much more complex, and one cannot make up for that complexity.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59673, "question": "But thats the point: the computers are no where near being able to tell that that definitely is a bird and not some other pattern designed to fool them. We're not perfect, but we are much more complex, and one cannot make up for that complexity.", "aSentId": 59674, "answer": "Humans are trained/have evolved to recognize faces, so we [find them everywhere.](http://io9.com/5953993/what-makes-us-see-jesus-in-a-taco-or-a-human-face-on-mars) \n\nIf we can be fooled so easily, so can computers.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59671, "question": "You're acting like humans never mislabel visual stimuli (and for example, would never mistake a jackdaw for a crow). ", "aSentId": 59676, "answer": "We aren't quite bad enough to mislabel noise as being the same thing as a complex 3d object, sure, paradoila kicks in sometimes, but we can tell the difference, and are smart enough to figure out that it's not REALLY a bus in the blurry mess, we're a bit more discriminatory than that.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59669, "question": "This is the sort of thing I mean when I say the singularity is a long way off. People think ai is complex or dangerous, but its incredibly simple and stupid. Self awareness is miles away.", "aSentId": 59678, "answer": "Optical illusions can easily trick humans, take the white/blue dress example recently.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59669, "question": "This is the sort of thing I mean when I say the singularity is a long way off. People think ai is complex or dangerous, but its incredibly simple and stupid. Self awareness is miles away.", "aSentId": 59680, "answer": "Machine vision progress has been roughly doubling every year. Every year the error on image net is half as much from the year before. It is just now starting to beat humans.\n\nHumans have a highly optimized visual system that was tuned by evolution for over 500 million years. It's unreasonable to expect the first few generations of computer vision systems to be flawless compared to it. But the rate of progress is so ridiculous, and the fact that we can catch up with humans at all is amazing. Literally a few months after that paper was published, another paper came out explaining the effect and fixing it. How often does your brain get bug fixes?\n\nWhether or not the singularity will happen in our lifetime depends on a lot of factors, but a certainly not that current machine vision algorithms are flawless. What matters is the rate of progress and our ability to fix the flaws.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59685, "question": "I haven't read the paper, so I apologize if I'm spouting nonsense,  but... what's so crazy about this? If I fit a 1D linear regression model from points on [0,1], shouldn't I expect garbage if I evaluate it on some other interval far away? Isn't that basically what's going on here?", "aSentId": 59686, "answer": "Yes, that's exactly the issue. In fact [another paper](http://arxiv.org/abs/1412.6572) came out saying it's pretty much the same thing, that the nets are too linear and changing the inputs in the right direction changes the outputs like it would in a linear model.", "corpus": "reddit"},{"docID": "t5_2r3gv", "qSentId": 59690, "question": "GTC 2015: The Big Bang of Deep Learning", "aSentId": 59691, "answer": "Big bang of deep learning? That was in the 80s.", "corpus": "reddit"}]