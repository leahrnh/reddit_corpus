[{"docID": "t5_2qhmr", "qSentId": 58672, "question": "Michael Stonebraker wins $1 million Turing Award. This year marks the first time that the Turing Award comes with a Google-funded $1 million prize.", "aSentId": 58673, "answer": "I'm sure he's pleased by it, but the award is probably far more than the cash prize to most recipients. It almost certainly doesn't need mention, nor does the fact that the sponsor got to buy their way onto the ticket. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58675, "question": "Why don't colleges teach ARM instead of MIPS?", "aSentId": 58676, "answer": "Were writing a compiler to mips. I'm pretty pissed to be learning a Dino language, but I see the reasoning. Writing a compiler is hard. My teacher wrote a reference implementation for us to test, and him to grade against. Rewriting it for arm is just too much work when mips is just fine I guess. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58677, "question": "Were writing a compiler to mips. I'm pretty pissed to be learning a Dino language, but I see the reasoning. Writing a compiler is hard. My teacher wrote a reference implementation for us to test, and him to grade against. Rewriting it for arm is just too much work when mips is just fine I guess. ", "aSentId": 58678, "answer": "our compiler design course used ARM, rewriting it wasnt hard since all they did was check the assembled program output, not the assembler itself.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58677, "question": "Were writing a compiler to mips. I'm pretty pissed to be learning a Dino language, but I see the reasoning. Writing a compiler is hard. My teacher wrote a reference implementation for us to test, and him to grade against. Rewriting it for arm is just too much work when mips is just fine I guess. ", "aSentId": 58680, "answer": "As much as MIPS is a dying instruction set, it's not dead yet. A lot of embedded devices and things like routers still use it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58675, "question": "Why don't colleges teach ARM instead of MIPS?", "aSentId": 58682, "answer": "I like what /u/kphth said, but I think there's another major concern:\n\nThere just isn't as much academic source material for ARM as there is for MIPS. If you want to teach a course with MIPS, you've got something like 20 years of material created expressly for teaching students. ARM doesn't have that wealth of material, so any course teaching it basically gets to start from scratch.\n\nThat isn't to say that there aren't ARM courses out there. Some of my school's \"Topics In\" classes have covered ARM in the past, but the structure of those classes is a lot more, uh, \"seat of the pants\" learning than a more traditional classroom setting.\n\nIn short, the professor needs to write the ARM curriculum from scratch, whereas the structure and material for MIPS courses is already pretty much established.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58683, "question": "I like what /u/kphth said, but I think there's another major concern:\n\nThere just isn't as much academic source material for ARM as there is for MIPS. If you want to teach a course with MIPS, you've got something like 20 years of material created expressly for teaching students. ARM doesn't have that wealth of material, so any course teaching it basically gets to start from scratch.\n\nThat isn't to say that there aren't ARM courses out there. Some of my school's \"Topics In\" classes have covered ARM in the past, but the structure of those classes is a lot more, uh, \"seat of the pants\" learning than a more traditional classroom setting.\n\nIn short, the professor needs to write the ARM curriculum from scratch, whereas the structure and material for MIPS courses is already pretty much established.", "aSentId": 58684, "answer": "Building on this, my school teaches ARM but the textbook we use had to be written by a professor. I guess they couldn't find any good preexisting texts out there. Unfortunately, the textbook is filled with errors. Apparently they just paid a grad student to write the answer key so basically every other solution is incorrect. The errata list my previous professor maintains is embarrassingly long. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58675, "question": "Why don't colleges teach ARM instead of MIPS?", "aSentId": 58686, "answer": "They teach MIPS because that architecture is easier to learn on than modern day architectures. Everything is simpler. At least that's the reasoning they gave at my school. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58693, "question": "The Nature of Code", "aSentId": 58694, "answer": "What is this website? It's brilliant. Tons of useful stuff.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58695, "question": "What is this website? It's brilliant. Tons of useful stuff.", "aSentId": 58696, "answer": "It's the companion website to the book/video series called \"Nature of Code\", which were a set of tutorials/chapters on various techniques to bring processing drawings (https://processing.org/) to life.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58693, "question": "The Nature of Code", "aSentId": 58698, "answer": "I didn't read the entire article, but I remember making those random drawing programs on my TI-84 during math class instead of paying attention.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58693, "question": "The Nature of Code", "aSentId": 58700, "answer": "bookmarked for later.  This looks very interesting.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58704, "question": "A librarian problem", "aSentId": 58705, "answer": "From an engineering standpoint, your design should avoid this by doing the hard work on insertion (when someone puts the book back). Leaving it until some cleanup phase means that you can't trust the integrity of the book stack. And this, I believe, brings up the main issue: how can you tell something is sorted? It may appear to be sorted, but may only be locally sorted.\n\nIf you can't track whether an item has been moved from a sorted position (whether the book was ever touched), then I believe you would have to re-sort the whole thing unless you can come up with a trustworthy heuristic, such as \"there are never more than C unsorted book(s) locally\".\n\nIf you can track the touched state, you can just gather all touched books M in N and do a binary search for inserting M items back into N. Or sort M (quicksort), and travel N, inserting as needed. The avg complexity should be (MlogN) and (MlogM + 2N), respectively. That's not necessarily big O.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58706, "question": "From an engineering standpoint, your design should avoid this by doing the hard work on insertion (when someone puts the book back). Leaving it until some cleanup phase means that you can't trust the integrity of the book stack. And this, I believe, brings up the main issue: how can you tell something is sorted? It may appear to be sorted, but may only be locally sorted.\n\nIf you can't track whether an item has been moved from a sorted position (whether the book was ever touched), then I believe you would have to re-sort the whole thing unless you can come up with a trustworthy heuristic, such as \"there are never more than C unsorted book(s) locally\".\n\nIf you can track the touched state, you can just gather all touched books M in N and do a binary search for inserting M items back into N. Or sort M (quicksort), and travel N, inserting as needed. The avg complexity should be (MlogN) and (MlogM + 2N), respectively. That's not necessarily big O.", "aSentId": 58707, "answer": "Right. The reasons that libraries have the problem is because they can't control insertion. If it's your program, you can control insertion. Do that. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58708, "question": "Right. The reasons that libraries have the problem is because they can't control insertion. If it's your program, you can control insertion. Do that. ", "aSentId": 58709, "answer": "Controlling insertion isn't always enough though.  Work with big enough databases for long enough and you inevitably have to deal with corruption.  A file will get scrambled, a disk will fail, or a backhoe will dig up a cable.  At that point it doesn't matter how controlled your insertion was.\n\nI think OP is asking about ways to recover from this kind of out-of-band error case.  Cosmic rays, disk wear, power spikes, and backhoes are real world examples of OP's \"random noise source.\"  :-)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58704, "question": "A librarian problem", "aSentId": 58711, "answer": "In practice, librarians have other tasks to do that causes them to incidentally go look for a particular book and scan over other possibly misplaced books in the process, such as fetching reserved books, putting back returned books on the shelves, or helping people find a particular book or books on a particular topic. If a book is misplaced, it is eventually noticed and corrected.\n\nFor your problem, if we want the array to be fully sorted at the end of the day (say), with the shuffles happening randomly in the array, as far as I can tell we need to do a full scan in order to find the shuffled elements and correct them. You can do better than a full O(n log n) (assuming comparison sort) re-sort every day, though, since the array is partially sorted. Something like insertion sort would probably work well here.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58712, "question": "In practice, librarians have other tasks to do that causes them to incidentally go look for a particular book and scan over other possibly misplaced books in the process, such as fetching reserved books, putting back returned books on the shelves, or helping people find a particular book or books on a particular topic. If a book is misplaced, it is eventually noticed and corrected.\n\nFor your problem, if we want the array to be fully sorted at the end of the day (say), with the shuffles happening randomly in the array, as far as I can tell we need to do a full scan in order to find the shuffled elements and correct them. You can do better than a full O(n log n) (assuming comparison sort) re-sort every day, though, since the array is partially sorted. Something like insertion sort would probably work well here.", "aSentId": 58713, "answer": "&gt; For your problem, if we want the array to be fully sorted at the end of the day\n\nright, but I'm more interested in an efficient solution that leaves the array mostly sorted, rather than a perfect solution.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58714, "question": "&gt; For your problem, if we want the array to be fully sorted at the end of the day\n\nright, but I'm more interested in an efficient solution that leaves the array mostly sorted, rather than a perfect solution.", "aSentId": 58715, "answer": "The problem statement is a bit vague.  Libraries and other large warehouses that have this problem do spot checks: i.e. test a shelf for sortedness when doing some other operation on it.  If the shelf is unsorted, you can often sort it locally, and pull out wildly misplaced items to re-insert with a less efficient operation.  (E.g. a librarian just puts wrongly shelved books on the cart when they are discovered, to be re-shelved with the rest of the returns.)\n\nMaintenance can be done on either or both insert or retrieve operations, or can be scheduled separately.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58716, "question": "The problem statement is a bit vague.  Libraries and other large warehouses that have this problem do spot checks: i.e. test a shelf for sortedness when doing some other operation on it.  If the shelf is unsorted, you can often sort it locally, and pull out wildly misplaced items to re-insert with a less efficient operation.  (E.g. a librarian just puts wrongly shelved books on the cart when they are discovered, to be re-shelved with the rest of the returns.)\n\nMaintenance can be done on either or both insert or retrieve operations, or can be scheduled separately.", "aSentId": 58717, "answer": "Perhaps I could've stated the problem more clearly, but it is intended to be a bit vague.  And yes, I did mention spot checks in the OP but I was just wondering if there are any more sophisticated approaches which have been studied in these sorts of situations where i) a complete sort is infeasible; and ii) a near-perfect but not necessarily perfect solution is acceptable.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58718, "question": "Perhaps I could've stated the problem more clearly, but it is intended to be a bit vague.  And yes, I did mention spot checks in the OP but I was just wondering if there are any more sophisticated approaches which have been studied in these sorts of situations where i) a complete sort is infeasible; and ii) a near-perfect but not necessarily perfect solution is acceptable.", "aSentId": 58719, "answer": "Librarians were the original \"big data\" folks and have had hundreds of years to work on the problem, so I feel it's very likely this has been well studied and formalized.  A (pre-internet) literature search would probably be very interesting.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58720, "question": "Librarians were the original \"big data\" folks and have had hundreds of years to work on the problem, so I feel it's very likely this has been well studied and formalized.  A (pre-internet) literature search would probably be very interesting.", "aSentId": 58721, "answer": "In a library context, this is solved by assigning an address to each item in the library. (call number in catalog) If you find a book out of place, the call number tells you exactly where to put it. \n\nThen pages and sometimes librarians will go through sections regularly to make sure everything is sorted.  Or if they notice something out of sort while doing something else, they will put it in the correct place, or put it on a cart to be re-shelved later.\n\nAll the hard work is done when a new item is cataloged (assigned an address). ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58722, "question": "In a library context, this is solved by assigning an address to each item in the library. (call number in catalog) If you find a book out of place, the call number tells you exactly where to put it. \n\nThen pages and sometimes librarians will go through sections regularly to make sure everything is sorted.  Or if they notice something out of sort while doing something else, they will put it in the correct place, or put it on a cart to be re-shelved later.\n\nAll the hard work is done when a new item is cataloged (assigned an address). ", "aSentId": 58723, "answer": "Librarians also had to maintain the card catalogs: similar problems, different scale.\n\nWhen I was in school ... late 80s ... we had to read journals. I remember following references to library and highway journals for algorithms and network courses. Cross-discipline work is fun!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58724, "question": "Librarians also had to maintain the card catalogs: similar problems, different scale.\n\nWhen I was in school ... late 80s ... we had to read journals. I remember following references to library and highway journals for algorithms and network courses. Cross-discipline work is fun!", "aSentId": 58725, "answer": "Oh yeah, I didn't even think about keeping your card catalog sorted as well. \n\n&gt; Cross-discipline work is fun!\n\nAgreed wholeheartedly!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58724, "question": "Librarians also had to maintain the card catalogs: similar problems, different scale.\n\nWhen I was in school ... late 80s ... we had to read journals. I remember following references to library and highway journals for algorithms and network courses. Cross-discipline work is fun!", "aSentId": 58727, "answer": "I haven't actually ever played around with a card catalog, but I imagine they would also have the same addresses so sorting would be essentially the same process as for the actual items as well. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58728, "question": "I haven't actually ever played around with a card catalog, but I imagine they would also have the same addresses so sorting would be essentially the same process as for the actual items as well. ", "aSentId": 58729, "answer": "Card catalogs are sort of like indexes in a database.  There are several of them, and they're organized by different keys.  For example, there's an 'author' catalog that is sorted by the author's name, and has one (or more) cards listing the books by that author.  You need this because the main stacks have only a single key (dewey decimal number) and the catalog tells you where to go in the stacks for a particular book.\n\nBut of course the catalogs themselves would get unsorted, people would pull cards out to write down the numbers and then put them back in the wrong place.\n\nSimilar problems exist in warehouses.  In theory there's a database somewhere which keeps track of inventory and where in the warehouse it's located, but warehouse staff will sometimes mess up and put things in the wrong location, or take stuff out to get at something and put it back in the wrong place.\n\nReconciling your indexes with the reality of your data storage systems is a common (and well studied) problem.\n\nAFAIK it's usually pretty easy to resolve though, and I'm not aware of any hugely clever algorithms in this area.  [Not that I've looked...]", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58730, "question": "Card catalogs are sort of like indexes in a database.  There are several of them, and they're organized by different keys.  For example, there's an 'author' catalog that is sorted by the author's name, and has one (or more) cards listing the books by that author.  You need this because the main stacks have only a single key (dewey decimal number) and the catalog tells you where to go in the stacks for a particular book.\n\nBut of course the catalogs themselves would get unsorted, people would pull cards out to write down the numbers and then put them back in the wrong place.\n\nSimilar problems exist in warehouses.  In theory there's a database somewhere which keeps track of inventory and where in the warehouse it's located, but warehouse staff will sometimes mess up and put things in the wrong location, or take stuff out to get at something and put it back in the wrong place.\n\nReconciling your indexes with the reality of your data storage systems is a common (and well studied) problem.\n\nAFAIK it's usually pretty easy to resolve though, and I'm not aware of any hugely clever algorithms in this area.  [Not that I've looked...]", "aSentId": 58731, "answer": "&gt;There are several of them, and they're organized by different keys. For example, there's an 'author' catalog that is sorted by the author's name\n\nAh that makes sense. Probably would have an authors catalog, and a subject catalog at least (generally how the Dewey Decimal Numbers of Library of Congress numbers are created). ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58704, "question": "A librarian problem", "aSentId": 58733, "answer": "what assumptions are you allowed to make here? I'll make two to help inform what kind of solution is viable. \n\n1. the initial state of the dataset is correctly sorted (though it may become unsorted over time)\n2. the storage mechanism of the dataset is sparse enough that we can reposition elements of it without having to shift the the entire dataset to make room for the repositioned elements.\n\nthe solution I would go with, given those assumptions is some form of piecewise sorting. this means breaking up the data into discrete segments and enforcing (probably whenever an insertion operation is made) that the segments are sorted with respect to other segments. this can be done by just checking the first element of a segment against the last element of the preceding segment. an occurrence of random noise shuffling the order within a segment can be resolved by just resorting the segment rather than resorting the entire set. its a separate (and perhaps difficult) problem to find the optimal number of segments for the dataset.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58737, "question": "&gt;You can pretty much accept that it will never be perfectly sorted, but you still want it to be sorted enough so that it's still for the most part usable.\n\nThat's hugely subjective, which usually doesn't go over too well with computer science.\n\nHowever, there is a technique known as a heuristic that can be used to find approximate solutions to problems that are too complex to find exact solutions. For example, the travelling salesman problem using a greedy algorithm with a heuristic.\n\nI haven't seen heuristics applied to sorting, because sorting is usually something you want an exact solution for (and because algorithms isn't really my area).", "aSentId": 58738, "answer": "Data may not always need to be completely sortable though.  It may be enough for it to be \"clumpable\", and then your task is to find clumps that match some criteria and then you can process all the data in a clump linearly.\n\nThis is pretty common with big data operations where you'd doing classification or recognition on a wide variety of inputs.\n\nTake matching fingerprints as an example.  There's no exact sort order for a saved fingerprint, but you can still take a new sample, do some feature detection on it, pull a subset of candidates from your large catalog that have some features in common, and then run a more expensive comparison algorithm against each candidate.  At no point was your data set completely sorted, but it was organized.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58739, "question": "Data may not always need to be completely sortable though.  It may be enough for it to be \"clumpable\", and then your task is to find clumps that match some criteria and then you can process all the data in a clump linearly.\n\nThis is pretty common with big data operations where you'd doing classification or recognition on a wide variety of inputs.\n\nTake matching fingerprints as an example.  There's no exact sort order for a saved fingerprint, but you can still take a new sample, do some feature detection on it, pull a subset of candidates from your large catalog that have some features in common, and then run a more expensive comparison algorithm against each candidate.  At no point was your data set completely sorted, but it was organized.", "aSentId": 58740, "answer": "That's true, but library books, in this hypothetical situation, usually have a system in place by category/author/title such that they are completely sortable.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58741, "question": "That's true, but library books, in this hypothetical situation, usually have a system in place by category/author/title such that they are completely sortable.", "aSentId": 58742, "answer": "Either Dewey Decimal or Library of Congress Catalog would be that system. Every item has an address (call number) on it that tells you exactly where it goes.  ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58749, "question": "Database pioneer Stonebraker rocks $1M \u201cNobel Prize in Computing\u201d", "aSentId": 58750, "answer": "Why not just call it the Turing Award? \n\n'Database pioneer wins the \"Oscar of Binary\"'", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58756, "question": "Anyone know of an interpreter for the language of Davis, Sigal, and Weyuker's book?", "aSentId": 58757, "answer": "Just whip something up in Ocaml :)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58759, "question": "Cross platform GPU computation for real time ray tracing rendering engine", "aSentId": 58760, "answer": "There's GL Compute (in GL 4.3 and above), but if you think OpenCL isn't cross-platform then nothing is.\n\nOn consoles too, you haven't got a hope. It's by design (vendor lock in doesn't work if you can choose).\n\nProbably be better off posting on /r/gpgpu, /r/opencl, and /r/cuda (listed in order of subscriber count).\n\nedit: That you're targeting consoles, makes me think you are not serious about this at all.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58761, "question": "There's GL Compute (in GL 4.3 and above), but if you think OpenCL isn't cross-platform then nothing is.\n\nOn consoles too, you haven't got a hope. It's by design (vendor lock in doesn't work if you can choose).\n\nProbably be better off posting on /r/gpgpu, /r/opencl, and /r/cuda (listed in order of subscriber count).\n\nedit: That you're targeting consoles, makes me think you are not serious about this at all.", "aSentId": 58762, "answer": "&gt;That you're targeting consoles, makes me think you are not serious about this at all.\n\nLikely, but  not necessarily. OP made me interested enough to check out the state of GPGPU on consoles, and apparently Ubisoft has ported their cloth physics to GPU for the current gen consoles and pc and held a talk about it at gdc europe 2014 http://gdcvault.com/play/1020939/Efficient-Usage-of-Compute-Shaders. \n\nThe fact that he has to ask, and here of all places, is what makes me skeptical about how serious he is about this.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58759, "question": "Cross platform GPU computation for real time ray tracing rendering engine", "aSentId": 58764, "answer": "Hello! My PhD is on Ray/Path Tracing along with GPU parallelism and all that good stuff so I feel I can offer some input here.\n\nSo first the bad news lets just get it out of the way, what you're looking for just doesn't exist. \n\n---\n\nThere are lots of cross-platform (cross-OS) frameworks for Win/Linux/Mac. Why? Because they all run (pretty much) the same sort of hardware (CPU, CPU RAM, one or more GPU's with independent RAM). \n\nA PS4 or an Xbox One have totally different hardware under the hood from a PC (and each other), and as such you have to specifically design your algorithms and implementations to take advantage of this hardware. If you do find tools for highly parallel development cross-console it will likely be made by a game house who have poured a lot of time and money into making that framework \"purely\" so they themselves can use it to port their own software around easier. More likely however the game company in question will actually just write the low level code of their engine several times over for each console and then the engine abstracts all that out of view for the actual developers making a game with the engine. \n\n---\n\nLets talk about Optix. Optix is really cool and you can definitely achieve some great real time demo's with it. But that's not really the main motivation behind Optix for NVidia. We've spent the last 30 years or so pouring money into Rasterized Graphics and into developing GPU's which are very good at doing exactly that. The last few years however, there's been a shift towards general purpose (GPGPU) programming. At first the hardware was still the same so heterogeneous GPU frameworks were really just sort of hacky ways of reusing the hardware we have. Today GPU's are way more than just rasterized graphics units but they still aren't RPU's (Ray Processing Unit's). That is to say, before we did raster graphics, and we used raster hardware. Now we do ray tracing but we use general purpose hardware. This means that ray tracing is done entirely in software and as such has to be incredibly well optimized. \n\nNVidia Optix gives us that. A very nicely optimized ray tracing framework for nvidia general purpose hardware. You can use optix to do real time stuff but really it's just meant to be fast. That way it benefits both real time applications and long duration applications like rendering for film CGI where a single 4k frame can take 30+ hours to render. \n\n---\n\nTo touch on \"cross-platform\" as a terminology quickly, be a little careful with phrasing. OpenCL and OpenACC are very much the definition of cross-platform heterogenous frameworks. But naturally just as Optix only works with CUDA hardware, OpenCL and OpenACC only support CPU's, GPU's, and Accelerators which they have have implemented low level drivers for which do the job of abstracting the raw hardware into an interface the OpenCL or ACC can then work with generically. Hence why for AMD cards you need the AMD OpenCL driver, and for Intel CPU's you need the Intel OpenCL Driver, ect. \n\n---\n\nOkay, so with that said lets talk about your goal for this project. I think you might be biting off a bit more than you can chew. Optix has been developed by a large team of world leading experts over the course of several years. So taking everything they've done so far and making it cross platform (your OpenGL to their DirectX) is a huge amount of very difficult work.\n\nAdd to that cross-device support as you want to support completely different hardware configurations for PS4 and Xbox. Remember Optix only supports CUDA devices, and it's still taken them years to get it working right.\n\nI don't mean to be sound defeatist but I just don't think it's doable. \n\n---\n\nSo what is doable then? Keep it to within Win/Linux/Mac for a start. An Optix style framework written in OpenCL would be pretty cool! But it would probably be quite a bit harder to build/use than Optix as OpenCL doesn't support many C++ features like CUDA and also OpenCL code is decoupled from host code while CUDA code is written in and around the C++ code in the same file.\n\nI think what you should be looking at working towards is an OpenCL ray tracing framework which you can then use to implement real time demos or to accelerate an offline renderer. But start small, there's no shame in it. There's only shame in not appreciating the huge amount of work that's gone into something like Optix. \n\n--- \n\n**Addendum** To be honest I'm not even sure how you'd go about getting access to a PS4 &amp; Xbox One development kit. Sony and Microsoft keep them really locked down and only tend to sell them to registered and legitimate developers that they feel will actually turn it around and end up making them some money.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58765, "question": "Hello! My PhD is on Ray/Path Tracing along with GPU parallelism and all that good stuff so I feel I can offer some input here.\n\nSo first the bad news lets just get it out of the way, what you're looking for just doesn't exist. \n\n---\n\nThere are lots of cross-platform (cross-OS) frameworks for Win/Linux/Mac. Why? Because they all run (pretty much) the same sort of hardware (CPU, CPU RAM, one or more GPU's with independent RAM). \n\nA PS4 or an Xbox One have totally different hardware under the hood from a PC (and each other), and as such you have to specifically design your algorithms and implementations to take advantage of this hardware. If you do find tools for highly parallel development cross-console it will likely be made by a game house who have poured a lot of time and money into making that framework \"purely\" so they themselves can use it to port their own software around easier. More likely however the game company in question will actually just write the low level code of their engine several times over for each console and then the engine abstracts all that out of view for the actual developers making a game with the engine. \n\n---\n\nLets talk about Optix. Optix is really cool and you can definitely achieve some great real time demo's with it. But that's not really the main motivation behind Optix for NVidia. We've spent the last 30 years or so pouring money into Rasterized Graphics and into developing GPU's which are very good at doing exactly that. The last few years however, there's been a shift towards general purpose (GPGPU) programming. At first the hardware was still the same so heterogeneous GPU frameworks were really just sort of hacky ways of reusing the hardware we have. Today GPU's are way more than just rasterized graphics units but they still aren't RPU's (Ray Processing Unit's). That is to say, before we did raster graphics, and we used raster hardware. Now we do ray tracing but we use general purpose hardware. This means that ray tracing is done entirely in software and as such has to be incredibly well optimized. \n\nNVidia Optix gives us that. A very nicely optimized ray tracing framework for nvidia general purpose hardware. You can use optix to do real time stuff but really it's just meant to be fast. That way it benefits both real time applications and long duration applications like rendering for film CGI where a single 4k frame can take 30+ hours to render. \n\n---\n\nTo touch on \"cross-platform\" as a terminology quickly, be a little careful with phrasing. OpenCL and OpenACC are very much the definition of cross-platform heterogenous frameworks. But naturally just as Optix only works with CUDA hardware, OpenCL and OpenACC only support CPU's, GPU's, and Accelerators which they have have implemented low level drivers for which do the job of abstracting the raw hardware into an interface the OpenCL or ACC can then work with generically. Hence why for AMD cards you need the AMD OpenCL driver, and for Intel CPU's you need the Intel OpenCL Driver, ect. \n\n---\n\nOkay, so with that said lets talk about your goal for this project. I think you might be biting off a bit more than you can chew. Optix has been developed by a large team of world leading experts over the course of several years. So taking everything they've done so far and making it cross platform (your OpenGL to their DirectX) is a huge amount of very difficult work.\n\nAdd to that cross-device support as you want to support completely different hardware configurations for PS4 and Xbox. Remember Optix only supports CUDA devices, and it's still taken them years to get it working right.\n\nI don't mean to be sound defeatist but I just don't think it's doable. \n\n---\n\nSo what is doable then? Keep it to within Win/Linux/Mac for a start. An Optix style framework written in OpenCL would be pretty cool! But it would probably be quite a bit harder to build/use than Optix as OpenCL doesn't support many C++ features like CUDA and also OpenCL code is decoupled from host code while CUDA code is written in and around the C++ code in the same file.\n\nI think what you should be looking at working towards is an OpenCL ray tracing framework which you can then use to implement real time demos or to accelerate an offline renderer. But start small, there's no shame in it. There's only shame in not appreciating the huge amount of work that's gone into something like Optix. \n\n--- \n\n**Addendum** To be honest I'm not even sure how you'd go about getting access to a PS4 &amp; Xbox One development kit. Sony and Microsoft keep them really locked down and only tend to sell them to registered and legitimate developers that they feel will actually turn it around and end up making them some money.", "aSentId": 58766, "answer": "I'm curious what you think of OpenRL", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58767, "question": "I'm curious what you think of OpenRL", "aSentId": 58768, "answer": "I've yet to be convinced on it. I don't overly like the OpenGL api model for doing conventional graphics, so the idea of applying that model to ray tracing doesn't appeal too much to me.\n\nImagination Technology / PowerVR do some great work with conventional mobile graphics. One of my colleagues used to write tech demos for them and his work is fantastic. But I can't help thinking OpenRL is flawed from the get go.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58759, "question": "Cross platform GPU computation for real time ray tracing rendering engine", "aSentId": 58770, "answer": "OpenCL is about as cross-platform as things get at the moment for gpgpu. For consoles it all depends on what the console manufacturers choose to support. XBox probably supports DirectCompute as it uses a superset of DX11.2, but I don't know what ps4 does.\n\nEdit: I a word", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58773, "question": "Question about the Turing Award", "aSentId": 58774, "answer": "IIRC, the award is only given for those who did research work in theoretical computer science.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58775, "question": "IIRC, the award is only given for those who did research work in theoretical computer science.", "aSentId": 58776, "answer": "Ok I totally misunderstood the Turing Award.\n\nThanks for info", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58773, "question": "Question about the Turing Award", "aSentId": 58778, "answer": "Besides what the other commenter said, I think Barbara's work trumps Linus'.\n\nFrom wikipedia:\n\n&gt;Liskov received the 2008 Turing Award from the ACM, in March 2009,[12] for her work in the design of programming languages and software methodology that **led to the development of object-oriented programming**", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58779, "question": "Besides what the other commenter said, I think Barbara's work trumps Linus'.\n\nFrom wikipedia:\n\n&gt;Liskov received the 2008 Turing Award from the ACM, in March 2009,[12] for her work in the design of programming languages and software methodology that **led to the development of object-oriented programming**", "aSentId": 58780, "answer": "I'd say that page needs an edit. Her work on the Liskov Substitution Principle was introduced in 1987. I think OOP had already been around for over 2 decades by then, in one form or another.\n\nHer work is particularly important in statically typed object-oriented languages, and has influenced typing in most of these.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58782, "question": "Thinking in Types", "aSentId": 58783, "answer": "This blogpost should be titled: \"Typeclasses are not OOP Interfaces\" or something. It is interesting but does not really give a solution as to what actually to do in Haskell if one wants to have objects that draw themselves without the system statically knowing their exact type (typeclass instance).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58782, "question": "Thinking in Types", "aSentId": 58785, "answer": "I liked this post. It actually looks pretty easy, but I think I would have made the same mistakes, comming from Java and co.\nI also liked the part where the article says, that Game Ball Player Player is better than Game Ball [Player]. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58782, "question": "Thinking in Types", "aSentId": 58787, "answer": "It sucks that this needs to be explained. It is good that someone is explaining it though. To me this is basically like teaching someone what a Struct is. I guess it's so easy to just make an array of objects, or make an interface for an object, that this pattern has been missed by some people\n\nedit: I guess I mean it sucks that people would be confused about how to do this if they have a purely OO background. of course it is always good for us to be learning and teaching things even (and especially) if they seem obvious", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58788, "question": "It sucks that this needs to be explained. It is good that someone is explaining it though. To me this is basically like teaching someone what a Struct is. I guess it's so easy to just make an array of objects, or make an interface for an object, that this pattern has been missed by some people\n\nedit: I guess I mean it sucks that people would be confused about how to do this if they have a purely OO background. of course it is always good for us to be learning and teaching things even (and especially) if they seem obvious", "aSentId": 58789, "answer": "My take from it wasn't that people don't understand how types work, or how to use them. It was more that you sometimes can go halfway, and that gets you in trouble. It also is a critical distinction, possibly made opaque by Haskell's naming of the concepts, and a type and a common interface are not identical.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58788, "question": "It sucks that this needs to be explained. It is good that someone is explaining it though. To me this is basically like teaching someone what a Struct is. I guess it's so easy to just make an array of objects, or make an interface for an object, that this pattern has been missed by some people\n\nedit: I guess I mean it sucks that people would be confused about how to do this if they have a purely OO background. of course it is always good for us to be learning and teaching things even (and especially) if they seem obvious", "aSentId": 58791, "answer": "idk why you got downvoted at the end of the blog post I thought to myself, \"okay so he just invented objected orientated programming\"?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58792, "question": "idk why you got downvoted at the end of the blog post I thought to myself, \"okay so he just invented objected orientated programming\"?", "aSentId": 58793, "answer": "That's not what happened, though. OOP or at least what that colleague of the author wanted to do would entail late binding. The article solution does not provide that at all. It just shows how you can separate the game entities so their type is statically known and the typeclass instances can work.\n\nWhether that's good or not I don't know, but he did not actually reinvent OOP there.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58795, "question": "My takeaway is this just reinforces what I learned doing C++ in 1992.  Type systems suck at modeling reality because reality isn't that neat.  The usual examples are penguins vs birds and squares vs rectangles.  \n\nWhat I really learned is that, apparently Haskell programmers have lost the ability to use loops in a lot of useful places.\n\nI'll be over here doing the Objective C/Smalltalk thing, thanks.", "aSentId": 58796, "answer": "Dunno where Objective C and Smalltalk fit into the type strength spectrum, but I've been doing a lot of stuff in python recently and it does my head in that I can't specify types/constness of arguments to functions - there have been several bugs that I wouldn't have written had I been able to make statements about variable types...\n\nI'm guessing objc/smalltalk are somewhere inbetween python and c++?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58797, "question": "Dunno where Objective C and Smalltalk fit into the type strength spectrum, but I've been doing a lot of stuff in python recently and it does my head in that I can't specify types/constness of arguments to functions - there have been several bugs that I wouldn't have written had I been able to make statements about variable types...\n\nI'm guessing objc/smalltalk are somewhere inbetween python and c++?", "aSentId": 58798, "answer": "&gt; Dunno where Objective C and Smalltalk fit into the type strength spectrum\n\nSmalltalk is dynamically-typed, and its types are arguably *weaker* than Python's. Objective-C is like a grafting of Smalltalk-style OO onto C, so it's somewhere in-between C and Java.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58797, "question": "Dunno where Objective C and Smalltalk fit into the type strength spectrum, but I've been doing a lot of stuff in python recently and it does my head in that I can't specify types/constness of arguments to functions - there have been several bugs that I wouldn't have written had I been able to make statements about variable types...\n\nI'm guessing objc/smalltalk are somewhere inbetween python and c++?", "aSentId": 58800, "answer": "More like python.  Well...Smalltalk is more like python.  Any variable can be any type and you can send any message to any object.\n\nObjective C allows this as well, however it is possible to specify reference types that the compiler will at least warn on.\n\nType errors are generally a very tiny fraction of the errors I end up with and I always felt that the cognitive load of trying to satisfy type systems was exhausting and the costs just didn't outweigh the benefits.\n\nSmalltalk is amazing in that you can code in the debugger.  I write a line, then execute it and inspect the results.  Write another line...in a live program.  If I write a line wrong, I can unwind a little and restart the current block.  This tends to produce very high quality code.  I'm not going to be surprised because I've already tried it.\n\nObjective C - not so much as it is more like C or C++ in that it has a compiler - although the debugger is decent and I always unit test as I go (although I don't tend to keep my tests like the test first people do - which is fine as I adhere to the open closed principle - I seldom modify code - once tested it doesn't get broken).\n\nAnyhow - for me the bottom line is type systems aren't really that helpful in real world software.  I'm currently working on a mobile app with a server component and all the tricky errors have been data synchronization issues, working around dodgy networks (idempotent servers and clients are crucial) and race conditions.  Not type problems.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58795, "question": "My takeaway is this just reinforces what I learned doing C++ in 1992.  Type systems suck at modeling reality because reality isn't that neat.  The usual examples are penguins vs birds and squares vs rectangles.  \n\nWhat I really learned is that, apparently Haskell programmers have lost the ability to use loops in a lot of useful places.\n\nI'll be over here doing the Objective C/Smalltalk thing, thanks.", "aSentId": 58802, "answer": "C++ circa 1992 doesn't in any way represent a power of a good type system.\n\nYou're approaching this from a position of ignorance. When instead you could learn as many tools as possible. Because all of them suck in general and ~~each~~ a lot of them rock when used properly.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58803, "question": "C++ circa 1992 doesn't in any way represent a power of a good type system.\n\nYou're approaching this from a position of ignorance. When instead you could learn as many tools as possible. Because all of them suck in general and ~~each~~ a lot of them rock when used properly.", "aSentId": 58804, "answer": "No - it represents the baggage of a very strict and pedantic type system though.  Java's is no better.\n\nAnyhow...I know a lot of languages.  I haven't had occasion to learn Haskell but I have read a number of tutorials and introductions.  I don't find its point of view attractive.\n\nConsider this article...the solution was to abandon looping and inline all the calls because of the type system.  That's a stupid solution. The world isn't that homogeneous.  Its messy.  Thus I prefer a messy (dynamically typed) language to deal with it.\n\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58806, "question": "I wish to gain experience in databases before I start my internship this summer (hopefully backend dev). Is there an online course you guys recommend?", "aSentId": 58807, "answer": "Where are you doing your intern??", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58809, "question": "Pick a programming language. Let's say you're in the past on the design team. What would you change?", "aSentId": 58810, "answer": "Java: Add unsigned numerics. It's a bit frustrating when you try to work with an IP address stored as a native byte type and bytes don't actually go up to 255....\n\nR: Use 0-based array/matrix indexing. In computer science, indexes start at *0*, not 1. And yes, I'm talking to you, physical scienctists.... :D\n\nAlso, foreach loops would be wonderful to have.\n\nC++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58811, "question": "Java: Add unsigned numerics. It's a bit frustrating when you try to work with an IP address stored as a native byte type and bytes don't actually go up to 255....\n\nR: Use 0-based array/matrix indexing. In computer science, indexes start at *0*, not 1. And yes, I'm talking to you, physical scienctists.... :D\n\nAlso, foreach loops would be wonderful to have.\n\nC++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D", "aSentId": 58812, "answer": "&gt; \n&gt; \n&gt; \n&gt; \n&gt; C++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D\n\nReferences are strictly less powerful than pointers. They cannot be null (except when you dereference a null pointer to create them), and they cannot be reseated. The only real benefit is that when you use a less powerful language feature, you're less likely to screw something up (like by typing `p = 0;` instead of `*p = 0;`).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58813, "question": "&gt; \n&gt; \n&gt; \n&gt; \n&gt; C++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D\n\nReferences are strictly less powerful than pointers. They cannot be null (except when you dereference a null pointer to create them), and they cannot be reseated. The only real benefit is that when you use a less powerful language feature, you're less likely to screw something up (like by typing `p = 0;` instead of `*p = 0;`).", "aSentId": 58814, "answer": "That's what I've always thought... I also like the fact that theirs MUCH less ambiguity about the fact that the value of a passed variable may get modified during the function call. I could see a circumstance where an unsespecting programmer could pass an integer that then magically changes value because of the extra ampersand :D", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58815, "question": "That's what I've always thought... I also like the fact that theirs MUCH less ambiguity about the fact that the value of a passed variable may get modified during the function call. I could see a circumstance where an unsespecting programmer could pass an integer that then magically changes value because of the extra ampersand :D", "aSentId": 58816, "answer": "I like to use * for modifiable values, and &amp; with only const variables for just that reason.  Its a nice call site reminder that whats coming in could change.  I like how other languages have you put ref or out on the call to show the same thing.  ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58817, "question": "I like to use * for modifiable values, and &amp; with only const variables for just that reason.  Its a nice call site reminder that whats coming in could change.  I like how other languages have you put ref or out on the call to show the same thing.  ", "aSentId": 58818, "answer": "Or you could be like python (or java, for that matter) and say \"To hell with pass by value. EVERYTHING is a object/reference!\"\n\nThats one way I like doing it. :D", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58819, "question": "Or you could be like python (or java, for that matter) and say \"To hell with pass by value. EVERYTHING is a object/reference!\"\n\nThats one way I like doing it. :D", "aSentId": 58820, "answer": "Java passes object pointer/references by value.\n\n    void foo(String bar) {bar = \"changed\";}\n\nThe caller does not see any change in this example, because bar is just a plain old stack variable. However, bar is still initialized at method call with a reference to whatever String was passed to foo.\n\nWhereas, in C++,\n\n    void too(string &amp; bar) {bar = \"changed\";}\n\nThis does have an effect on already occupied memory, and the caller will see this change.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58821, "question": "Java passes object pointer/references by value.\n\n    void foo(String bar) {bar = \"changed\";}\n\nThe caller does not see any change in this example, because bar is just a plain old stack variable. However, bar is still initialized at method call with a reference to whatever String was passed to foo.\n\nWhereas, in C++,\n\n    void too(string &amp; bar) {bar = \"changed\";}\n\nThis does have an effect on already occupied memory, and the caller will see this change.", "aSentId": 58822, "answer": "True. The thing I like about java is the fact that it's almost completely consistent across any code you write :)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58811, "question": "Java: Add unsigned numerics. It's a bit frustrating when you try to work with an IP address stored as a native byte type and bytes don't actually go up to 255....\n\nR: Use 0-based array/matrix indexing. In computer science, indexes start at *0*, not 1. And yes, I'm talking to you, physical scienctists.... :D\n\nAlso, foreach loops would be wonderful to have.\n\nC++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D", "aSentId": 58824, "answer": "Much of the reason Java lacks unsigned was the lack of JVM opcodes.\n\nSmall binary size was something they cared about a lot, so they wanted to keep the opcode size to one byte. The unsigned equivalents of the various arithmetic and whatnot instructions would consume more than the 56 currently free opcodes.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58825, "question": "Much of the reason Java lacks unsigned was the lack of JVM opcodes.\n\nSmall binary size was something they cared about a lot, so they wanted to keep the opcode size to one byte. The unsigned equivalents of the various arithmetic and whatnot instructions would consume more than the 56 currently free opcodes.", "aSentId": 58826, "answer": "The unsigned equivalents of the various arithmetic instructions are in most cases exactly the same as their signed counterparts. Addition, subtraction, negation, bitwise operators (except right shift but they have two of it already), equality, even multiplication.. they could even implement the rest of them with function calls, making unsigned integers really just syntactic sugar.\n\nSo it could easily have been done even with the restricting that *no* opcodes be dedicated to them.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58811, "question": "Java: Add unsigned numerics. It's a bit frustrating when you try to work with an IP address stored as a native byte type and bytes don't actually go up to 255....\n\nR: Use 0-based array/matrix indexing. In computer science, indexes start at *0*, not 1. And yes, I'm talking to you, physical scienctists.... :D\n\nAlso, foreach loops would be wonderful to have.\n\nC++: I've always been confused by the C++ distinction between pass by reference and plain pointers... I know there are usages for both, but the ANSI C side of my brain wonders why pointers won't do the job just as well. :D", "aSentId": 58828, "answer": "Java/JVM: To hell with UCS-2, make chars 1 or 4 bytes, goddammit!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58829, "question": "Java/JVM: To hell with UCS-2, make chars 1 or 4 bytes, goddammit!", "aSentId": 58830, "answer": "UTF-16/UCS-2 is evil. Microsoft made the wrong choice back in the day and they still pay for it. On the other hand, UTF-8 wasn't invented back then so there's that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58809, "question": "Pick a programming language. Let's say you're in the past on the design team. What would you change?", "aSentId": 58832, "answer": "C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nJava: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nJavascript: Support shared-memory multithreading natively. Also, change the inheritance system to something sane like what C++ and Java have.\n\nEvery language where the native API uses fucking camel case: Make the native API not use fucking camel case.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58833, "question": "C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nJava: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nJavascript: Support shared-memory multithreading natively. Also, change the inheritance system to something sane like what C++ and Java have.\n\nEvery language where the native API uses fucking camel case: Make the native API not use fucking camel case.", "aSentId": 58834, "answer": "&gt; Require that the asterisk be with the type\n\nHeathen!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58835, "question": "&gt; Require that the asterisk be with the type\n\nHeathen!", "aSentId": 58836, "answer": "My understanding is the * with the variable name is meant to mirror dereference semantics. \n\nHence: into *foo\u2026 use *foo to get the int.\n\nBut function pointers are god awful and I'd change them any day.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58837, "question": "My understanding is the * with the variable name is meant to mirror dereference semantics. \n\nHence: into *foo\u2026 use *foo to get the int.\n\nBut function pointers are god awful and I'd change them any day.", "aSentId": 58838, "answer": "I prefer the symmetry of putting it next to the type, I think it makes it more obvious what's happening. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58839, "question": "I prefer the symmetry of putting it next to the type, I think it makes it more obvious what's happening. ", "aSentId": 58840, "answer": "The problem is it's a lie.  If you do:\n\n    int* foo, bar;\n\nThen foo is a pointer but bar isn't.  Now you can ban multi declarations, but I prefer to keep in mind it goes with the variable not the type. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58839, "question": "I prefer the symmetry of putting it next to the type, I think it makes it more obvious what's happening. ", "aSentId": 58842, "answer": "Then you need more changes, like, where do you put [].", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58833, "question": "C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nJava: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nJavascript: Support shared-memory multithreading natively. Also, change the inheritance system to something sane like what C++ and Java have.\n\nEvery language where the native API uses fucking camel case: Make the native API not use fucking camel case.", "aSentId": 58844, "answer": "&gt; C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nGo gets that one right, among other things. It's really C in safe without the mistakes in its design.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58845, "question": "&gt; C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nGo gets that one right, among other things. It's really C in safe without the mistakes in its design.", "aSentId": 58846, "answer": "I should really try Go one of these days.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58833, "question": "C/C++: Require that the asterisk be with the type. And change that awful function pointer declaration syntax accordingly.\n\nJava: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nJavascript: Support shared-memory multithreading natively. Also, change the inheritance system to something sane like what C++ and Java have.\n\nEvery language where the native API uses fucking camel case: Make the native API not use fucking camel case.", "aSentId": 58848, "answer": "&gt;Java: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nMay I ask why?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58849, "question": "&gt;Java: Let you put multiple classes in a single source file, and have it still compile to a single bytecode file.\n\nMay I ask why?", "aSentId": 58850, "answer": "Why *not?*\n\nAs it is, every time I make a new class, no matter how small it is or how little it does in the program, I have an extra file to keep track of (two, if I don't make it an inner class). Distinguishing between hundreds of tiny snippets of code is not what a filesystem is optimized to do, and the language should not force the programmer to organize his code using his computer's filesystem instead of any other way. I understand why *sometimes* you would want to organize things that way (e.g. if there's some particular class you want to use in two different projects), but those cases are not the norm, and it should be an option, not mandatory. Moreover, it *is* optional in C and C++, so making it mandatory in Java seems like a completely unnecessary step backwards in usability.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58851, "question": "Why *not?*\n\nAs it is, every time I make a new class, no matter how small it is or how little it does in the program, I have an extra file to keep track of (two, if I don't make it an inner class). Distinguishing between hundreds of tiny snippets of code is not what a filesystem is optimized to do, and the language should not force the programmer to organize his code using his computer's filesystem instead of any other way. I understand why *sometimes* you would want to organize things that way (e.g. if there's some particular class you want to use in two different projects), but those cases are not the norm, and it should be an option, not mandatory. Moreover, it *is* optional in C and C++, so making it mandatory in Java seems like a completely unnecessary step backwards in usability.", "aSentId": 58852, "answer": "In my view a Java class is not even a file, for all i care it could be stored in a database or in an archive. The 1 class/1 file is just the simplest representation of that Java class source in the filesystem. \n\nAs to why the .class files are stored as separate files, that is also just a convenience, when stored in a JAR, the are packed together anyway. The only point that is important, is that the class loader should be able to find and load classes on individual basis as needed and requested. And for that some separation is needed, for example based on file name, and pulled from a JAR.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58851, "question": "Why *not?*\n\nAs it is, every time I make a new class, no matter how small it is or how little it does in the program, I have an extra file to keep track of (two, if I don't make it an inner class). Distinguishing between hundreds of tiny snippets of code is not what a filesystem is optimized to do, and the language should not force the programmer to organize his code using his computer's filesystem instead of any other way. I understand why *sometimes* you would want to organize things that way (e.g. if there's some particular class you want to use in two different projects), but those cases are not the norm, and it should be an option, not mandatory. Moreover, it *is* optional in C and C++, so making it mandatory in Java seems like a completely unnecessary step backwards in usability.", "aSentId": 58854, "answer": "You can already have several classes in the same source file. They do not have to be inner classes. Of course only one of them is allowed to be public.\n\nOf course that doesn't fix the class-file problem but I never really see or touch them directly anyway and the filesystem can deal with them just fine.\n\nI think the rational was to always be able to locate a source file by having the public hierarchies mapped to the file system. Of course, nowadays we have IDEs and we don't need to rely on the file system anymore for that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58851, "question": "Why *not?*\n\nAs it is, every time I make a new class, no matter how small it is or how little it does in the program, I have an extra file to keep track of (two, if I don't make it an inner class). Distinguishing between hundreds of tiny snippets of code is not what a filesystem is optimized to do, and the language should not force the programmer to organize his code using his computer's filesystem instead of any other way. I understand why *sometimes* you would want to organize things that way (e.g. if there's some particular class you want to use in two different projects), but those cases are not the norm, and it should be an option, not mandatory. Moreover, it *is* optional in C and C++, so making it mandatory in Java seems like a completely unnecessary step backwards in usability.", "aSentId": 58856, "answer": "&gt; Distinguishing between hundreds of tiny snippets of code is not what a filesystem is optimized to do\n\nA (Unix) file system is exactly made for keeping track of tons of small files. It's just that NTFS sucks.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58858, "question": "&gt; Also, change the inheritance system to something sane like what C++ and Java have.\n\nOr better, remove it altogether. Inheritance is useless.", "aSentId": 58859, "answer": "What would be a better alternative to inheritance? Mixins? ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58860, "question": "What would be a better alternative to inheritance? Mixins? ", "aSentId": 58861, "answer": "Composition over inheritance. Interfaces, mixins.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58809, "question": "Pick a programming language. Let's say you're in the past on the design team. What would you change?", "aSentId": 58863, "answer": "**C++:**\n\n* Replace iostreams with something less stateful. A `cout &lt;&lt; hex` in one function shouldn't mess up printing in other functions, etc.\n* Get rid of the `vector&lt;bool&gt;` template specialization.\n\nIMO those are probably the major out-and-out *bad* decisions in C++. I'd also like a more fully-equipped STL, but I don't think having a small STL is really a design decision so much as it is a product of the way the C++ standard is created.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58864, "question": "**C++:**\n\n* Replace iostreams with something less stateful. A `cout &lt;&lt; hex` in one function shouldn't mess up printing in other functions, etc.\n* Get rid of the `vector&lt;bool&gt;` template specialization.\n\nIMO those are probably the major out-and-out *bad* decisions in C++. I'd also like a more fully-equipped STL, but I don't think having a small STL is really a design decision so much as it is a product of the way the C++ standard is created.", "aSentId": 58865, "answer": "What more would you like to see in STL?\nI'm curious what we're maybe missing out on?\n\nI think a circular buffer would be a nice addition, perhaps an \"optional\" wrapper type as well, but I can't think of much else.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58866, "question": "What more would you like to see in STL?\nI'm curious what we're maybe missing out on?\n\nI think a circular buffer would be a nice addition, perhaps an \"optional\" wrapper type as well, but I can't think of much else.", "aSentId": 58867, "answer": "Both of those would make great additions--an \"optional\" type is actually exactly what I was thinking of when I wrote that. In addition I think certain operating system operations are a little more difficult to do in a cross-platform way than they should be. Off the top of my head:\n\n* Launching a subprocess\n* Working with directories\n* Opening a file with a fixed location relative to a source file (e.g. opening a dictionary of words, etc).\n\nMost of those are covered by Boost, Qt, etc, but it would be nice to have them in the language spec. Given that these all fit under the same umbrella of \"OS operations\", my guess is there's something that stops these from going through standardization process--either it's much harder than it seems or there's politics involved or something like that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58864, "question": "**C++:**\n\n* Replace iostreams with something less stateful. A `cout &lt;&lt; hex` in one function shouldn't mess up printing in other functions, etc.\n* Get rid of the `vector&lt;bool&gt;` template specialization.\n\nIMO those are probably the major out-and-out *bad* decisions in C++. I'd also like a more fully-equipped STL, but I don't think having a small STL is really a design decision so much as it is a product of the way the C++ standard is created.", "aSentId": 58869, "answer": "How would you make iostreams less stateful? Add a reset manipulator? Make it only work for the next output object?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58870, "question": "How would you make iostreams less stateful? Add a reset manipulator? Make it only work for the next output object?", "aSentId": 58871, "answer": "I admittedly haven't thought about this too deeply, but I'd probably make `cout` and `cin` into subclasses of `ostream` and `istream`, instead of static instances of them. They would be used like this:\n\n    int main() {\n        std::cin input;\n        std::cout output;\n        output &lt;&lt; \"What is your name?\" &lt;&lt; std::endl;\n        std::string name;\n        input &gt;&gt; name;\n        output &lt;&lt; \"Your name is \" &lt;&lt; name &lt;&lt; std::endl;\n    }\n\nThe idea being that `cout` and `cin` are no longer global and static, so if you pass `std::hex` to an instance of `cout` it doesn't affect other `cout`s throughout the program.\n\nIf there's some reason this is a terrible idea I'd love to hear it--I think language design is really interesting.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58873, "question": "C: Fix operator precedence. They [got it wrong](http://stackoverflow.com/questions/4685072/operator-precedence-bitwise-lower-than) in the 60's, and we're still paying for their mistakes today.\n\n    3 &amp; 2 == 2  // is TRUE\n    6 &amp; 2 == 2  // is FALSE (!)\n\nBoth should be true, damnit. At least in C# it throws a compile time exception, but that really shouldn't be necessary..", "aSentId": 58874, "answer": "1971 to be specific http://cm.bell-labs.com/who/dmr/chist.html\n\nAnd it's because &amp; was originally supposed to be for booleans until &amp;&amp; was introduced for booleans and &amp; was repurposed for bitwise. Only later did they realize their mistake.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58876, "question": "PHP, I'd just go back and break Rasmus's coding fingers ", "aSentId": 58877, "answer": "Or just take examples of some average PHP code back in time with you, and rub his nose in it.\n\n\"BAD! BAD RASMUS!\"", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58876, "question": "PHP, I'd just go back and break Rasmus's coding fingers ", "aSentId": 58879, "answer": "Probably the only way.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58881, "question": "C++ functions can return multiple types without needing some sort of variant class to wrap then.", "aSentId": 58882, "answer": "You can get pretty close to that with C++11 tuples and `std::tie`.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58883, "question": "You can get pretty close to that with C++11 tuples and `std::tie`.", "aSentId": 58884, "answer": "&gt; without needing some sort of variant", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58885, "question": "&gt; without needing some sort of variant", "aSentId": 58886, "answer": "You never need to explicitly create a class to use tuples for multiple return values.\n\nSee [here](http://ideone.com/QSawOi). It's definitely less elegant than, say, Python's tuple unpacking, but it's not all that bad.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58885, "question": "&gt; without needing some sort of variant", "aSentId": 58888, "answer": "How do you imagine the syntax to be without some kind of tupple to store it in? Like this\n\nint a; \nfloat b;\n\na, b = foo() ;\n\nor how do you mean when you type \"without any variant\"? Just curiously wondering ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58889, "question": "How do you imagine the syntax to be without some kind of tupple to store it in? Like this\n\nint a; \nfloat b;\n\na, b = foo() ;\n\nor how do you mean when you type \"without any variant\"? Just curiously wondering ", "aSentId": 58890, "answer": "auto var = foo(); perhaps", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58891, "question": "auto var = foo(); perhaps", "aSentId": 58892, "answer": "There would still be an underlying variant class and additional overhead as the type is resolved and validated.\n\nboost::any comes to mind, but you still have to validate and cast it to a type to use the data/object.\n\n\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58893, "question": "There would still be an underlying variant class and additional overhead as the type is resolved and validated.\n\nboost::any comes to mind, but you still have to validate and cast it to a type to use the data/object.\n\n\n", "aSentId": 58894, "answer": "Well sure, but op wanted a feature added to the language. I want to be able to return a different type depending on the parameter, and have it just work. I know I could use boost or a tuple, but it would be cool if auto could just do it for me.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58883, "question": "You can get pretty close to that with C++11 tuples and `std::tie`.", "aSentId": 58896, "answer": "That's more about returning multiple values than multiple types.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58898, "question": "For my 2 favorite getting things done languages:\n\n**Scala**: \n\nx) Add const as a concept.  As in, this thing Im passing in can not be modified.  \n\nx) Get rid of the GC and embrace RAII\n\nx) Dont use type erasure (although thats more a jvm thing)\n\nx) Possibly: Build it on the CLR rather than the JVM\n\nx) Dont make value types a decision at type declaration time, but rather at instance declaration time.\n\nx) Also add unsigned.  Again, I think this is a jvm thing\n\n**C++**: \n\nx) Put a real macro system in.  \n\nx) Add a reflection system.\n\nx) Add scala's linearization for multi inheritance and all the attendant pieces.  This makes a lot of neat emergent structures possible like stackable traits.  \n\nx) Add lambdas.  Oh wait, we got those.  \n\nx) Add pattern matching.\n\nx) Use Expected from the beginning for error handling.  \n\nx.edit) Other things to make the code more dry.  Case classes from Scala are a good example.  The macro system should be powerful enough to make them, but theyre in the std lib.  \n\nIm sure theres more.  If I remember any Ill put them.  ", "aSentId": 58899, "answer": "What exactly would you want from c++'s reflection system? My only experience with reflection has been understanding and unfucking some python code written by someone who was *far* to keen on obfuscating everything with reflection and who unfortunately left before I could ask him about it / beat him round the head with something.\n\nI guess I'm asking what sort of problems is reflection good at when its done *well*? Where does it shine?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58898, "question": "For my 2 favorite getting things done languages:\n\n**Scala**: \n\nx) Add const as a concept.  As in, this thing Im passing in can not be modified.  \n\nx) Get rid of the GC and embrace RAII\n\nx) Dont use type erasure (although thats more a jvm thing)\n\nx) Possibly: Build it on the CLR rather than the JVM\n\nx) Dont make value types a decision at type declaration time, but rather at instance declaration time.\n\nx) Also add unsigned.  Again, I think this is a jvm thing\n\n**C++**: \n\nx) Put a real macro system in.  \n\nx) Add a reflection system.\n\nx) Add scala's linearization for multi inheritance and all the attendant pieces.  This makes a lot of neat emergent structures possible like stackable traits.  \n\nx) Add lambdas.  Oh wait, we got those.  \n\nx) Add pattern matching.\n\nx) Use Expected from the beginning for error handling.  \n\nx.edit) Other things to make the code more dry.  Case classes from Scala are a good example.  The macro system should be powerful enough to make them, but theyre in the std lib.  \n\nIm sure theres more.  If I remember any Ill put them.  ", "aSentId": 58901, "answer": "Also **Scala:**\n\nMake trait-order relevant for subtyping.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58903, "question": "JavaScript: use strict mode always, add a block scope, fix binding of this, remove with, fix + operator, etc.", "aSentId": 58904, "answer": "remove eval, optional typing, es6 style classes instead of prototypes, anything from the strong mode proposal", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58906, "question": "C: I'd start with explicitly sized integer types. int8_t, int16_t, int32_t and int64_t, and of course their unsigned variants. I'd also define 8 bits to a byte :). I've spent way too much time fixing things on \"embedded\" systems transitioning between 32 and 64 bit because the storage capacity of long changes. (At least in LP64, which wouldn't be a problem at all if we fixed the integer types...)", "aSentId": 58907, "answer": "Do you *hate* people who use C to program their DSPs or graphics cards?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58908, "question": "Do you *hate* people who use C to program their DSPs or graphics cards?", "aSentId": 58909, "answer": "Do you mean program as in design the HW or driver level SW?\n\nDrivers are what I was thinking of when I wrote it. Pretty much everything that touches HW is typed according to register size or known storage capacity, but many stdlib functions take arguments in terms of short/int/long/longlong. I don't think I've ever seen a case where its useful for int to transition between 16 bits and 32+ depending on architecture.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58910, "question": "Do you mean program as in design the HW or driver level SW?\n\nDrivers are what I was thinking of when I wrote it. Pretty much everything that touches HW is typed according to register size or known storage capacity, but many stdlib functions take arguments in terms of short/int/long/longlong. I don't think I've ever seen a case where its useful for int to transition between 16 bits and 32+ depending on architecture.", "aSentId": 58911, "answer": "I was talking about the programs that run on DSPs. DSPs often use weird type sizes, like 36 bit words.\n\nAn `int` is bounded below to 16 bit because C can also be used on 16 bit platforms. It absolutely makes sense to have the default type 16 bits in size there so the C standard does not forbid that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58910, "question": "Do you mean program as in design the HW or driver level SW?\n\nDrivers are what I was thinking of when I wrote it. Pretty much everything that touches HW is typed according to register size or known storage capacity, but many stdlib functions take arguments in terms of short/int/long/longlong. I don't think I've ever seen a case where its useful for int to transition between 16 bits and 32+ depending on architecture.", "aSentId": 58913, "answer": "&gt; I don't think I've ever seen a case where its useful for int to transition between 16 bits and 32+ depending on architecture.\n\nI make an effort to only ever use \"int\" when I want a number that holds small values, no higher than I'm going to want to usually count on a machine.\n\nAnywhere that I need a specific bit width, I use the stdint.h types you mention (granted, this was added later, and should have been in from the start).\n\nI find that following those rules, you end up using \"int\" in a *lot* of places. The majority even, as generally you're only interested in counting in machine friendly ways. Now if I *lost* \"int\", and had to choose a given bit width, I'd be forced to choose between worse-than-halving my performance on 16 bit micros and doubling my memory usage, or slowing down access everywhere on 32 bit processors thanks to required sign extending. I wouldn't like that.\n\n\"int\"'s very useful like that - just give me a value that probably fits into a register that can count up to at least ~2^15. I'd rather not lose it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58914, "question": "&gt; I don't think I've ever seen a case where its useful for int to transition between 16 bits and 32+ depending on architecture.\n\nI make an effort to only ever use \"int\" when I want a number that holds small values, no higher than I'm going to want to usually count on a machine.\n\nAnywhere that I need a specific bit width, I use the stdint.h types you mention (granted, this was added later, and should have been in from the start).\n\nI find that following those rules, you end up using \"int\" in a *lot* of places. The majority even, as generally you're only interested in counting in machine friendly ways. Now if I *lost* \"int\", and had to choose a given bit width, I'd be forced to choose between worse-than-halving my performance on 16 bit micros and doubling my memory usage, or slowing down access everywhere on 32 bit processors thanks to required sign extending. I wouldn't like that.\n\n\"int\"'s very useful like that - just give me a value that probably fits into a register that can count up to at least ~2^15. I'd rather not lose it.", "aSentId": 58915, "answer": "And then when you go to 64 bit, you're only reading half the register width again. That's the core of the problem, the default types really don't play well with changing architectures. They're supposed to, but they dont.\n\nI think maybe having something like a \"native word\" integer type would help that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58916, "question": "And then when you go to 64 bit, you're only reading half the register width again. That's the core of the problem, the default types really don't play well with changing architectures. They're supposed to, but they dont.\n\nI think maybe having something like a \"native word\" integer type would help that.", "aSentId": 58917, "answer": "&gt; I think maybe having something like a \"native word\" integer type would help that.\n\nWhich is what `int` was supposed to be. The reason why we often have a 32 bit `int` type on 64 bit architectures is that not having a 32 bit `int` means using kludges to get a 32 bit type on pre-C99 implementations of the C language. Go gets that right again: They have fixed with types and an `int` type whose size is the word size of the platform the code is running on.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58919, "question": "Java: Perform whatever dark rituals would be necessary to allow generic arrays. Yes,  I know,  type erasure and whatnot make it a problem, but it annoys the crap out of me. ", "aSentId": 58920, "answer": "Um, sorry, can you clarify what you mean by generic arrays?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58921, "question": "Um, sorry, can you clarify what you mean by generic arrays?", "aSentId": 58922, "answer": "In Java, the following code won't compile:\n\n    public class GenericArrayTest&lt;T&gt; {\n      // returns an array of the parameterised type\n      public &lt;T&gt; T[] returnArray() {\n        return new T[10];\n      }\n    }\n\nThe standard workaround is to use an `Object[]` array (which is how things like `ArrayList` are implemented) but then you lose type-safety.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58921, "question": "Um, sorry, can you clarify what you mean by generic arrays?", "aSentId": 58924, "answer": "The problem with java is that you can't use the generic type as a type for new objects, e.g. \n\n    public class genArray&lt;T&gt; {\n        T[] foo = new T[10];\n    }\ndoesn't work, because during runtime the code is actually:\n\n    public class genArray {\n        Object[] foo = new Object[10];\n    }\n    ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58926, "question": "C++. I'd talk everyone out of developing it entirely. Hey, you asked for opinions. That's mine.", "aSentId": 58927, "answer": "How about a new language called (c++)--. Next thing you know, it's been optimized out by the compiler!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58926, "question": "C++. I'd talk everyone out of developing it entirely. Hey, you asked for opinions. That's mine.", "aSentId": 58929, "answer": "OR just tell Bjarne that its better to break backward compatibility with C (or earlier versions of C++).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58930, "question": "OR just tell Bjarne that its better to break backward compatibility with C (or earlier versions of C++).", "aSentId": 58931, "answer": "&gt; break backward compatibility with C\n\nThey already do in many places. if they wanted to not break C compatibility, they should have prefix there keywords with an `@` sign, just light in Objective C.\n\n&gt; or earlier versions of C++\n\nOh please not. It sucks not being able to use a library because it's written against the wrong version of your language. So many wasted man-hours.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58932, "question": "&gt; break backward compatibility with C\n\nThey already do in many places. if they wanted to not break C compatibility, they should have prefix there keywords with an `@` sign, just light in Objective C.\n\n&gt; or earlier versions of C++\n\nOh please not. It sucks not being able to use a library because it's written against the wrong version of your language. So many wasted man-hours.", "aSentId": 58933, "answer": "The problem though is that a number of features are so badly designed they should really be deprecated. So new features have to cope with those, and eventually you end with a language so baroque you need to be a language lawyer to write libraries.\r\rI feel that the \"Within C++, there is a much smaller and cleaner language struggling to get out\" part got buried in layers of complexity long ago.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58934, "question": "The problem though is that a number of features are so badly designed they should really be deprecated. So new features have to cope with those, and eventually you end with a language so baroque you need to be a language lawyer to write libraries.\r\rI feel that the \"Within C++, there is a much smaller and cleaner language struggling to get out\" part got buried in layers of complexity long ago.", "aSentId": 58935, "answer": "&gt; I feel that the \"Within C++, there is a much smaller and cleaner language struggling to get out\" part got buried in layers of complexity long ago.\n\nThat's right. People are trying to extract that language (e.g. Rust), but they follow the Siren's call of \u201cmore features\u201d just like C++ did and they are probably going to end up with a language that is just as convoluted and complex.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58926, "question": "C++. I'd talk everyone out of developing it entirely. Hey, you asked for opinions. That's mine.", "aSentId": 58937, "answer": "C++ is such a mess, which is a shame since it's such a popular and powerful language", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58940, "question": "To me the answer is obvious: array bounds checking in C. Would have saved so many lives, no doubt. Certainly 10,000 person years @ $100k = $1b as a very conservative estimate, probably a few orders of magnitude more than that.", "aSentId": 58941, "answer": "Do you apply it to all pointer indexing or just explicitly arrays? To apply it to all pointer dereferences using the indexing syntax requires wrapping the pointer in a container that also contains the number of elements, which C has no native way to do, and forcing you to do it for all pointers is wasteful.\n\nIts pretty hard to index out of range of an actual array, you can always statically get the size of an array, and therefore know how many elements in it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58942, "question": "Do you apply it to all pointer indexing or just explicitly arrays? To apply it to all pointer dereferences using the indexing syntax requires wrapping the pointer in a container that also contains the number of elements, which C has no native way to do, and forcing you to do it for all pointers is wasteful.\n\nIts pretty hard to index out of range of an actual array, you can always statically get the size of an array, and therefore know how many elements in it.", "aSentId": 58943, "answer": "Personally I'd have it for all pointers by default with an option to wrap code in something like an unsafe{} block if you actually need it. \n\nI appreciate that would make c a *very* different language though.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58944, "question": "Personally I'd have it for all pointers by default with an option to wrap code in something like an unsafe{} block if you actually need it. \n\nI appreciate that would make c a *very* different language though.", "aSentId": 58945, "answer": "Go is that language.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58940, "question": "To me the answer is obvious: array bounds checking in C. Would have saved so many lives, no doubt. Certainly 10,000 person years @ $100k = $1b as a very conservative estimate, probably a few orders of magnitude more than that.", "aSentId": 58947, "answer": "No, please not. It's not possible to get that right in C and it would make a lot of programs a lot slower.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58948, "question": "No, please not. It's not possible to get that right in C and it would make a lot of programs a lot slower.", "aSentId": 58949, "answer": "Obviously you'd want to have an \"unsafe\" keyword like C# has for when you need performance.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58950, "question": "Obviously you'd want to have an \"unsafe\" keyword like C# has for when you need performance.", "aSentId": 58951, "answer": "Such keywords are kludges. I'm not particularly fond of them. Also, you miss the point with respect to C, which is often used for things close to the hardware.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58952, "question": "Such keywords are kludges. I'm not particularly fond of them. Also, you miss the point with respect to C, which is often used for things close to the hardware.", "aSentId": 58953, "answer": "Which is often the problem. Many low-level programs, such as O/S, have security bugs which are caused by the unsafe memory semantics.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58952, "question": "Such keywords are kludges. I'm not particularly fond of them. Also, you miss the point with respect to C, which is often used for things close to the hardware.", "aSentId": 58955, "answer": "What's wrong with adding unsafe blocks to c? Some syntax like:\n\n    unsafe {\n        // code\n    }\n\nWould fit well with c I think. It would make it way easier to find the bugs caused by doing bad stuff with memory as you could focus your efforts on the unsafe blocks.\n\nI guess you could have a compiler flag to disable the checks on a full program if you *really* needed to.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58957, "question": "This only a small one but it has been known to drive me nuts:\n\nHaskell: Make sure that \":\" stands for \"has the type\" and \"::\" stands for cons. You know, the right way around.", "aSentId": 58958, "answer": "I'd rather like it if `;` was cons.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58957, "question": "This only a small one but it has been known to drive me nuts:\n\nHaskell: Make sure that \":\" stands for \"has the type\" and \"::\" stands for cons. You know, the right way around.", "aSentId": 58960, "answer": "I think Haskell has some bigger issues than that though. Lazy IO by default can be confusing as hell for instance. Some things that are only available via GHC extensions should have been standard too, like BangPatterns for instance. Overall it's still the best language I've ever used though.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58964, "question": "C++\n\nAdd some pedantic flags to require braces for single statement loops/if statements.\n\nMultiDeclaration int* foo,bar;  should throw an error.and not make a damn int bar;\n\nNo Damn =  Have both \"assign\" and \"test\" as explicit := and == respectively\n\n\n\nfix the declaration vector &lt;vector &lt;int&gt;&gt; so it doesn't die on the &gt;&gt;\n\n\n\n", "aSentId": 58965, "answer": "The last one is fixed in either 11 or 14.  \n\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58967, "question": "Java:\n\nGive an easier mechanism for handling checked exceptions in lambdas and streams\n\nGet rid of checked exceptions\n\nNo type erasure\n\nAdd unsigned ", "aSentId": 58968, "answer": "I think type erasure is imposed mainly by the JVM. We would just need to start over with that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58972, "question": "C# - get rid of the UB around unchecked conversion from out-of-range doubles to ints. I don't even care what the result is, but it should at least be the same for constant expressions and expressions evaluated at runtime, in accordance with the Principle of Least Surprise.\n\nx86 assembly (does that count as a programming language with a \"design\"?) - ban AT&amp;T syntax before it is invented, or at least change the memory operand syntax to be more readable. Also add a bit-reversal instruction.\n\nC - no type-based aliasing rules. They've destroyed more than they have created. They don't work as intended (pointers passed to a function tend to be of the same type on average), and some implementations (I'm looking at you, GCC) treat it as the Word of God even in the face of type-punned pointers that are obviously statically *equal*. Again violating the Principle of Least Surprise.", "aSentId": 58973, "answer": "I actually like AT&amp;T-syntax. I find its memory operand syntax to be much easier to read. The only thing that sucks is the butchered operand order.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58974, "question": "I actually like AT&amp;T-syntax. I find its memory operand syntax to be much easier to read. The only thing that sucks is the butchered operand order.", "aSentId": 58975, "answer": "The memory syntax isn't too bad when you get used to it I suppose. But it doesn't actually say what the effective address is, you have to learn the structure before it makes sense. It generates a ton of questions (on SO and so on) from learners.\n\nBut easier, I find that very hard to believe. You can't immediately read off the address like you can with Intel syntax, because it just isn't there, only the parts are there with no connecting operators.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58976, "question": "The memory syntax isn't too bad when you get used to it I suppose. But it doesn't actually say what the effective address is, you have to learn the structure before it makes sense. It generates a ton of questions (on SO and so on) from learners.\n\nBut easier, I find that very hard to believe. You can't immediately read off the address like you can with Intel syntax, because it just isn't there, only the parts are there with no connecting operators.", "aSentId": 58977, "answer": "My problem with Intel syntax is that it does not distinguish between things the machine computes and things the assembler computes. This begins with register names having no prefix (so you can't distinguish them from symbols) and continues with expression syntax being reused for indirect addressing. For instance, the instruction `mov [a+b*c],d` could mean one of the following depending on what the macros `a`, `b`, `c`, and `d` are defined as:\n\n* If a, b, and c are constants or symbols, this is an indirect move to a fixed address which is computed either at assembling or linking time.\n* If either is a macro for a register, this might be a register-indirect move, with an addressing mode depending on which ones are registers.\n* Depending on what d is, this is either a move of a value, or a register.\n\nI don't like having to guess what is actually being moved. AT&amp;T syntax is much clearer in this regard and doesn't have problems with future registers being added. If I used a symbol called `ymm0` in my assembly before AVX came arround, my assembly won't assemble any more because the assembler now sees `ymm0` as a register instead of a symbol.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58978, "question": "My problem with Intel syntax is that it does not distinguish between things the machine computes and things the assembler computes. This begins with register names having no prefix (so you can't distinguish them from symbols) and continues with expression syntax being reused for indirect addressing. For instance, the instruction `mov [a+b*c],d` could mean one of the following depending on what the macros `a`, `b`, `c`, and `d` are defined as:\n\n* If a, b, and c are constants or symbols, this is an indirect move to a fixed address which is computed either at assembling or linking time.\n* If either is a macro for a register, this might be a register-indirect move, with an addressing mode depending on which ones are registers.\n* Depending on what d is, this is either a move of a value, or a register.\n\nI don't like having to guess what is actually being moved. AT&amp;T syntax is much clearer in this regard and doesn't have problems with future registers being added. If I used a symbol called `ymm0` in my assembly before AVX came arround, my assembly won't assemble any more because the assembler now sees `ymm0` as a register instead of a symbol.", "aSentId": 58979, "answer": "Ok, there is that. But the solution there is the prefixes for registers and constants, not the \"this tuple does some math but you can't tell what unless you already know\"-thing", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58980, "question": "Ok, there is that. But the solution there is the prefixes for registers and constants, not the \"this tuple does some math but you can't tell what unless you already know\"-thing", "aSentId": 58981, "answer": "Not quite. The solution is the combination of that and the usage of a distinct syntax for things the processor computes over things the assembler computes. If I write `a+b`, then I want to be sure that this is something the assembler computes, regardless of what `a` and `b` are. AT&amp;T-style operands do just that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58982, "question": "Not quite. The solution is the combination of that and the usage of a distinct syntax for things the processor computes over things the assembler computes. If I write `a+b`, then I want to be sure that this is something the assembler computes, regardless of what `a` and `b` are. AT&amp;T-style operands do just that.", "aSentId": 58983, "answer": "With prefixes for registers you can trivially tell the difference between the two different kinds of plus, one can only appear when neither operand is a register, and the other is for all other cases.\n\nTuple syntax is a disaster, but it could be improved at least, by making it strictly a summation of all the parts. Like (123, rax, rdx*2) or whatever. Still unclear though.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58984, "question": "With prefixes for registers you can trivially tell the difference between the two different kinds of plus, one can only appear when neither operand is a register, and the other is for all other cases.\n\nTuple syntax is a disaster, but it could be improved at least, by making it strictly a summation of all the parts. Like (123, rax, rdx*2) or whatever. Still unclear though.", "aSentId": 58985, "answer": "This doesn't work when you build or use macros as you can't tell what the macro argument is going to be. In your example how one could \u201cget right\u201d AT&amp;T-Syntax, you still have the same issue as before with the multiplication operator.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58986, "question": "This doesn't work when you build or use macros as you can't tell what the macro argument is going to be. In your example how one could \u201cget right\u201d AT&amp;T-Syntax, you still have the same issue as before with the multiplication operator.", "aSentId": 58987, "answer": "It doesn't get it right, it gets is slightly less hard to get the hang of. It's still broken, of course. It's fundamentally broken because it still doesn't show what the hell is going on, and it doesn't address your macro problem, which by the way I have never had. I guess I don't really use macros that way.\n\nPerhaps that could be fixed by allowing the register prefix to appear in macro argument names (which could then only take a register name as input).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58988, "question": "It doesn't get it right, it gets is slightly less hard to get the hang of. It's still broken, of course. It's fundamentally broken because it still doesn't show what the hell is going on, and it doesn't address your macro problem, which by the way I have never had. I guess I don't really use macros that way.\n\nPerhaps that could be fixed by allowing the register prefix to appear in macro argument names (which could then only take a register name as input).", "aSentId": 58989, "answer": "I prefer preserving orthogonality; that's why I like AT&amp;T-style memory operands.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58991, "question": "Prolog:  \n\nAdd inline expressions. I want foo(X) :- write(X), foo(X-1). rather than foo(X) :- write(X), X1 is X-1, foo(X1).  \nCompiled rather than interpreted.  \nI was going to mention typing, but there's some really neat libraries for that.\n\nI'm aware most everything is covered by Mercury, but the amount of libraries floating around for raw Prolog is great.", "aSentId": 58992, "answer": "I'm not sure how you would go about compiling Prolog.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58993, "question": "I'm not sure how you would go about compiling Prolog.", "aSentId": 58994, "answer": "SWI-Prolog is able to be 'compiled', but it's just (AFAIK) a bundled-in version of the interpreter.\n\nAnd I'm not sure how compilation wouldn't work. Mercury is, basically, entirely pure Prolog, and that's compiled. Then it's solely the impure elements - which would be assert and IO.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58998, "question": "Python with some Haskell/ml features such as type classes pattern matching lambdas that suck less etc.", "aSentId": 58999, "answer": "Functional programming in python? Ooh that sounds yummy!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59000, "question": "Functional programming in python? Ooh that sounds yummy!", "aSentId": 59001, "answer": "Pretty sure that the Benevolent Dictator of Python decreed that lambda can never suck less, nor will tail call optimization be added. Strong indicators that Python will not add many FP features anytime soon.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59002, "question": "Pretty sure that the Benevolent Dictator of Python decreed that lambda can never suck less, nor will tail call optimization be added. Strong indicators that Python will not add many FP features anytime soon.", "aSentId": 59003, "answer": "Actually, what I want is a mix of R and Python.... something like what PANDAS does", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58998, "question": "Python with some Haskell/ml features such as type classes pattern matching lambdas that suck less etc.", "aSentId": 59005, "answer": "I'd be so happy if python had the collections of clojure. Immutability by default + what you suggested is so much better. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 58998, "question": "Python with some Haskell/ml features such as type classes pattern matching lambdas that suck less etc.", "aSentId": 59007, "answer": "Don't forget better recursion. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59010, "question": "Java: get rid of primitives and replace them with objects.", "aSentId": 59011, "answer": "What would that accomplish?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59012, "question": "What would that accomplish?", "aSentId": 59013, "answer": "consistency. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59015, "question": "Having a native size type while all other sizes are of defined size in C.", "aSentId": 59016, "answer": "There is a native size type in C, it's called `size_t`.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59017, "question": "There is a native size type in C, it's called `size_t`.", "aSentId": 59018, "answer": "Yes, but char, short, int, long, long long, float, double, and long double are not guaranteed to be the same across platforms/architectures/compilers.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59019, "question": "Yes, but char, short, int, long, long long, float, double, and long double are not guaranteed to be the same across platforms/architectures/compilers.", "aSentId": 59020, "answer": "We've had `stdint.h` since C99.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59021, "question": "We've had `stdint.h` since C99.", "aSentId": 59022, "answer": "Right but this is about design at inception. How many library functions or system calls use stdint.h? Wasn't size_t also an after though?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59019, "question": "Yes, but char, short, int, long, long long, float, double, and long double are not guaranteed to be the same across platforms/architectures/compilers.", "aSentId": 59024, "answer": "Yes, because that's not possible.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59025, "question": "Yes, because that's not possible.", "aSentId": 59026, "answer": "Why not?", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59027, "question": "Why not?", "aSentId": 59028, "answer": "\u201cpossible\u201d as in \u201cis a good idea.\u201d C code is being written for platforms where bytes don't have eight bits or where a word has 36 bits, etc. The C standard has to take care of all of these.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59029, "question": "\u201cpossible\u201d as in \u201cis a good idea.\u201d C code is being written for platforms where bytes don't have eight bits or where a word has 36 bits, etc. The C standard has to take care of all of these.", "aSentId": 59030, "answer": "Perhaps int, long etc. could be defined multiples of char, where char is the smallest addressable unit. I would be happy with that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59031, "question": "Perhaps int, long etc. could be defined multiples of char, where char is the smallest addressable unit. I would be happy with that.", "aSentId": 59032, "answer": "Define \u201cmultiple.\u201d I'm not sure what that's supposed to mean. Right now, `char` is by definition the smallest addressable type. The size in bits of each other type is a multiple of the size of `char`, but some bits might be padding bits that cannot be used. For instance, this is the case for unsigned integers on some machines with a sign-and-magnitude representation: The sign bit is unused for unsigned integers but it still counts towards the size of the type.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59033, "question": "Define \u201cmultiple.\u201d I'm not sure what that's supposed to mean. Right now, `char` is by definition the smallest addressable type. The size in bits of each other type is a multiple of the size of `char`, but some bits might be padding bits that cannot be used. For instance, this is the case for unsigned integers on some machines with a sign-and-magnitude representation: The sign bit is unused for unsigned integers but it still counts towards the size of the type.", "aSentId": 59034, "answer": "A `short` would be twice the size of `char`, `int` four times, `long` six or eight times, and so on.\n\nPerhaps incorrectly, it seems to me that this would make portability easier on systems where portability is desirable. In this case I'm thinking different operating systems as well as architectures, x86, 64 bit x86, arm, sparc, unix, windows etc. An application using those integer types would then behave the same on all those platforms without having to worry that one of the integer types is a different size.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59035, "question": "A `short` would be twice the size of `char`, `int` four times, `long` six or eight times, and so on.\n\nPerhaps incorrectly, it seems to me that this would make portability easier on systems where portability is desirable. In this case I'm thinking different operating systems as well as architectures, x86, 64 bit x86, arm, sparc, unix, windows etc. An application using those integer types would then behave the same on all those platforms without having to worry that one of the integer types is a different size.", "aSentId": 59036, "answer": "This won't cut it. For instance, on DSPs it's common that `char`, `short`, `int`, and `long` are the same 36 bit type or alternatively `char` is an 8 bit type and both `short` and `int` are 36 bit types. Types having different sizes is an old problem and it takes skill to program with types of variable sizes, but it makes your code much more efficient when the target ABI can pick a type for `int` that is actually reasonably fast on the target platform. For instance, quite a few 64 bit architectures do not provide instructions to do 32 bit arithmetic. If an `int` had 32 bit on such an architecture, that would be horrible. C is designed in a way that all arithmetic operations are done on types no smaller than an `int` so C can be compiled on such platforms into efficient programs. It's a bad idea to loose all of that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59037, "question": "This won't cut it. For instance, on DSPs it's common that `char`, `short`, `int`, and `long` are the same 36 bit type or alternatively `char` is an 8 bit type and both `short` and `int` are 36 bit types. Types having different sizes is an old problem and it takes skill to program with types of variable sizes, but it makes your code much more efficient when the target ABI can pick a type for `int` that is actually reasonably fast on the target platform. For instance, quite a few 64 bit architectures do not provide instructions to do 32 bit arithmetic. If an `int` had 32 bit on such an architecture, that would be horrible. C is designed in a way that all arithmetic operations are done on types no smaller than an `int` so C can be compiled on such platforms into efficient programs. It's a bad idea to loose all of that.", "aSentId": 59038, "answer": "After trying to come up with a couple examples. I realize I haven't given it enough thought. Would have never thought twice about using an `int` in the following (I would actually since 32 bit ints are widely used, but just for the sake of argument)\n    \n    // (2^32)/2 + 1\n    for (int i = 0; i &lt; 2147483648; i++) ;\n\nMy thought before this was \"it's dumb that this might not work on machines where `int`s are 4 bytes but will work where it's bigger.\" Never even considered `int`s are only guaranteed [\u221232767,+32767] and\n\n    for (int i = 0; i &lt; 50000; i++) ;\n\nisn't good C.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59039, "question": "After trying to come up with a couple examples. I realize I haven't given it enough thought. Would have never thought twice about using an `int` in the following (I would actually since 32 bit ints are widely used, but just for the sake of argument)\n    \n    // (2^32)/2 + 1\n    for (int i = 0; i &lt; 2147483648; i++) ;\n\nMy thought before this was \"it's dumb that this might not work on machines where `int`s are 4 bytes but will work where it's bigger.\" Never even considered `int`s are only guaranteed [\u221232767,+32767] and\n\n    for (int i = 0; i &lt; 50000; i++) ;\n\nisn't good C.", "aSentId": 59040, "answer": "POSIX sort of guarantees that an `int` has 32 bits and that two's-complement is used. That's generally a good assumption to make when writing software for hosted environments. It's just that the C language itself must be applicable to much broader use-cases.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59044, "question": "Uh, how has no one mentioned pascal: not allowing null to inhabit all types yet?", "aSentId": 59045, "answer": "Pascal is an accident that shouldn't ever have happened.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59047, "question": "Go back to the beginning, and kick everyone who thought to create their own separate language in the nads.\n\nWe have too many damn languages and libraries that attempt to reinvent the wheel. We need one language and a concrete modular library system. It all gets converted to machine code in the end. . . \n\nFor example, if I need an MD5 hashing algorithm, I simply load the Hash::MD5 library. If I need to do some matrix math, I load the Math::Matrix library. No choosing between all the math libraries available and still having to implement my own wrapper.\n\nmeh, I just get upset when I need something in my programs and find that I either have to implement it myself from scratch, or use two or three different libraries that all implement the same functions, to get one or two features I need.\n", "aSentId": 59048, "answer": "Now imagine that the person who created your MD5 hashing library and Matrix multiplication library had a crap implementation, but he also was the loudest voice in the room, so you're stuck with it.\n\nIt's good to have some variety.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59049, "question": "Now imagine that the person who created your MD5 hashing library and Matrix multiplication library had a crap implementation, but he also was the loudest voice in the room, so you're stuck with it.\n\nIt's good to have some variety.", "aSentId": 59050, "answer": "You see that is the beauty of computer science. . . any computer scientist worth his salt would know that it is a crap implementation and be able to logically prove without a doubt that it is such, and thus get the algorithm rewritten.\n\nYou push the update to all systems running the single library and voila all applications that use that algorithm are suddenly running that much better.\n\nNow, if there were two algorithms that performed the same operation in different ways, but neither could definitively be proven to be significantly better than the other. . .then we throw a little configuration option into the code to choose one or the other. If proof can be provided later, we just ignore or override the option and use the optimal algorithm.\n\nAnyway, my point is we should start using science, not rhetoric (had to take that upper level english course for my degree), to decide what is best.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59052, "question": "C# : Destroy Nullalbles completely, just remove them.  They cause more trouble than they are worth.\n\nOkay, instead of checking for null you check for .hasValue or something.  Plus they are only used half the time.", "aSentId": 59053, "answer": "Null pointers are extremely useful for many purposes because they give a pointer type a natural zero value and they allow you to model \u201cno object\u201d in an efficient way.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59055, "question": "ITT: People who don't understand design goals of existing languages.", "aSentId": 59056, "answer": "You could at least have the decency to explain *why* unsigned numeric types are contrary to the design goals of Java, why 0-based indexing and foreach loops are contrary to the design goals of R, why pattern matching is contrary to the design goals of Python, etc.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59057, "question": "You could at least have the decency to explain *why* unsigned numeric types are contrary to the design goals of Java, why 0-based indexing and foreach loops are contrary to the design goals of R, why pattern matching is contrary to the design goals of Python, etc.", "aSentId": 59058, "answer": "Other people already did this for me.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59055, "question": "ITT: People who don't understand design goals of existing languages.", "aSentId": 59060, "answer": "&gt; Everything is great, programming language design is solved!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59061, "question": "&gt; Everything is great, programming language design is solved!", "aSentId": 59062, "answer": "We did it guys!", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59064, "question": "Looking for a particular type of IDE/Features", "aSentId": 59065, "answer": "Emacs with projectile mode.\n\nInstall it from homebrew though.  The emacs built into OS X is very very old.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59064, "question": "Looking for a particular type of IDE/Features", "aSentId": 59067, "answer": "I tried sublime text 3, while it has the open by folder feature which is great, along with C/C++ Linting. It's go to defenition feature pretty much doesnt work.\n\nSure there is Xcode, IntelliJ products and the like, but none of them allow me to open an arbitary code project, and I'm forced to create something under their structure.\n\nI would like to use Eclipse, however, it ends up creating so much junk within my folders. It's an open source project so this is going to be painful", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59068, "question": "I tried sublime text 3, while it has the open by folder feature which is great, along with C/C++ Linting. It's go to defenition feature pretty much doesnt work.\n\nSure there is Xcode, IntelliJ products and the like, but none of them allow me to open an arbitary code project, and I'm forced to create something under their structure.\n\nI would like to use Eclipse, however, it ends up creating so much junk within my folders. It's an open source project so this is going to be painful", "aSentId": 59069, "answer": "Sublime text 3 go to def works for me. Be sure to have all sources in the project. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59071, "question": "Implementing OOP With Type Erasure", "aSentId": 59072, "answer": "On Type Erasure:  The point of type erasure is to take advantage of the uniform representation of pointers to get type-safe polymorphic functions without generating specialized code for each type. But for this to give any benefit over vtable-style polymorphism, your type-erasing containers have to contain only a single type and perform a reinterpret-cast from a void * to a T * when members are accessed.\n\nYour example has a heterogenous vector of various types that all happen to share an interface, which means they've got to have VTables to get the correct implementation for their type. Rather than simply having a vector of objects with VTables, you're making a vector of \"wrapper\" objects that have VTable functions that point to fake VTables and also point to externally stored real objects. So you've got extra run-time indirection and extra storage overhead for all the pointers. The only time I can imagine this making sense is when there are very strict representation restrictions on the data; i.e. it's shared with another process that doesn't understand your VTable or something. \n\nI don't know, maybe I'm missing something about what you're doing or C++ is working even more differently these days than I recall, but this doesn't seem to be something of very wide usefulness.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59073, "question": "On Type Erasure:  The point of type erasure is to take advantage of the uniform representation of pointers to get type-safe polymorphic functions without generating specialized code for each type. But for this to give any benefit over vtable-style polymorphism, your type-erasing containers have to contain only a single type and perform a reinterpret-cast from a void * to a T * when members are accessed.\n\nYour example has a heterogenous vector of various types that all happen to share an interface, which means they've got to have VTables to get the correct implementation for their type. Rather than simply having a vector of objects with VTables, you're making a vector of \"wrapper\" objects that have VTable functions that point to fake VTables and also point to externally stored real objects. So you've got extra run-time indirection and extra storage overhead for all the pointers. The only time I can imagine this making sense is when there are very strict representation restrictions on the data; i.e. it's shared with another process that doesn't understand your VTable or something. \n\nI don't know, maybe I'm missing something about what you're doing or C++ is working even more differently these days than I recall, but this doesn't seem to be something of very wide usefulness.", "aSentId": 59074, "answer": "While you do now have a vtable pointer inside of the wrapper object, you no longer have a vtable pointer inside of the object itself.  So unless you have more than one pointer to the object, then you've broken even on memory.  Also if your object has more complex inheritance than simple single inheritance, you've won on memory consumption.   \n\nI'm not sure what you mean by fake vtable - it's the same as a normal vtable, with the normal space complexity.  It's also the same number of indirections.\n\nThe point of this is to take off the burden of declaring what interfaces when you declare your class, just like how you can do\n\n    std::function &lt;int (int) &gt; intFunc = [=](int i){return i + 42;};\n\nExcept extended further.\n", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59071, "question": "Implementing OOP With Type Erasure", "aSentId": 59076, "answer": "I think that dynamic casts are going to be a lot harder using this system. As long as the dynamic cast can dynamically generate a new vtable at runtime by reflecting on the object and interface, you're fine but traditional oo has avoided this by calculating all available vtables in the same compilation unit as the class, making dynamic casts possible.\n\nOn the other hand, golang uses a similar strategy, so maybe it's not so hard after all. I hope it's not, because I really like this idea a lot.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59077, "question": "I think that dynamic casts are going to be a lot harder using this system. As long as the dynamic cast can dynamically generate a new vtable at runtime by reflecting on the object and interface, you're fine but traditional oo has avoided this by calculating all available vtables in the same compilation unit as the class, making dynamic casts possible.\n\nOn the other hand, golang uses a similar strategy, so maybe it's not so hard after all. I hope it's not, because I really like this idea a lot.", "aSentId": 59078, "answer": "You can do this at compile time if for each base class you precalculate all interfaces it supports.  For runtime use then you can have a \n    \n    struct ReflectData\n    {\n       std::unordered_map&lt;TypeIndex, void*&gt; vtableLookup;\n    };\n    \nSo it's\n    \n    template &lt;typename FromType, typename ToType&gt;\n    ToType dynamicCast(FromType from)\n    {\n       if (!from.data) return nullptr;\n       ReflectData* baseTypeReflData = from-&gt;vtable-&gt;reflectData;\n       auto newVtable =  baseTypeReflData-&gt;vtableLookup.find(TypeIndexOf&lt;ToType&gt;::get());\n       if (newVtable == baseTypeReflData-&gt;vtableLookup.end()) return nullptr; //no conversion\n       return ToType(newVtable.second, from.data);  //memory management blah blah\n    }\n    \nYou only have to calculate this for types that dynamicCast is being called on, and it's a hash so each type shouldn't have too many children.  There might be a cleaner way, but it feels solvable.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59079, "question": "You can do this at compile time if for each base class you precalculate all interfaces it supports.  For runtime use then you can have a \n    \n    struct ReflectData\n    {\n       std::unordered_map&lt;TypeIndex, void*&gt; vtableLookup;\n    };\n    \nSo it's\n    \n    template &lt;typename FromType, typename ToType&gt;\n    ToType dynamicCast(FromType from)\n    {\n       if (!from.data) return nullptr;\n       ReflectData* baseTypeReflData = from-&gt;vtable-&gt;reflectData;\n       auto newVtable =  baseTypeReflData-&gt;vtableLookup.find(TypeIndexOf&lt;ToType&gt;::get());\n       if (newVtable == baseTypeReflData-&gt;vtableLookup.end()) return nullptr; //no conversion\n       return ToType(newVtable.second, from.data);  //memory management blah blah\n    }\n    \nYou only have to calculate this for types that dynamicCast is being called on, and it's a hash so each type shouldn't have too many children.  There might be a cleaner way, but it feels solvable.", "aSentId": 59080, "answer": "It's only simple when you do full-program analysis. For a number of reasons (closed source, incremental builds, dynamic linking) we don't really do full-program analysis anymore (except at runtime in the JVM). This is why golang can pull it off but most languages wouldn't be able to handle it.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59081, "question": "It's only simple when you do full-program analysis. For a number of reasons (closed source, incremental builds, dynamic linking) we don't really do full-program analysis anymore (except at runtime in the JVM). This is why golang can pull it off but most languages wouldn't be able to handle it.", "aSentId": 59082, "answer": "Oh of course, right you are.  That's ugly, I guess you would have to do something tricky.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59071, "question": "Implementing OOP With Type Erasure", "aSentId": 59084, "answer": "Your implementation looks like more general to support vtable, by which I mean, you can assign/move Ball to Renderable even if it isn't a subclass of Renderable, Renderable can be a delegation for calling render on any types having RendererVTableImpl implemented, there doesn't need to have any inheritance relationship. For vtable, compilers pretty much do the same thing, when vtable is needed( having virutal function or virtual base class), compiler automatically insert pointer to vtable at the beginning of the object. This is exactly the same as you did, if Ball is a subclass of Renderable, because if you look into the memory layout of a Ball object, at the beginning of the object should be a Renderable object, at the begining of the Renderable object, you have a vtable, so in turn any object of Ball will have a vtable. Only if Ball is not a subclass of Renderable, as I said before, more generally, this doesn't hold. \n\nActually there is one big different between your implementation and compiler inserted vtable. In order to call virtual function from vtable, one has to use pointer or reference, if call a function use an object itself, there will be no vtable involved, if you look into the compiled assembly code, that will be a directly jump to the address of the function, this could be some performance benefit, if programmer explicitly say I want to call this function, no need vtable involved. And this cannot be achieved with your implementation, which losing some kind of flexibility. ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59085, "question": "Your implementation looks like more general to support vtable, by which I mean, you can assign/move Ball to Renderable even if it isn't a subclass of Renderable, Renderable can be a delegation for calling render on any types having RendererVTableImpl implemented, there doesn't need to have any inheritance relationship. For vtable, compilers pretty much do the same thing, when vtable is needed( having virutal function or virtual base class), compiler automatically insert pointer to vtable at the beginning of the object. This is exactly the same as you did, if Ball is a subclass of Renderable, because if you look into the memory layout of a Ball object, at the beginning of the object should be a Renderable object, at the begining of the Renderable object, you have a vtable, so in turn any object of Ball will have a vtable. Only if Ball is not a subclass of Renderable, as I said before, more generally, this doesn't hold. \n\nActually there is one big different between your implementation and compiler inserted vtable. In order to call virtual function from vtable, one has to use pointer or reference, if call a function use an object itself, there will be no vtable involved, if you look into the compiled assembly code, that will be a directly jump to the address of the function, this could be some performance benefit, if programmer explicitly say I want to call this function, no need vtable involved. And this cannot be achieved with your implementation, which losing some kind of flexibility. ", "aSentId": 59086, "answer": "Well, you can still use the object itself here, and it'll work just the same?  Also devirtualization is often trivial, I'm thinking something like\n\n    void sort(RandomAccessContainer container){...}\n    \n    std::vector&lt;int&gt; test = {1,4,3,2,6};\n    sort(test);  //somehow make this a reference... but you get the idea\n\nIt would be a very easy optimization to make an implementation of sort for vector&lt;int&gt;.  This is true for regular interfaces as well, but this goes a tad bit further.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59087, "question": "Well, you can still use the object itself here, and it'll work just the same?  Also devirtualization is often trivial, I'm thinking something like\n\n    void sort(RandomAccessContainer container){...}\n    \n    std::vector&lt;int&gt; test = {1,4,3,2,6};\n    sort(test);  //somehow make this a reference... but you get the idea\n\nIt would be a very easy optimization to make an implementation of sort for vector&lt;int&gt;.  This is true for regular interfaces as well, but this goes a tad bit further.", "aSentId": 59088, "answer": "Only speaking c++, I think your solution valid for a good reason. But when it come to super/sub class, there is really no much difference between what compiler add and your implementation(though standard doesn't say anything about how to implementation virtual function). In your example of sort, c++ already provide the ability to do compiling time polymorphic through template, so why go for runtime polymorphic. But the language itself really doesn't stop you doing thing like that. Just like scala has implicit for type class, it is possible to implement the same with more verbose syntax in c++ without the syntax sugar.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59091, "question": "What Kind of Specs for College?", "aSentId": 59092, "answer": "/r/suggestapc", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59091, "question": "What Kind of Specs for College?", "aSentId": 59094, "answer": "Consider this part of your course and understand why certain things are bottlenecks. It will stand to you. Psst, it's usually IO.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59096, "question": "Complexity theory isn\u2019t required to be a programmer", "aSentId": 59097, "answer": "This guy seems to be completely missing the point of why you learn about complexity in school. You don't learn complexity theory to summarize an algorithm poorly, you learn it so you understand the decisions you make and when to be concerned about them.\n\nIn his example of his daily use-case, he is choosing that list with brute-force comparisons, but he's doing that with full knowledge of the actual complexity of that operation and the knowledge of why that's okay to do in that situation. He says he is regularly choosing the 'correct API' to do things. When it comes to data structures, there are MANY possibilities to choose from, and without knowing the tradeoffs you're dealing with (insert, lookup, storage cost, etc) you're just choosing blindly.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59096, "question": "Complexity theory isn\u2019t required to be a programmer", "aSentId": 59099, "answer": "The vast majority of programmers are employed at a level where they serve to make glue code.  The vast majority of programmers are employed to do the things the more valuable employees would be wasted doing.\n\nSo no,  most of them don't need to know about complexity theory.\n\nNow an architect, researcher, lead developer, etc.  those guys need to know their complexity theory.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59096, "question": "Complexity theory isn\u2019t required to be a programmer", "aSentId": 59101, "answer": "&gt;How does the algorithm perform given the layers of caching in the CPU? I\u2019m sure many of us have thought about this before, and even designed algorithms around this. I\u2019m however still not aware of how to properly integrate this with complexity theory. I know there is cache-aware analysis, but the topic isn\u2019t widely covered it seems.\n\nCache obliviousness is all the rage right now if you look at papers about data structures.\n\nAnd, no, I don't know enough about that stuff to do a formal analysis, either, especially when it comes to amortising. But I know enough about it to make informed decisions, and judge approaches *before* I implement them. Because, you know, you can't benchmark every algorithm under the sun.\n\nYou should definitely have an *informal*, but thorough, understanding of it. When some paper speaks about it none of the terminology should be alien, or shallow, to you.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59102, "question": "&gt;How does the algorithm perform given the layers of caching in the CPU? I\u2019m sure many of us have thought about this before, and even designed algorithms around this. I\u2019m however still not aware of how to properly integrate this with complexity theory. I know there is cache-aware analysis, but the topic isn\u2019t widely covered it seems.\n\nCache obliviousness is all the rage right now if you look at papers about data structures.\n\nAnd, no, I don't know enough about that stuff to do a formal analysis, either, especially when it comes to amortising. But I know enough about it to make informed decisions, and judge approaches *before* I implement them. Because, you know, you can't benchmark every algorithm under the sun.\n\nYou should definitely have an *informal*, but thorough, understanding of it. When some paper speaks about it none of the terminology should be alien, or shallow, to you.", "aSentId": 59103, "answer": "Just to be clear, cache obliviousness isnt about ignoring cache. I think perhaps cache agnostic may be a better phrase.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59104, "question": "Just to be clear, cache obliviousness isnt about ignoring cache. I think perhaps cache agnostic may be a better phrase.", "aSentId": 59105, "answer": "The long term should be \"cache configuration oblivious\". That is, they're cache-aware algorithms that are *so* cache aware that they ceased to have to care about the number of levels, sizes etc. because they work the cache perfectly no matter its configuration. They work by harnessing the divinity of mathematical unicorns: Having grasped the fundamental truths about the universe, they are unfettered by earthly matters.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59111, "question": "Thoughts on the Relationship between Optimization and Decision Problems", "aSentId": 59112, "answer": "In many (traditional) cases binary search usually provides the most effective reduction from decision problem to optimization problem.  However I'm sure there are more exotic complexity classes where this doesn't work.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59113, "question": "In many (traditional) cases binary search usually provides the most effective reduction from decision problem to optimization problem.  However I'm sure there are more exotic complexity classes where this doesn't work.", "aSentId": 59114, "answer": "And if you, OP, add \"binary search\" to your Google searches you'll probably find some informative sources.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59111, "question": "Thoughts on the Relationship between Optimization and Decision Problems", "aSentId": 59116, "answer": "Going from decision to optimization is kind of trivial... decision version: \"can we do X?\" -&gt; optimization version: find the optimum solution and check if it subsumes X.\n\nFor a concrete example: \"is this 3-SAT instance satisfiable?\" -&gt; \"what is the maximum number of satisfiable clauses?\" and check if it's all of them.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59118, "question": "My Master's program capstone project: The M Programming Language (feedback welcome)", "aSentId": 59119, "answer": "You might want to pick a new name. M is shorthand for MUMPS, which is a language that already exists.\n\nNot trying to sound snarky- i don't have strong enough compsci skills to offer constructive feedback on the language itself (im sure its excellent!)", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59120, "question": "You might want to pick a new name. M is shorthand for MUMPS, which is a language that already exists.\n\nNot trying to sound snarky- i don't have strong enough compsci skills to offer constructive feedback on the language itself (im sure its excellent!)", "aSentId": 59121, "answer": "Not snarky at all.  M stands for 'module' in this instance, a major concept of my language and primary influence on its namesake, just to clarify. I did a bit of a search online ahead of time and honestly did not come up with MUMPS (which I had heard of, due to its clever built-in database ideas), but I did not know MUMPS was also known as M. \n\nTL;DR Thanks, I didn't know that.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59122, "question": "Not snarky at all.  M stands for 'module' in this instance, a major concept of my language and primary influence on its namesake, just to clarify. I did a bit of a search online ahead of time and honestly did not come up with MUMPS (which I had heard of, due to its clever built-in database ideas), but I did not know MUMPS was also known as M. \n\nTL;DR Thanks, I didn't know that.", "aSentId": 59123, "answer": "Comes up as the second link in google for \"m programming language\" Wikipedia page for mumps. \"MUMPS (Massachusetts General Hospital Utility Multi-Programming System) or alternatively M, is a general-purpose computer programming language that...\"", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59118, "question": "My Master's program capstone project: The M Programming Language (feedback welcome)", "aSentId": 59125, "answer": "I'd like to see why I should use M over any of the other learning choices (Python/Java/PHP). It's covered in the first two pages of your design document, but not the GitHub page, which is where most people will be looking, I think.\n\nI also see that some choices were deliberate and that you call this a \"toy\" language, but I personally find the choice to use `end` instead of curly braces very confusing. Same with `elsif` over `else if` or `elif`. For a learner, I think `else if` is more explicit and also parses easier for an interpreter.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59126, "question": "I'd like to see why I should use M over any of the other learning choices (Python/Java/PHP). It's covered in the first two pages of your design document, but not the GitHub page, which is where most people will be looking, I think.\n\nI also see that some choices were deliberate and that you call this a \"toy\" language, but I personally find the choice to use `end` instead of curly braces very confusing. Same with `elsif` over `else if` or `elif`. For a learner, I think `else if` is more explicit and also parses easier for an interpreter.", "aSentId": 59127, "answer": "Thanks for the feedback. Your first point is great regarding design rationale info more easily-attainable. I've made note, and will work it into the next Github/blog/tutorial edit I do.\n\nRegarding the use of `elsif`: I adopted the Ruby keyword for its implementation. Since I needed to narrow influence on the language down to a few concrete languages, and since Ruby was chosen to impact syntax in a high-level-scripting-style-coding-kind-of-way, I figured why not take its `elsif` as well? The same goes for choosing the `end` keyword over braces.\n\nSince many new(-ish, or perceived as \"new\") HLLs tend toward keyword-delimited blocks (or whitepsace-assisted, as in Python), I thought that would be a nice way to update a C descendant. At least, that's my reasoning; whether its sound or not is open to interpretation.\n\nThanks for taking the time to look over things and comment. Much appreciated.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59118, "question": "My Master's program capstone project: The M Programming Language (feedback welcome)", "aSentId": 59129, "answer": "What does this bring to the table that other languages don't? Not being snarky, I want your rationale.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59131, "question": "Do you have the SOS defined for the language somewhere? And the type safety proof? I'd like to check those out if you have them.", "aSentId": 59132, "answer": "I do not, at this point. As a single-semester project, my prof laid out what he thought was reasonable to expect from me, which was a design doc, programmer documentation, a tutorial, a test suite, a compiler, and a journal-style paper after-the-fact. I would like to entertain these on my own, however. Thank you for the offer.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59133, "question": "I do not, at this point. As a single-semester project, my prof laid out what he thought was reasonable to expect from me, which was a design doc, programmer documentation, a tutorial, a test suite, a compiler, and a journal-style paper after-the-fact. I would like to entertain these on my own, however. Thank you for the offer.", "aSentId": 59134, "answer": "Well if you'd like help defining the language formally I think I would have a lot of fun doing that (and I'm far from good at it-- I'm just a Programming Languages undergrad). ", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59135, "question": "Well if you'd like help defining the language formally I think I would have a lot of fun doing that (and I'm far from good at it-- I'm just a Programming Languages undergrad). ", "aSentId": 59136, "answer": "I'll send you a PM", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59138, "question": "Designing programming languages are cool. I'm taking a compiler construction course, and I'm getting reall close to being able to do it myself.\n\nWondering why you used polish notation for a beginner's language", "aSentId": 59139, "answer": "Probably for disambiguation. This is a valid statement in C++: f = g+++h; But what does it do?\n\nI'd prefer Reverse Polish, but whatever.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59138, "question": "Designing programming languages are cool. I'm taking a compiler construction course, and I'm getting reall close to being able to do it myself.\n\nWondering why you used polish notation for a beginner's language", "aSentId": 59141, "answer": "I'm just a fan of RPN, and since I probably won't design and implement many languages in my life, I wanted to use it. Bad rationale, maybe, but it's the truth.\n\nRPN just makes sense to me... I see a `+` and I know it's time to add. Add what? the next couple of numbers. Lisp has had a huge impact on the way I look at languages, and I wish I had learned it first.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59142, "question": "I'm just a fan of RPN, and since I probably won't design and implement many languages in my life, I wanted to use it. Bad rationale, maybe, but it's the truth.\n\nRPN just makes sense to me... I see a `+` and I know it's time to add. Add what? the next couple of numbers. Lisp has had a huge impact on the way I look at languages, and I wish I had learned it first.", "aSentId": 59143, "answer": "Sorry for the pedantry, but RPN stands for *reverse* Polish notation which is postfix. You have regular, non-reverse Polish notation. I think it's much clearer to just call it prefix, infix and postfix notation...\n\nI personally think they are all fine, but I think that infix would be easier for new programmers. It's what they're used to from math/arithmetic, and now it's another thing to remember. I think it makes more sense in Lisp, because arithmetic operators and other functions are treated the same way, but the notation in M is still different (`plus(a,b)` vs. `+ a b`).", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59144, "question": "Sorry for the pedantry, but RPN stands for *reverse* Polish notation which is postfix. You have regular, non-reverse Polish notation. I think it's much clearer to just call it prefix, infix and postfix notation...\n\nI personally think they are all fine, but I think that infix would be easier for new programmers. It's what they're used to from math/arithmetic, and now it's another thing to remember. I think it makes more sense in Lisp, because arithmetic operators and other functions are treated the same way, but the notation in M is still different (`plus(a,b)` vs. `+ a b`).", "aSentId": 59145, "answer": "Oh, wow, oversight. I meant Polish, not RPN. Bad habit, thanks for clarifying.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59144, "question": "Sorry for the pedantry, but RPN stands for *reverse* Polish notation which is postfix. You have regular, non-reverse Polish notation. I think it's much clearer to just call it prefix, infix and postfix notation...\n\nI personally think they are all fine, but I think that infix would be easier for new programmers. It's what they're used to from math/arithmetic, and now it's another thing to remember. I think it makes more sense in Lisp, because arithmetic operators and other functions are treated the same way, but the notation in M is still different (`plus(a,b)` vs. `+ a b`).", "aSentId": 59147, "answer": "The reason I think infix would have been better is that you have  \n&gt; a + (b + c) = (a + b) + c  \n\nand so you write  \n&gt; a + b + c.\n\nBut with a prefix + you have  \n&gt; \\+ a (+ b c) = + (+ a b) c  \n\nand there you write... what? the problem is that the expressions are different even without the parentheses. So you must be forced to choose between them, arbitrarily. \u0010The fewer arbitrary choices one is forced to make the more elegant things end up.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59150, "question": "Why did you change the name from Escalang?  I kinda liked that better.\n\nI can't immediately see what you changed from that thread.", "aSentId": 59151, "answer": "Ha... thanks for noticing.\n\nThe major changes are a better syntax, fewer built-in keywords with off-loading of operations to libraries, removal of objects altogether, using fewer sigils... basically I simplified and tried to do a few things half-decently well, instead of doing everything rather poorly. Led to cohesion.\n\nAnd I'm actually using Escalang as the name of the language I am also designing based on the lessons learned in this project, which is to be a bit more \"conventional\" in nature, and compile directly to bytecode.\n\nThanks for the comment, and for looking.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59153, "question": "Do you have standard data structures such as lists, queues, and all that? It's a pain in the neck having to rewrite things all the time as you do in C, and makes other languages with these built in or as part of their standard library a lot friendlier to use.", "aSentId": 59154, "answer": "I should have explained this better, and will shoe-horn this into my documents afterward, but the reason for one structure was 2 fold: \n1- It was based on Lisp's approach to this topic (I was to choose a few languages to emulate the \"good\" parts of), and \n2 - It encourages exploration and learning on the part of potential students or new programmers by using the list to write their own additional structures (again, in the Lisp way...). \nThat's my rationale, whether or not it's solid.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59155, "question": "I should have explained this better, and will shoe-horn this into my documents afterward, but the reason for one structure was 2 fold: \n1- It was based on Lisp's approach to this topic (I was to choose a few languages to emulate the \"good\" parts of), and \n2 - It encourages exploration and learning on the part of potential students or new programmers by using the list to write their own additional structures (again, in the Lisp way...). \nThat's my rationale, whether or not it's solid.", "aSentId": 59156, "answer": "Regardless of desire for purity or pedagogy, having stacks, queues, hashmaps and such in the standard library for your language is a must if you want anyone to teach in it, let alone use it for their own programming.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59157, "question": "Regardless of desire for purity or pedagogy, having stacks, queues, hashmaps and such in the standard library for your language is a must if you want anyone to teach in it, let alone use it for their own programming.", "aSentId": 59158, "answer": "Yeah I have to agree. There's only so much you can teach about making your own data structures.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59160, "question": "Small typo in Reference Manual:  \n\n*  Page 12: \"Expressions come in a number flavors\"  \n\nThe manual could use a few less commas, and the section on escaping string literals is a bit anemic.  Other than that, looks good.\n\nNice job.", "aSentId": 59161, "answer": "Nice catch, and thanks for the other input. I've been told many times that my writing is way too comma-heavy.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59163, "question": "I have used quite a few languages (and designed two myself a long time ago) and one behavior I have used in every language, but which may not be possible in yours is quickly commenting out a function implementation to debug something or prevent behavior in an environment that I know will not work right now.\n\n\n\nmodule foo(int x)\n\n   # going to comment out the below item to debug something...\n\n   # stdio.putl(x);\n\nend\n\n\n\n\n\nIf I read your syntax right, moment I do that, the function just became a data structure?  What happens to code that was calling it, do they get an error?", "aSentId": 59164, "answer": "This is a great point, and something that I had not at all considered. I don't have an answer right now, but it's something I will clearly have to investigate.\n\nThe power of extra eyes... thank you.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59165, "question": "This is a great point, and something that I had not at all considered. I don't have an answer right now, but it's something I will clearly have to investigate.\n\nThe power of extra eyes... thank you.", "aSentId": 59166, "answer": "A possible elegant solution is to make everything a data structure with a default initializer.  If your module supplies an implementation, then that code is executed after the initializer.\n\nSo if you make a call:\nfoo(\"Bob\", 42\");\n\nand foo is defined as:\n\nmodule foo(name, age)\n\nstdio.putl(name);\n\nstdio.putl(age);\n\nend\n\n\nWhat happens is foo is created with name and age set by the initializer and then the implementation is called.\n\nIf there is no implementation, then you just initialized your data structure.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59167, "question": "A possible elegant solution is to make everything a data structure with a default initializer.  If your module supplies an implementation, then that code is executed after the initializer.\n\nSo if you make a call:\nfoo(\"Bob\", 42\");\n\nand foo is defined as:\n\nmodule foo(name, age)\n\nstdio.putl(name);\n\nstdio.putl(age);\n\nend\n\n\nWhat happens is foo is created with name and age set by the initializer and then the implementation is called.\n\nIf there is no implementation, then you just initialized your data structure.", "aSentId": 59168, "answer": "This is nice, I'll have to play with it. Appreciate the insight.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59170, "question": "I'm not sure why you use `with` as a keyword instead of `import`, where all the informal explanations that you give about `with` mention that it is used to import stuff. Why not directly use `import` then? Plus `with` is a rather common word which you may want to add as a different keyword in future language extensions.", "aSentId": 59171, "answer": "A perfectly valid point. Thank you.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59173, "question": "The no global variable bit reminds me of Gilad Bracha's work. Now I'm reading your thesis.", "aSentId": 59174, "answer": "Just to be clear, it's only a one semester project, and so the paper isn't a thesis... I don't mean to be a prick, just trying to temper expectations in regard to the design document. I do understand what your comment is referring to, however, and appreciate the interest, and your taking the time.\n\nHowever, I do hope to test this out afterward in a high school programming setting, after which a paper would follow that would be much closer to a thesis.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59176, "question": "Why just one data structure?   That seems to be a huge limitation.   ", "aSentId": 59177, "answer": "I should have explained this better, and will shoe-horn this into my documents afterward, but the reason for one structure was 2 fold: \n1- It was based on Lisp's approach to this topic (I was to choose a few languages to emulate the \"good\" parts of), and \n2 - It encourages exploration and learning on the part of potential students or new programmers by using the list to write their own additional structures (again, in the Lisp way...). \nThat's my rationale, whether or not it's solid.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59178, "question": "I should have explained this better, and will shoe-horn this into my documents afterward, but the reason for one structure was 2 fold: \n1- It was based on Lisp's approach to this topic (I was to choose a few languages to emulate the \"good\" parts of), and \n2 - It encourages exploration and learning on the part of potential students or new programmers by using the list to write their own additional structures (again, in the Lisp way...). \nThat's my rationale, whether or not it's solid.", "aSentId": 59179, "answer": "*\"It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures.\"*\n\n- Alan J. Perlis", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59181, "question": "When I saw \"modules\" I was thinking in the lines of Modula-3, Modula-2 and Oberon. It may be worth mentioning these in your documentation.\n\nUseless story: when I was in college I TA'd a compilers course that was being taught by a new professor in the department. He decided to use Modula-3 as the implementation language and did not believe in using LEX and YACC in an intro course. So not only did the poor bastards have to struggle with Dragon Book they also had to write their own scanner and parser generators in a language they had never seen before. The whole thing was FUBAR from the start. What a nightmare.\n", "aSentId": 59182, "answer": "I'd thought of the Modulas, too, but not Oberon. Out of curiosity I'm checking that now. Ada came up in discussions with prof quite a bit, due to the keyword-delimiting blocks and use of `end` in an established, earlier-generation language. I may actually go back and shoehorn these as a hat tip.\n\nAnd that class sounds rough. I couldn't imagine not using a parser/lexer in an intro course. As this is a one-semester project, I'll be using ANTLR, which is the Java answer to LEX and YACC, as I'm sure you're aware.\n\nDid anyone get a working compiler out of that course? Or was the result expectation tempered at some point, like just get a parser running? I'm not saying it's not possible, but given any course load at all, it would seem pretty daunting, given time limitations. I guess chosen language to compile would be a big part of it. I've peaked at quite a few compiler courses online from various universities, and I could be wrong (and I'm sure someone will prove me so), but I don't *believe* that I have ever come across a contemporary intro compiler course that doesn't use a parser/lexer.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59183, "question": "I'd thought of the Modulas, too, but not Oberon. Out of curiosity I'm checking that now. Ada came up in discussions with prof quite a bit, due to the keyword-delimiting blocks and use of `end` in an established, earlier-generation language. I may actually go back and shoehorn these as a hat tip.\n\nAnd that class sounds rough. I couldn't imagine not using a parser/lexer in an intro course. As this is a one-semester project, I'll be using ANTLR, which is the Java answer to LEX and YACC, as I'm sure you're aware.\n\nDid anyone get a working compiler out of that course? Or was the result expectation tempered at some point, like just get a parser running? I'm not saying it's not possible, but given any course load at all, it would seem pretty daunting, given time limitations. I guess chosen language to compile would be a big part of it. I've peaked at quite a few compiler courses online from various universities, and I could be wrong (and I'm sure someone will prove me so), but I don't *believe* that I have ever come across a contemporary intro compiler course that doesn't use a parser/lexer.", "aSentId": 59184, "answer": "Oberon was Wirth's successor to Modula-2: -3 was implemented by a different group. In either case they're further evolutions of Pascal.\n\nWRT the compiler course, no one finished. It's been 25 years or more but I think a couple of people made it as far as creating an AST. The language they were working with was a simplified Pascal.\n\nThis was the only case where I've seen a compiler course not use a scanner/parser generator. When I took it we learned the theory behind them, but then treated these tasks as a solved problem and used LEX/YACC.  The professor in the class I was a TA for felt that the only way to truly grasp the ideas was to implement them. It was brutal (because I had to learn enough Modula-3 to stay ahead of them!)\n\nAs the repressed memories are surfacing I don't think he used the Dragon book either... he used something published by Springer Verlag. Waaaahhhh.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59185, "question": "Oberon was Wirth's successor to Modula-2: -3 was implemented by a different group. In either case they're further evolutions of Pascal.\n\nWRT the compiler course, no one finished. It's been 25 years or more but I think a couple of people made it as far as creating an AST. The language they were working with was a simplified Pascal.\n\nThis was the only case where I've seen a compiler course not use a scanner/parser generator. When I took it we learned the theory behind them, but then treated these tasks as a solved problem and used LEX/YACC.  The professor in the class I was a TA for felt that the only way to truly grasp the ideas was to implement them. It was brutal (because I had to learn enough Modula-3 to stay ahead of them!)\n\nAs the repressed memories are surfacing I don't think he used the Dragon book either... he used something published by Springer Verlag. Waaaahhhh.", "aSentId": 59186, "answer": "See, in my mind, using a lexer and parser is really the *only* way to understand the theory, since a one-semester course on compilers wouldn't afford time to both understand the theory *and* write from the ground-up. If you had to implement everything yourself, I'd say a practical text on compilers (there are many today, probably far-fewer that many years ago) in Java or similar would be the way to go, and forget about (much) theory. Using the automated tools affords additional time to learn theoretical compiler design as you go, at last in my mind. A second compiler attempt after such a course would probably generate far better results than in the former, IMHO.\n\nThanks for the input and anecdote.", "corpus": "reddit"},{"docID": "t5_2qhmr", "qSentId": 59188, "question": "My criticism is that your semantic specifications are practically nonexistent and the language incomplete without them. If time was short, between doing that and implementing I would have done that. Not sure if you decided they weren't worth your limited time because the language was similar enough to others that semantics could be guessed, or because you thought the implementation was enough to clarify the semantics if needed (worse), or because you thought the syntax was 'self-explanatory' (worse still).", "aSentId": 59189, "answer": "It was very much a time-related matter. Discussions with prof on what to focus on resulted in what's here, but I understand and accept the criticism. This is something I could flesh out after my other work is complete, no question.\n\nThanks for the feedback (here and above). Much appreciated.\n", "corpus": "reddit"}]